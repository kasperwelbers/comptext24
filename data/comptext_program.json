[{"slot":"Day1_1","session_title":"Exploring Global Challenges and Communication Dynamics","session":35,"session_meansim":0.3182,"Title":"Great Power Trade Cooperation and Conflict: A New Dataset Based On Supervised Machine-Learning","authors":"Tanja Schweinberger; Jascha Uriel Gruebel","full_text":"Great Power Trade Cooperation and Conflict: A New Dataset Based On Supervised Machine-Learning\n\nU.S.-China power struggle represents a key feature of world politics nowadays. Understanding variation in cooperation between the two greatest current powers is therefore crucial. Whilst relations between the U.S. and China are incessantly discussed, there is remarkably little systematic evidence on both powers’ cooperative and conflictual policy initiatives towards each other over time, especially in the highly politicized area of trade politics. More research is needed to examine when cooperation or conflict in bilateral trade prevails and what factors shape these outcomes. This paper presents a novel dataset: the Great Power Trade Cooperation and Conflict (GPTCC) dataset. Inspired by event-data analysis approaches from conflict research, the GPTCC captures bilateral trade cooperation and conflict between the U.S. and China from 1978 to 2020. With supervised machine-learning of 400’000 newspaper articles from the U.S. and China to gauge major trade policies of great powers towards each other, we discover important over-time variation. After introducing the dataset, we also illustrate how GPTCC can be used in future IPE research by examining the relative importance of political and economic variables over time.","keywords":"Machine Learning, International Political Economy, Trade","approach":"supervised machine learning","data":"newspaper articles from the U.S. and China","issue":"cooperation and conflict between the US and China in trade politics","geofocus":"U.S. and China","Corresponding Author":"Schweinberger, Tanja","chair":"Shaunette T. Ferguson","discussant":"Markos Mpadanes","time":"Friday, 09:30-11:00"},{"slot":"Day1_1","session_title":"Exploring Global Challenges and Communication Dynamics","session":35,"session_meansim":0.3619,"Title":"Real-Time Tracking of the Influence of Press Releases on News Media","authors":"Morley Weston; Markos Mpadanes","full_text":"Real-Time Tracking of the Influence of Press Releases on News Media\n\nIn strategic communication, influencing what is in the media and how it gets there is paramount for organizational entities (Zerfass et al., 2018). With this, several studies have shown the significant role of press releases in news coverage (see Boumans, 2017). However, most of these studies focused on specific organizations (e.g., Schwartz et al., 2012), issues (e.g., Lee & Basnyat, 2013), or people (e.g., Miller et al., 1998), and remained small in scale. \n\nTherefore, we developed an automated method, primarily written in Python and Rust, that aims to assess the degree to which press releases influence media coverage (agenda building; Curtin, 2009) and the extent to which the media coverage directly replicates press releases (churnalism; Davies, 2008). We examined the impact of organizational press releases on news production and evaluated whether this phenomenon has grown. \n\nAs a pilot, we scraped two extensive German-language data sets from 2013 to 2023, the first comprising 321,380 press releases, the second a sample of 172,808 news texts from three newspapers with different political and qualitative characteristics. Next, we used NER tools to extract entities mentioned in each text. When there was a match, we used novel text similarity calculation methods to find a window of overlapping content, which enables large-scale matching of StratCom and news texts. Ultimately, our real-time monitoring tool allows us to examine a) the flow of press release data into news media and b) their intersection over time.","Discipline":"communication science; strategic communication; organizational communication;","keywords":"named entity recognition; web scraping; strategic communication; news production","approach":"text similarity calculation","data":"press releases and news texts","issue":"influence of press releases on media coverage","geofocus":"Germany","Corresponding Author":"Markos Mpadanes","chair":"Shaunette T. Ferguson","discussant":"Markos Mpadanes","time":"Friday, 09:30-11:00"},{"slot":"Day1_1","session_title":"Exploring Global Challenges and Communication Dynamics","session":35,"session_meansim":0.3182,"Title":"Revealing temporal patterns in online racialized discourse","authors":"Shaunette T. Ferguson; Courtney Cogburn; Colin Wayne Leach","full_text":"Revealing temporal patterns in online racialized discourse\n\nSocial media allows individuals to discuss political events online as they unfold offline. Few works, however, are dynamic enough to examine the temporal patterns of discussion online in relation to the discontinuous unfolding of events offline. From the “Beyond the Hashtags” dataset we examined 1.6 million tweets by almost 400,000 users over August 2014, in which unarmed Black teenager Michael Brown was killed by police in Ferguson, Missouri. This led to a discontinuous series of offline events (e.g., demonstrations, police suppression, politician speeches) that further shaped online discussion. Thus, we constructed a temporal network of co-occurring hashtags for 24-hour time windows, overlapping at 12-hour intervals. We exclude non-random hashtag pairs via a filtering mechanism and examine (1) network structure, and (2) temporal properties of discussion. The network structure showed the emergence of distinct communities appearing to frame events in distinct ways — as news, as systemic injustice, as left-wing rabble-rousing. In terms of evolution, some discussions spiked sharply after an event and quickly dissipate not to appear again (e.g., the naming of the officer who killed Brown), whereas others spiked then appear later (e.g., the police killing of Eric Garner). Yet other discussions emerged gradually and then decayed slowly, such as the calls “Justice for Mike Brown” or “Unite for the Blue”. By examining the links between unfolding events and differently evolved discussions, we may better understand the dynamic ebb and flow of offline and online political experience and behavior.","Discipline":"Network science; Computational social science; data science","keywords":"temporal social networks, text analysis, network analysis","approach":"temporal network analysis","data":"tweets from the “Beyond the Hashtags” dataset","issue":"online racialized discourse","geofocus":"Ferguson, Missouri","Corresponding Author":"Shaunette T. Ferguson","chair":"Shaunette T. Ferguson","discussant":"Markos Mpadanes","time":"Friday, 09:30-11:00"},{"slot":"Day1_1","session_title":"Exploring Global Challenges and Communication Dynamics","session":35,"session_meansim":0.3182,"Title":"Who Leads the Responses to the Coronavirus Pandemic in China? A Text-as-Data Approach","authors":"Chao-Yo Cheng; Tao Lin","full_text":"Who Leads the Responses to the Coronavirus Pandemic in China? A Text-as-Data Approach\n\nWhile China is a de jure unitary state, throughout history, local governments have played a pivotal role in numerous instances of policy innovations. In this study, we examine the government's policy responses to the pandemic in China. We assert that the policymaking process in China should not be simplified as a mere top-down approach. The interplay of political affiliations and the degree of emergency and uncertainty profoundly influenced the dynamics of policy agenda establishment when the pandemic struck the country. The relationships between national and subnational ruling cadres can act as an informal conduit, bridging the information gap regarding policy priorities across various government tiers. Particularly during times of heightened uncertainty, as was the case in the initial year of the COVID-19 outbreak, senior government authorities are more inclined to adopt policy initiatives originating from lower tiers. Drawing upon over 16,000 policy documents disseminated by different levels of government administration, we utilize structural topic modeling (STM) to deduce and investigate the daily distribution of pandemic-related policy topics. Subsequently, we employ a panel vector autoregressive model to uncover how the initiation of a policy agenda at one government level can trigger corresponding policy responses from counterparts at other levels. Our findings indicate that the central government primarily aligned with the topics set by both the provinces and prefectures. Below the provincial level, prefectures lacking strong connections to their provincial leaders emerged as the primary agenda-setters. Provinces were responsive to the topics set by non-connected prefectures, with connected prefectures following suit.","Discipline":"Political science","keywords":"policy agenda setting; Structural topic modeling; panel data analysis","approach":"text-as-data","data":"policy documents disseminated by different levels of government administration","issue":"government policy responses to the COVID-19 pandemic in China","geofocus":"China","Corresponding Author":"Chao-Yo Cheng","chair":"Shaunette T. Ferguson","discussant":"Markos Mpadanes","time":"Friday, 09:30-11:00"},{"slot":"Day1_1","session_title":"Exploring Global Challenges and Communication Dynamics","session":35,"session_meansim":0.3182,"Title":"Just asking questions? An inquiry into top-down conspiracist communication on social media in Poland, Belgium, Greece, and Finland '","authors":"Nathalie Brack , Piotr Marczyński and Kostas Papaioannou","full_text":"Just asking questions? An inquiry into top-down conspiracist communication on social media in Poland, Belgium, Greece, and Finland'\n\nIn the wake of the COVID-19 pandemic, the proliferation of conspiracy theories on social media became the centerpiece of concerns over the epistemic foundations of democracy. With the real-life consequences of online knowledge contestation becoming all too real, the scholarly effort to understand the determinants of conspiracism intensified.  However, while our understanding of individual-level conspiracy beliefs expands, the emphasis on 'bottom-up conspiracies' overshadowed the agentic role of political parties in propagating conspiracies. This study builds on the nascent literature on top-down conspiracism to develop a framework for capturing the frequency and patterns of conspiracist communication of party officials on X across four countries. Building on the literature on populist communication, framing, and social identity, our measure aims at capturing how politicians mobilize conspiratorial frames to entrench the epistemic unity of the in-group. Effectively, our operationalization entails invocations of evil conspirators, ominous plots, and efforts to suppress the 'Truth.' Based on this operationalization, we will code all posts of 10 (most active and influential) politicians from each party in parliament. We will employ purposive sampling that will include 3-month periods before national elections, before European elections, during the \"normal\" period, and at the height of vaccine rollout.Given the topic's novelty, we want to explore both manual coding and computational methods. Although we expect the former to detect context-dependent conspiracies more appropriately, we continue to seek feedback on how computational methods can aid our analysis, either as the primary tool or as a means of cross-validating our findings.","Discipline":"Political science","geofocus":{},"Corresponding Author":"Piotr Marczyński","chair":"Shaunette T. Ferguson","discussant":"Markos Mpadanes","time":"Friday, 09:30-11:00"},{"slot":"Day1_1","session_title":"Media, Narratives, and Polarization: A Study of Social Media","session":1,"id":85,"session_meansim":43227,"Title":"Black Solidarity and Hostile Co-option on Twitter: #Black Lives Matter in the Netherlands","authors":"Diantha Vliet; Nicole Lemire-Garlic","full_text":"Black Solidarity and Hostile Co-option on Twitter: #Black Lives Matter in the Netherlands\n\nThe murder of George Floyd in 2020 caused outrage inside and outside of the United States, yet most studies have centered on the U.S. experience. This aligns with the historic tendency to hinge the study of study Blackness on the experiences of Black Americans. Focusing on the U.S. has both helped and hindered how Black political experiences are regarded in European countries. Although there is certainly overlap in global experiences of Blackness, which contributes the critical mass sometimes needed to bring anti-Black practices to light, the centering of U.S. experiences does the unique stories of Black Europe a disservice. \n \nTo investigate European understandings of the Black Lives Matter (BLM) movement post-Floyd, we studied the expressions of solidarity and uniqueness in Dutch-language BLM tweets (n = 10,056) from May to June 2020. Using quanteda (Benoit et al., 2018) to perform hashtag co-occurrence analysis, and Brock’s (2018) critical technocultural discourse analysis to qualitatively analyze tweets, we found that Dutch users expressed solidarity with Black Americans under a shared understanding of oppression and liberation. They also localized their BLM support through the inclusion of regional hashtags like #kzop. At the same time, we found an antithetical use of the hashtag by some to antagonize anti-racists and blame foreign influences.\n \nMoving beyond U.S. analogies to examining Dutch perspectives in their own right, this study enables a fuller understanding of transnational Black activism amidst the complex dynamics of BLM protests. The findings further highlight the weaponized use of hashtags by local antagonists to undermine activism.","Discipline":"communication","keywords":"Black Lives Matter; Hashtag Activism; Dutch Language","approach":"quanteda analysis","data":"Dutch-language BLM tweets","issue":"Black solidarity and hostile co-option on Twitter","geofocus":"Netherlands","Corresponding Author":"Nicole Lemire-Garlic","chair":"Lotte Schrijver","discussant":"Ned Westwood","time":"Friday, 09:30-11:00"},{"slot":"Day1_1","session_title":"Media, Narratives, and Polarization: A Study of Social Media","session":1,"id":107,"session_meansim":43227,"Title":"Gendered hostility? Affective polarization among elites on social media\"","authors":"Albert Wendsjö; Hanna Bäck; Andrej Kokkonen","full_text":"Gendered hostility? Affective polarization among elites on social media\"\n\nAffective polarization is increasing in many parts of the world, and scholars have shown increasing interest in understanding why this is. Recently it has been argued that the characteristics of those who serve in parliaments can affect mass-level affective polarization. Specifically, it has been suggested that women MPs decrease affective polarization. Still, we know little of how and especially why female MPs might mitigate mass-level affective polarization. It has been proposed in the literature that women use a more consensual leadership style and softer rhetoric, but this idea has not been systematically tested. In this paper we test fill in this empirical gap in the research by studying how politicians talk about each other on social media in 26 western countries. Using a dataset of over 10 million tweets and a combination of dictionary and multilingual language models, we find that politicians indeed are more negative towards politicians from outgroups, and more positive towards politicians from ingroups. When looking at the moderating effect of gender, we find that male politicians are more likely to attack outgroups, and that males overall receive more outgroup negativity. We derive two mechanisms that explain this pattern, namely that politicians are responsive to how interactions are received by the online audience, and that politicians might attack each other for retribution – creating a negative spiral. We find no evidence suggesting that online interactions are rewarded differently based on the gender of the sender or receiver of those interactions. However, we do find support for the idea that negativity sparks negativity.","Discipline":"Political Science","keywords":"affective polarization; elite communication; social media; multilingual text analysis","approach":"dictionary and multilingual language models","data":"tweets","issue":"affective polarization among elites on social media","geofocus":"western countries","Corresponding Author":"Albert Wendsjö","chair":"Lotte Schrijver","discussant":"Ned Westwood","time":"Friday, 09:30-11:00"},{"slot":"Day1_1","session_title":"Media, Narratives, and Polarization: A Study of Social Media","session":1,"id":106,"session_meansim":43227,"Title":"Narratives as Framed Information: Leveraging Large Language Models to Explore the Conceptual Overlap Between Two Popular Theories of Communication","authors":"Ned Westwood; Emily Robinson","full_text":"Narratives as Framed Information: Leveraging Large Language Models to Explore the Conceptual Overlap Between Two Popular Theories of Communication\n\nIn the field of environmental communication, ‘Framing’ and ‘Narratives’ are two richly studied concepts. However, they are often studied individually, and when they are presented together, they are often deployed using complementary but separate methodologies. This presents a methodological research gap between two concepts that seemingly share significant theoretical overlap. Framing, as articulated by Robert Entman, elucidates the process by which narratives are constructed and presented. The four framing functions—defining problems, diagnosing causes, making moral judgments, and suggesting remedies—serve as the structural backbone for narratives. For instance, within environmental discourse, political figures or entities can be cast as heroes or villains, connecting them causally to events and actions deemed as both remedies for and contributors to political challenges and environmental problems. \n\nIn this study, we seek to bridge the gap between these domains, applying a combined theoretical framework that considers framing functions to be the process by which narratives are shaped. We leverage state-of-the-art language models such as GPT3.5, Zephyr, and Vicuna, to explore the nature of this relationship, comparing discourse related to Electronic Vehicles (EVs) across three social media platforms; Twitter, TikTok, and Facebook. Our investigation posits that integrating these approaches computationally will reveal nuanced insights into how framing shapes narratives and how narratives, in turn, embody framing functions. This approach offers a holistic understanding of the intertwined nature of framing and narrative within environmental communication.","Discipline":"Environmental Communication; Social Data Science","keywords":"LLM; Narratives; Framing Functions","approach":"large language models","data":"environmental communication on Twitter","issue":"relationship between framing and narratives","geofocus":"social media platforms","Corresponding Author":"Ned Westwood","chair":"Lotte Schrijver","discussant":"Ned Westwood","time":"Friday, 09:30-11:00"},{"slot":"Day1_1","session_title":"Media, Narratives, and Polarization: A Study of Social Media","session":1,"id":77,"session_meansim":43227,"Title":"The Effect of Triggerpoints on Social Media Discussions","authors":"Dimosthenis Antypas; Christian Arnold; Jose Camacho Collados; Nedjima Ousidhoum; Carla Perez Almendros","full_text":"The Effect of Triggerpoints on Social Media Discussions\n\nMau et al. (2023) introduced ‘triggerpoints’ as a new concept in discussions about politics and society. Rooted in theories of affective political identity, triggerpoints relate to deeply lying beliefs about moral expectations and social dispositions. When touched upon in discussions, these triggerpoints produce strong and emotional responses, often related to normative beliefs about fairness. While the original work introduced the concept and studied its effect with qualitative methods in focus groups, it has not been tested at larger scale. Our paper, therefore, systematically studies triggerpoints and their related theoretical expectations. Analyzing online deliberations on Twitter(X) and Reddit between 2020 and 2022 with Natural Language Processing, we identify a set of well-defined triggerpoints that should cause reactions along the lines of the original definition. We then investigate whether triggerpoints cause the expected emotional ‘flare-up’ in online deliberations the theory suggests. In a second step, we identify the causal effect of triggerpoints in a difference-in-difference design, and quantify how much of a difference ‘touching upon a triggerpoint’ actually makes to online discussions. Systematically testing the ‘triggerpoint’ concept and its theoretical implications, our work is relevant to all who study how citizens debate politics and society in light of affective polarisation.","Discipline":"NLP; Political Science; Sociology","keywords":"affective polarisation; hate speech; social media","approach":"natural language processing","data":"Twitter and Reddit","issue":"triggerpoints and their effect on social media discussions","geofocus":"2020-2022","Corresponding Author":"Christian Arnold","chair":"Lotte Schrijver","discussant":"Ned Westwood","time":"Friday, 09:30-11:00"},{"slot":"Day1_1","session_title":"Media, Narratives, and Polarization: A Study of Social Media","session":1,"id":71,"session_meansim":43227,"Title":"Training a BERT model to recognize misinformation: how to define and measure misinformation for machine learning in the context of the covid pandemic","authors":"Lotte Schrijver; Rens Vliegenthart; Pearl Dykstra","full_text":"Training a BERT model to recognize misinformation: how to define and measure misinformation for machine learning in the context of the covid pandemic\n\nMany studies have shown that machine learning models perform well on misinformation detection tasks, reaching F1 scores up to 0.93 (Bondielli & Marcelloni, 2019). However, these studies often have a simplified understanding of misinformation. They ignore that defining the boundaries between accurate information and misinformation is not always straightforward, and that the choices made in this process should be clarified (Vraga & Bode, 2020). Researchers are unclear about how they fact-checked the examples of misinformation used to train the model and what the model classified as misinformation. \n To give more insight into how misinformation can be defined and operationalized for a detection task, we trained a BERT model to recognize misinformation in Dutch-language Tweets posted during the covid pandemic. A team of four elaborately trained coders labeled the data using an extensive codebook. Our contribution is two-fold. We developed instructions to label misinformation in short texts that can be used for training machine learning models. We also tested the performance of a BERT model trained based on an operationalization of misinformation that takes the complexities of this concept into account. We focus on the covid pandemic, because the pandemic showed how difficult defining misinformation in a context of heightened uncertainty can be (Krause et al., 2022), and is therefore an excellent test case. Preliminary results are promising, showing that our BERT model performs as well as other models trained to detect misinformation in Dutch-language Tweets about covid (e.g. Alam et al., 2021). Final results will be available at the conference.","Discipline":"Communication science; political science","keywords":"Mis- and disinformation; supervised machine learning; covid pandemic; Twitter","approach":"BERT model","data":"Dutch-language Tweets during the covid pandemic","issue":"defining and measuring misinformation for machine learning","geofocus":"Netherlands","Corresponding Author":"Lotte Schrijver","chair":"Lotte Schrijver","discussant":"Ned Westwood","time":"Friday, 09:30-11:00"},{"slot":"Day1_1","session_title":"Political Leadership Visibility Study","session":4,"id":136,"session_meansim":49154,"Title":"‘Anti-sexism’: Where does it exist in politics, and its influence on classification of sexism","authors":"Aditi Dutta; Susan Banducci; Chico Camargo","full_text":"‘Anti-sexism’: Where does it exist in politics, and its influence on classification of sexism\n\nWe have all heard about sexism, but how many of us know of 'anti-sexism'? Prevalence of sexism in different forms, has existed in political discourse, especially in online platforms like Twitter. With rising awareness of the gender divide in political spaces, in terms of freedom of expression and capabilities comparable to their male counterparts, a new phenomenon has been observed in Twitter. This can be termed as 'anti-sexist' attitude, that can be defined as vehement support of anti-sexist rhetoric, not just promoting gender equality, but also opposing any sexist narratives at the event of controversial trigger events. However, such conversations can easily be mistaken as aggressive behaviour or sarcasm by computational methodologies. While the tone may be set as assertive, demanding and often condescending, they actually condemn online sexism. This causes an issue among different classification models, as they might be misclassified as harmful content, when in actuality, it is anything but. Consequently, this causes a lower recall value for such texts, and may cause problems in identifying a non-sexist online content from a sexist one. The aim of this research is to explore the prevalence of 'anti-sexism' in the UK political discourse- analyse its trigger events with regards to content, context and phrasing, and using that to computationally integrate it through Large Language Models(LLMs). The findings from this research should highlight the potential of prompting for (anti-)sexism detection and show how both the prompt and the model have a significant impact on achieving more accurate predictions in this task.","Discipline":"Politics; Computer Science","keywords":"Anti-sexism; computational social science; textual data analysis","approach":"computational analysis","data":"Twitter posts","issue":"anti-sexism in politics","geofocus":"UK","Corresponding Author":"Aditi Dutta","chair":"Hannes Salzmann","discussant":"Clint Claessen","time":"Friday, 09:30-11:00"},{"slot":"Day1_1","session_title":"Political Leadership Visibility Study","session":4,"id":52,"session_meansim":49154,"Title":"Bridging the Gap: Party Group Appeals and Party System Responsiveness","authors":"Denise Al-Gaddooa; Simon T. Franzmann; Felicia Riethmüller","full_text":"Bridging the Gap: Party Group Appeals and Party System Responsiveness\n\nAgainst the background of declining party-voter alignments, the use of group appeals in the analysis of party competition has experienced a considerable revival. While the aspects of party strategies to address social groups are well analysed, group appeals’ impact on the overall responsiveness is rarely analysed. Similarly, responsiveness literature tends to neglect the influence of group appeals. Our research aims to bridge this gap. At the party level, we examine if parties respond to the issue priorities of the groups they appeal to. At the party system level, we examine which groups’ issue priorities are neglected by party competition. We argue that unequal responsiveness at the party system level can prevail even when individual parties are highly responsive to their core electorate. We expect that stronger policy-seeking strategies among parties enhance the likelihood of parties aligning with social groups’ issue priorities, as these parties are more likely to appeal to specific groups with a greater (long-term) commitment. This commitment sets them apart from parties primarily focused on vote- or office-seeking, as these strategies are aimed to align with the mean voter. Employing a dictionary on the Manifesto Project’s corpus, we identify the groups appealed to in party manifestos. Utilizing the novel manifestoberta large language model, we classify open-ended responses from the EES and CSES into the Manifesto Project’s 56 issue categories. This allows us to compare social groups’ issue priorities with parties’ issue emphasis. Our study deepens our understanding of party strategies, social group appeals and the quality of representation.","Discipline":"political science","keywords":"responsiveness; party group appeals; large language models","approach":"dictionary approach","data":"party manifestos","issue":"party group appeals and party system responsiveness","geofocus":"global","Corresponding Author":"Denise Al-Gaddooa","chair":"Hannes Salzmann","discussant":"Clint Claessen","time":"Friday, 09:30-11:00"},{"slot":"Day1_1","session_title":"Political Leadership Visibility Study","session":4,"id":129,"session_meansim":49154,"Title":"Can identity appeals in party communication or news media influence voter perceptions?","authors":"Marvin Stecker; Fabienne Lind; Hajo G. Boomgaarden; Markus Wagner","full_text":"Can identity appeals in party communication or news media influence voter perceptions?\n\nResearch has increasingly studied how political parties use appeals to social groups in their communication to voters. This research tends to use one of two approaches: it either focuses only on changes in the supply-side of party rhetoric in manifestos but neglects the perspective of voters, or it focuses on the effects of group appeals in experimental settings. As a result, we still know little about how stable or malleable voter perceptions of party group linkages are over long time periods. Moreover, group appeals studies often only consider communication by party elites while overlooking the role of media reporting, possibly the most important source of political information, especially for more disengaged citizens. \nIn the present study, we bring together computational text analysis of party communication and news media with panel survey data from Austria and the UK. We use these two data sources to analyse the effects that party positioning towards social groups, both in parties’ own communication and in news reports, has on voter perceptions of parties and vote choice. The study contributes to research on group appeals and cleavages by bridging demand- and supply-side perspectives, analysing changes on the individual level and empirically separating the impact of two different sources of information on voter’s behaviour.","Discipline":"Political Science; Communication Science","keywords":"identity politics; linkage analysis; political behaviour","approach":"computational text analysis","data":"party communication and news media","issue":"voter perceptions of party group linkages","geofocus":"Austria and UK","Corresponding Author":"Marvin Stecker","chair":"Hannes Salzmann","discussant":"Clint Claessen","time":"Friday, 09:30-11:00"},{"slot":"Day1_1","session_title":"Political Leadership Visibility Study","session":4,"id":98,"session_meansim":49154,"Title":"Temporal Dynamics of Party Positions and Intra-party Variance: Measuring Party Positions in Parliamentary Speeches Using Sentence Transformer Models","authors":"Hannes Salzmann","full_text":"Temporal Dynamics of Party Positions and Intra-party Variance: Measuring Party Positions in Parliamentary Speeches Using Sentence Transformer Models\n\nMeasuring party positions has long been the basis for analysing party competition, party stances, and party behaviour. Established methods like expert surveys or analysing party manifestos, however, come with drawbacks regarding both the temporal dimension, e.g. manifestos only being released every couple of years, and the treatment of parties as unitary actors vis-a-vis intra-party variance. To develop a more fine-grained measure of party positions, I use parliamentary speeches as a promising data source and sentence-transformer models. Adapting the coding scheme of the Manifesto Project, rearranged into a Libertarian-Authoritarian and a GAL-TAN dimension, all speeches from the German Bundestag are classified by the sentence-transformer model which facilitates positioning every speech and MP on both dimensions over time. This not only allows for grasping the temporal dynamics of party positions in the inter-electoral period; uncovering intra-party dynamics also promises new insights into party behaviour and reactions in times of external shocks or crises, as well as the distribution of positions within a party. Leveraging this new approach, the paper tests hypotheses on parties converging towards a median position after an election, ideological wings showing in MPs positions, and divergence from the party line by “backbenchers”.","Discipline":"Political Science","keywords":"Party Positions; Parliamentary Debates; Natural Langugage Processing","approach":"Sentence Transformer Models","data":"Parliamentary speeches","issue":"party positions and intra-party variance","geofocus":"German Bundestag","Corresponding Author":"Hannes Salzmann","chair":"Hannes Salzmann","discussant":"Clint Claessen","time":"Friday, 09:30-11:00"},{"slot":"Day1_1","session_title":"Political Leadership Visibility Study","session":4,"id":3,"session_meansim":49154,"Title":"Who owns Green issues? A machine-learning approach to measuring speech distinctiveness of Green parties in government and opposition","authors":"Clint Claessen; Maxime Walder; Anthea Alberto","full_text":"Who owns Green issues? A machine-learning approach to measuring speech distinctiveness of Green parties in government and opposition\n\nThe literature utilizing supervised party label classification of parliamentary speech as a fictitious prediction problem has produced important findings regarding the discriminative power of political language and the detection of ideological shifts within political parties. This article adds to this understanding by examining the speech behavior of Green Parties in Germany and Ireland as issue owners on their main topic, the environment. Using legislative speech data from Germany (1991-2005) and Ireland (1992-2013), we find that the capture of environmental ministries significantly influences the Green Parties' speech distinctiveness and serves as a potential explanation for their strategies in maintaining issue ownership. We build upon the literature about issue ownership and coalition politics by arguing that government participation gives rise to a more distinctive rhetorical profile, even for parties traditionally considered outsiders or niche. Specifically, we find evidence that Green parties' government participation significantly increases the distinctiveness of their parliamentary speech. Lastly, we find election campaign dynamics in Germany: the German Green Party is more likely to deliver distinctive speeches as the election draws nearer. Our methodological approach, leveraging supervised learning for analyzing speech patterns, offers new insights into partisanship and speech distinctiveness, highlighting the utility of machine learning techniques in political text analysis.","Discipline":"Political Science; Text Analysis","keywords":"Visual Analysis, Machine Learning, Social Media, Political Elites","approach":"face verification classifier","data":"Instagram images posted by MPs during party leader elections","issue":"party leader visibility and voting during party leader elections","geofocus":"11 countries","Corresponding Author":"Clint Claessen","chair":"Hannes Salzmann","discussant":"Clint Claessen","time":"Friday, 09:30-11:00"},{"slot":"Day1_1","session_title":"Political Position Predictions","session":7,"id":30,"session_meansim":45124,"Title":"Detecting Democratic Decline: Political Leaders’ Public Discourse as an Early Warning Signal","authors":"Seraphine Maerz; Dean Schafer; Carsten Schneider","full_text":"Detecting Democratic Decline: Political Leaders’ Public Discourse as an Early Warning Signal\n\nPolitical leaders signal their commitment to democratic or authoritarian values through public speeches. Such signals can constitute a breach of democratic norms (Schedler 2019) and can also indicate intent to undermine both formal and informal democratic institutions. By listening to what leaders say we can identify when their positions are out of line with existing institutions and therefore detect crises of democracy in the making. In this article, we develop an Illiberal Speech Index (ISI). Utilizing a machine learning approach, we train an LLM model on speeches manually identified as being strongly indicative of authoritarian speech. We then use that model to classify 25,025 speeches by 201 leaders in 74 countries between 1995 and 2022. The resulting scores place leaders and their speeches on a liberal-illiberal dimension. We show that the ISI can predict democratic decline using time series analysis that combines our index with V-Dem scores. We test robustness of our explanation to country-level factors—such as existing democratic institutions—as well as international factors, such as regional democracy. We show that public, authoritarian rhetoric provides an early warning signal of future autocratization.","Discipline":"Political Science","keywords":"democracy and autocracy; machine learning; text analysis","approach":"machine learning","data":"speeches by political leaders","issue":"democratic decline","geofocus":"74 countries","Corresponding Author":"Dean Schafer","chair":"Verena Kunz","discussant":"Kenneth Benoit","time":"Friday, 09:30-11:00"},{"slot":"Day1_1","session_title":"Political Position Predictions","session":7,"id":68,"session_meansim":45124,"Title":"Distinct Rhetoric? Predicting Voting Defection from Parliamentary Speech Using Machine Learning","authors":"Verena Kunz","full_text":"Distinct Rhetoric? Predicting Voting Defection from Parliamentary Speech Using Machine Learning\n\nDo legislators discuss votes on the parliamentary floor differently when they defect from their party principals than when they are loyal? Plenary debates are generally considered a central arena for legislators to exchange arguments, appeal to voters, and justify their positions. Adopting an approach suggested by Peterson and Spirling (2018) that uses model performance as a substantive quantity of interest, I assess how well different text representations and supervised learning algorithms are able to predict whether a plenary debate contribution comes from a defecting or loyal legislator. When the algorithm performs well at distinguishing these speeches, this suggests that legislators focus on different aspects or use different rhetoric in response to their voting decision when taking the plenary floor. Empirically, I draw on an original data set of roll-call votes and associated multilingual debate contributions from the 7th, 8th, and 9th European Parliament (2009-2023). Preliminary results from this supervised classification task suggest that parliamentary speech differs depending on whether legislators defect from their party principals or not. The findings contribute to our understanding of how legislators manage intra-party conflict, with implications for political representation.","Discipline":"(computational) political science","keywords":"multilingual text analysis; large language models; supervised classification; parliamentary speech; defection","approach":"supervised machine learning","data":"parliamentary speech","issue":"voting defection","geofocus":"Europe","Corresponding Author":"Verena Kunz","chair":"Verena Kunz","discussant":"Kenneth Benoit","time":"Friday, 09:30-11:00"},{"slot":"Day1_1","session_title":"Political Position Predictions","session":7,"id":8,"session_meansim":45124,"Title":"Places in Political Communication - Deconstructing Politician's Spatial Framing Using Text as Data","authors":"Lukas Birkenmaier; Marius Sältzer; Constantin Wurthmann","full_text":"Places in Political Communication - Deconstructing Politician's Spatial Framing Using Text as Data\n\nDyadic representation constitutes a central characteristic of present-day democracies.\nHowever, the mechanisms how politicians address their constituency on a direct\nlevel remains largely unclear. To address this research gap, our study delves into the\nstrategic framing of places by politicians. Specifically, we explore how politicians\nshape the narrative around their local constituency, with a particular emphasis on\nplaces within their electoral district. To conduct our analysis, we examine a corpus of\n1.7 million tweets and 250.000 parliamentary speeches by elected politicians during\nthe 19th German Bundestag. Applying named entity recognition and supervised\nmachine learning, we then proceed to assess the relationship between the policy\nframes articulated by politicians and the characteristics of the places they talk about","Discipline":"political science","keywords":"named entity recognition, political framing, political communication","approach":"supervised machine learning","data":"tweets and parliamentary speeches","issue":"politician","geofocus":"Germany","Corresponding Author":"Lukas Birkenmaier","chair":"Verena Kunz","discussant":"Kenneth Benoit","time":"Friday, 09:30-11:00"},{"slot":"Day1_1","session_title":"Political Position Predictions","session":7,"id":127,"session_meansim":45124,"Title":"Predicting Left-Right Position from Hand-Coded Content Analysis using Large Language Models","authors":"Kenneth Benoit; Michael Laver; Stefan Mueller; Jinshuai Ma","full_text":"PREDICTING LEFT-RIGHT POSITIONS FROM HAND-CODED CONTENT ANALYSIS USING LARGE LANGUAGE MODELS\n\nEstimating policy positions from political text is a core element in many empirical analyses of political competition. This has traditionally been achieved using classical content analysis, which requires costly and unreliable human experts. Benoit et al. (2016) showed that crowd workers can label political texts as effectively as experts, but faster and more cheaply, yet because it relies on judgments about every sentence in every text by multiple crowd workers, limiting its scalability to large corpora. Unsupervised machine learning requires human “curation” of texts based on policy content, to allow ex-post human interpretation of results. Supervised machine learning methods, in contrast, leverage a relatively small training set of text labelled by humans, whether experts or crowd workers, to analyze a potentially huge volume of text out of sample, making this a much more scalable research tool. In this paper, we evaluate the effectiveness of different supervised machine learning algorithms using training sets labelled by humans, whether experts or crowd workers, to analyze both party manifestos and legislative speeches. We first replicate the widely-used RILE scale from the Manifesto Project, derived from classical text analysis by human experts, by applying traditional supervised machine learning methods, artificial neural network (ANN) models using static word embeddings, and finally transformer-based ANNs using a multi-lingual large language model to produce scale estimates on a par with those from human coders. We show that this also works out of domain using transfer learning to produce policy positions for regional manifestos never coded by the Manifesto Project.","Discipline":"Political Science","keywords":"transformers, policy positions, manifesto project","approach":"supervised machine learning","data":"hand-coded content analysis","issue":"predicting political positions from text","geofocus":"unspecified","Corresponding Author":"Kenneth Benoit","chair":"Verena Kunz","discussant":"Kenneth Benoit","time":"Friday, 09:30-11:00"},{"slot":"Day1_1","session_title":"Political Position Predictions","session":7,"id":51,"session_meansim":45124,"Title":"Subjectivity vs. Reliability - New Perspectives from Machine Learning Research","authors":"Anke Stoll","full_text":"Subjectivity vs. Reliability - New Perspectives from Machine Learning Research\n\nReliability is a key quality criterion in quantitative content analysis and is defined as the agreement between coders based on a shared, often theory-based, understanding of a concept (Krippendorff, 2018). From the perspective of standardized measurement, this criterium is straight-forward, as deviations between coders can contradict the meaningfulness and generalization of research results. However, deviations are not necessarily a consequence of measurement error, but of subjective or context dependent perceptions (Baden et al., 2023). Here, one prominent example is the concept of incivility (Bormann et al., 2022). Research reveals that what is perceived as uncivil (e.g., as harmful or inappropriate) greatly differs regarding gender, personal experience, and professional role of recipients.\nThe subjectiveness of concepts such as incivility poses significant challenges not only to manual content analysis but also to machine learning-based classification of uncivil content. In supervised learning, a model learns to classify content based on one unique manual measurement, in which subjectivity between coders is aligned by averaging or majority voting. Recent perspectives in NLP and machine learning research question the assumption of one unique understanding of subjective concepts. Researchers propose the approach of data perspectivism (Basil et al., 2021), which aims to consider coding deviations as valid subjectivity instead of measurement error.\nDuring my presentation, I will give an overview of the state of research on data perspectivism approaches. On the example of incivility, I will show potential application scenarios and discuss the question, what data perspectivism would imply for manual and computational content analysis.","Discipline":"Computational Communication Science","keywords":"machine learning, automated content analysis, data perspectivism","approach":"data perspectivism","data":"manual content analysis and machine learning-based classification","issue":"subjective concepts in quantitative content analysis","geofocus":"NLP and machine learning research","Corresponding Author":"Anke Stoll","chair":"Verena Kunz","discussant":"Kenneth Benoit","time":"Friday, 09:30-11:00"},{"slot":"Day1_2","session_title":"Group Appeals in Text Analysis","session":16,"id":161,"session_meansim":41226,"Title":"Group Appeals Across Time and Space: An Automated Measure of Parties’ Appeals to Social Groups","authors":"Will Horne; Alona O. Dolinsky; Lena Maria Huber","full_text":"Group Appeals Across Time and Space: An Automated Measure of Parties’ Appeals to Social Groups\n\nA growing literature in political science studies parties’ group-based appeals, which have been found to be prevalent in parties’ election materials. However, as past large-scale data collection efforts focused primarily on the policy content of manifestos rather than on appeals to social groups per se, still little data exist to support empirical analyses. This data scarcity is in part the result of the significant effort required in collecting such data on a large scale. As questions of group appeals are important for our understanding of political representation, party behavior, and the party-voter linkage, we join the recent efforts to expand available data on group appeals. Turning to computational text analysis methods, this paper outlines an automated approach to the extraction of group appeals from political texts. This includes the construction of a base-dictionary to set up a new transformer model for social group detection, as well as an LLM approach based on a BERT-NLI model (tested against roBERTa) to identify the stance (positive, negative or neutral) parties take towards the social group. As a test case, we analyze election manifestos of major parties in the UK and Ireland since the 1970s, showing LLMs to be valuable in extracting data on group appeals, revealing important trends in party behavior with implications for party competition, voter behavior and political representation.","Discipline":"Political Science","approach":"computational text analysis","data":"election manifestos of major parties in the UK and Ireland","issue":"group appeals","geofocus":"UK and Ireland","Corresponding Author":"Alona O. Dolinsky","chair":"Alona O. Dolinsky","discussant":"Vivien Fabry","time":"Friday, 11:15-12:45"},{"slot":"Day1_2","session_title":"Group Appeals in Text Analysis","session":16,"id":162,"Title":"Group Appeals and the Origins of Party Reputations","authors":"Christoffer H. Dausgaard, Frederik Hjorth","full_text":"Group Appeals and the Origins of Party Reputations\n\nParty reputations, widely shared perceptions of what political parties stand for and who they represent, are an essential feature of party competition. Earlier scholarship identifies parties' connections to social groups as an important constituent cause of party reputations. How do parties establish and maintain such connections? We study the role of group appeals, i.e. valenced references to social groups in public speech, and theorize that parties strategically use group appeals to forge and maintain linkages to social groups, which in turn underpins party reputations. This mechanism is often assumed in the group appeals literature but has rarely been tested, and never outside of experimental settings. To test this theory, we use large language models to measure a range of group appeals across millions of speeches in three parliamentary systems, linking them to survey-based measures of citizens' perceptions of group-party linkages. With this data, we examine whether and how party elites can use group appeals to shape party reputations. In a set of follow-up analyses, we hold constant the role of policy, isolating the effect of the symbolic dimension of group appeals. Our findings provide new insights into the role of group appeals in shaping public opinion and the nature and origins of party reputations.","Discipline":"Political science","keywords":"political behaviour, political rhetoric, group appeals, party reputations","approach":"computational text analysis","data":"election manifestos of major parties in the UK and Ireland","issue":"group appeals","geofocus":"UK","Corresponding Author":"Christoffer H. Dausgaard","chair":"Alona O. Dolinsky","discussant":"Vivien Fabry","time":"Friday, 11:15-12:45"},{"slot":"Day1_2","session_title":"Group Appeals in Text Analysis","session":16,"id":45,"session_meansim":40057,"Title":"What is the (group) appeal?: A Comparative Analysis of Disability Representation in European Multiparty Systems","authors":"Vivien Fabry","full_text":"What is the (group) appeal?: A Comparative Analysis of Disability Representation in European Multiparty Systems\n\nThis research delves into the intersection of voting behavior, collective iden-\ntity, and party policies, particularly focusing on social groups. Parties strate-\ngically employ group appeals to either align or distance themselves from these\ngroups (Dolinsky, 2022; Lawrence et al., 2018; Thau, 2021). While the existing\nresearch predominantly centers on well-established social groups, it is essential\nto acknowledge the marginalization of other groups, such as individuals with\ndisabilities (Evans & Reher, 2022; Fabry, 2023; Guldvik & Lesjø, 2014; Reher,\n2021). This study addresses this notable gap by examining disability represen-\ntation in parliamentary speeches spanning from 1997 to 2023 across different\nEuropean countries with multiparty systems, namely: Germany, Austria, the\nNetherlands, and Ireland. Leveraging a supervised token classification method\nby Licht and Sczepanski, 2023 and a Google BERT-based classifier (Nayak,\n2019), the research identifies group mentions and classifies the language into be-\ning more belittling or autonomous to analyze party attitudes toward individuals\nwith disabilities. The findings shed light on the following pattern: right-leaning\nparties demonstrate a tendency to employ belittling language while left-leaning\nparties lean towards more autonomous expressions. This ideological influence is\nnotably consistent across countries. However, the frequency of discussions about\ndisability in parliament differs per country. In contributing to our understanding\nof disability representation, this research not only offers a nuanced framework\napplicable to other marginalized groups, such as the trans* community but also\npropels efforts to address critical issues in global political inclusivity.","Discipline":"Political Science; Computational Social Science; Communication Science","keywords":"Political Representation; Text Analysis; Disability; Group Appeals","approach":"token classification","data":"parliamentary speeches","issue":"disability representation in European multiparty systems","geofocus":"Germany, Austria, the Netherlands, and Ireland","Corresponding Author":"Vivien Fabry","chair":"Alona O. Dolinsky","discussant":"Vivien Fabry","time":"Friday, 11:15-12:45"},{"slot":"Day1_2","session_title":"Group Appeals in Text Analysis","session":16,"id":131,"session_meansim":52411,"Title":"Which identities are mobilized? Party competition over social group identities in comparative perspective","authors":"Felicia Riethmüller","full_text":"Which identities are mobilized? Party competition over social group identities in comparative perspective\n\nPolitical parties competing in elections do not only mobilize policy issues, but also actively appeal to voters’ group identities. Recent studies point to the continuous relevance of group identities’ structuring voter behaviour. A crucial question which lacks theoretical and empirical examination however is which social group identities become relevant to parties and why. This paper makes an argument for electoral availability as an explanation and intends to map and measure how contested diverse social group identities are - thereby deducing hypotheses on which groups become attractive targets for identity appeals and under which conditions.\n\n I empirically test these assumptions by using party manifestos from Germany, Austria and Switzerland from 1980 to 2022 and identify appeals to groups using automated classification. Here, my focus will also lie on comparing different computational approaches for identifying social group identities in political text and their implications for substantive results. I combine this with survey data to assess how electorally available different social groups are, which allows me to show in how far electoral availability can explain which social identities parties decide to mobilize. The results stress parties’ active role in shaping group-based party competition and help us understand the surge of different social identities in party competition across time and countries. The paper also contributes to the measurement of group-based appeals in political text, which is becoming increasingly relevant to party research.","Discipline":"Political Science","keywords":"social group appeals, electoral availability, party competition","approach":"computational approaches","data":"party manifestos and survey data","issue":"social group identities in comparative perspective","geofocus":"Germany, Austria, and Switzerland","Corresponding Author":"Felicia Riethmüller","chair":"Alona O. Dolinsky","discussant":"Vivien Fabry","time":"Friday, 11:15-12:45"},{"slot":"Day1_2","session_title":"Media and Mobilization","session":18,"id":160,"session_meansim":4302,"Title":"Classifying Subtle News Articles on Two Ideological Dimensions using Large Language Models","authors":"Lucas Paulo da Silva","full_text":"Classifying Subtle News Articles on Two Ideological Dimensions using Large Language Models\n\nThe “minimal media effects” literature argues that media outlets do not influence voting behaviour much, primarily because voters already select ideologically like-minded media outlets. However, cross-pressured voters (CPVs) may lack these like-minded outlets in the first place. CPVs hold economically-leftist and culturally-conservative positions (left-conservatives) or economically-rightist and culturally-progressive positions (right-progressives). Based on the market and journalistic models of media ideology, I argue that media outlets that are more economically-rightist are also more culturally-conservative, despite the large and growing CPV audience. \n \n To test this relationship for the first time, I construct a novel corpus of 100,000 online media articles from 120 outlets in six countries. I then use a Structural Topic Model to assign articles to economic or cultural supertopics. Next, I use large language models (primarily GPT-4 Turbo) to label 3000 economic articles as progressive/centrist/conservative and 3000 cultural articles as leftist/centrist/rightist. I compare 300 of these to expert-coded labels and find a high degree of similarity, despite the challenge of labelling subtle texts on two different ideological dimensions. I train Support Vector Machines on the embeddings of the labelled articles and calculate ideological scores for the unlabelled economic and cultural articles. I then compute the mean economic and cultural outlet positions.\n \n Although this study only tests the media supply, the implications for voting behaviour are significant. My study tests whether CPVs must select outlets with which they disagree on either the economic or cultural dimensions. This exposure to divergent media outlets could alter their voting behaviour considerably.","Discipline":"Political Science","approach":"large language models and machine learning","data":"online media articles","issue":"media ideology and its impact on voting behavior","geofocus":"six countries","Corresponding Author":"Lucas Paulo da Silva","chair":"Constantine Boussalis","discussant":"Mariken van der Velden","time":"Friday, 11:15-12:45"},{"slot":"Day1_2","session_title":"Media and Mobilization","session":18,"id":120,"session_meansim":4302,"Title":"Cross-Topic Identification of False Information Using Linguistic and Stylistic Cues","authors":"Noelle Lebernegg","full_text":"Cross-Topic Identification of False Information Using Linguistic and Stylistic Cues\n\nIn an era of widespread misinformation, the development of computational approaches for automated detection in news and social media has gained prominence, with researchers reporting significant success in identifying both genuine and deceptive content. The present study contributes to this line of research in two ways. Firstly, addressing a practical challenge, the scarcity of high-quality data for misinformation detection often leads to reliance on topically biased datasets. To explore the transferability of such classifiers across topics, this study assesses whether topic-specific models can effectively detect dis- and misinformation in unrelated subjects. Assuming that textual disinformation exhibits consistent linguistic and stylistic characteristics independent of specific topics, the study aims to evaluate the classification performance of cross-topic models, i.e., models applied to a target topic different from the topic used for training, relying on such linguistic and stylistic features. Beyond practical considerations, this examination helps the identification and understanding of a potentially universal yet understudied \"language of fake news.\" By scrutinizing relevant linguistic and stylistic features in cross-topic classification models, the study contributes to uncovering patterns indicative of disinformation across diverse subjects, offering insights for more effective automated detection systems.","Discipline":"Communication Science","keywords":"Misinformation detection, cross-topic classification, language of fake news","approach":"linguistic and stylistic cues","data":"news and social media","issue":"false information detection","geofocus":"universal","Corresponding Author":"Noelle Lebernegg","chair":"Constantine Boussalis","discussant":"Mariken van der Velden","time":"Friday, 11:15-12:45"},{"slot":"Day1_2","session_title":"Media and Mobilization","session":18,"id":69,"session_meansim":4302,"Title":"Diverging Perspectives? Comparing Visual Heatwave Portrayals by Developed and Developing Country Media Outlets","authors":"Constantine Boussalis; Travis G. Coan; Ranadheer Malla; Saffron O’Neill","full_text":"Diverging Perspectives? Comparing Visual Heatwave Portrayals by Developed and Developing Country Media Outlets\n\nThis paper contributes to the literature on the visual communication of heatwave risks in developing countries, contrasting it with previous work focused on Europe. Specifically, we aim to explore how media portrayals in the developing world differ from those in developed nations, particularly given the increased vulnerability of developing countries to climate change. Our methodological approach involves the use of large visual models (LVMs) for image annotation through the use of automated descriptions and visual question-and-answering, applied to a dataset of 54,018 articles from 126 newspapers from a sample of countries from Europe, the Middle East, Asia, and Oceania. This study aims to deepen our understanding of visual framing in heatwave reporting by extending analytical scope provided by O’Neill et al (2023), which highlighted a predominantly positive visual framing of heatwaves in European media. By comparing these trends with media representations in developing countries, the study seeks to identify potential disparities and biases. Although results are pending, the paper anticipates contributing to a more nuanced understanding of climate change communication, emphasizing the role of visual media in influencing public perception and policy on climate emergencies. The study’s reliability is bolstered by validating our model’s annotations against a human-annotated set.","Discipline":"Climate change; communication","keywords":"Visual language models; image processing; climate change; media","approach":"visual framing analysis","data":"newspapers from developing and developed countries","issue":"heatwave portrayals in media","geofocus":"Europe, Middle East, Asia, and Oceania","Corresponding Author":"Constantine Boussalis","chair":"Constantine Boussalis","discussant":"Mariken van der Velden","time":"Friday, 11:15-12:45"},{"slot":"Day1_2","session_title":"Media and Mobilization","session":18,"id":2,"session_meansim":4302,"Title":"Liberation Technology 2.0: State repression, digital diaries, and backlash mobilization","authors":"Babak RezaeeDaryakenari","full_text":"Liberation Technology 2.0: State repression, digital diaries, and backlash mobilization\n\nIs state repression effective in demobilizing dissidents? While some studies find that repression can be effective, at least in the short term, a strand of this literature doubts its effectiveness due to backlash mobilization. However, despite widespread attention, studying the underlying mechanisms through which the backlash mechanism influences dissidents and their mobilization has received limited attention. This study argues that the rise of social media platforms for keeping and sharing personal diaries, especially among the younger generation, increases the likelihood of backlash mobilization in response to the state’s violent response to protests. Building on scholarship from psychology and communication science, I develop a theoretical framework to explain how the digital diaries of the victims of state repression brace protestors and increase social cohesion among dissidents. The study examines the proposed theoretical arguments by analyzing the nexus of repression-protest during the “Woman, Life, Freedom” revolutionary campaign in Iran. I use an originally collected dataset on the digital presence (image, video, and text) of citizens killed by the state and data on street protests and online campaigns to show that digital diaries has created a backlash effect.","Discipline":"political science; sociology; methodology; computational data analysis","keywords":"digital trace; digital diaries; repression; social movement","approach":"content analysis","data":"digital diaries and street protests","issue":"state repression and backlash mobilization","geofocus":"Iran","Corresponding Author":"Babak RezaeeDaryakenari","chair":"Constantine Boussalis","discussant":"Mariken van der Velden","time":"Friday, 11:15-12:45"},{"slot":"Day1_2","session_title":"Media and Mobilization","session":18,"id":154,"session_meansim":4302,"Title":"tg.observer: A database and toolset for identifying information sources on Telegram","authors":"Aleksi Knuutila; Roman Kyrychenko; Vasileios Maltezos","full_text":"tg.observer: A database and toolset for identifying information sources on Telegram\n\nTelegram is an encrypted messaging and broadcasting platform that claims over 800 million users in 2023. The platform's relatively permissive moderation policies and support for anonymity have made it attractive for pariahs from other social media platforms, political groups (including fringe or extremist politics), and real-time coverage of conflicts worldwide. Telegram's API makes it straightforward to download messages and media for study, but the platform has no central directory of public channels or groups and no global search for messages. Because of this, scholars studying Telegram typically rely on snowball sampling to identify channels relevant to their research interest, which can be technically demanding. This paper presents tg.observer, a database and a set of tools for researchers aiming to lower the threshold for studying the platform. The project publishes metadata about public groups and channels on Telegram and a citation graph between them. We also provide a set of tools for selecting networks of channels focused on particular topics. We will publish the project's first results in January 2024 at https://tg.observer. In addition to describing the database and tools, the presentation will discuss potential sampling biases in standard snowball sampling practices. Based on the more extensive database, we describe how sensitive snowball sampling is to the initial seedlist of channels and how far the snowball sampling needs to run to include influential channels in different types of networks. We conclude with suggestions for best practices for large-scale studies of Telegram.","Discipline":"Sociology; Computational social science","keywords":"telegram; sampling; social media","approach":"database and toolset","data":"Telegram messages and media","issue":"identifying information sources on Telegram","geofocus":"no geographical focus provided","Corresponding Author":"Aleksi Knuutila","chair":"Constantine Boussalis","discussant":"Mariken van der Velden","time":"Friday, 11:15-12:45"},{"slot":"Day1_2","session_title":"Policy Analysis","session":11,"id":62,"session_meansim":45252,"Title":"Analysing frames of Euroscepticism in times of crisis: how did Eurosceptic parties problematise the EU during the pandemic crisis and the Ukraine war?","authors":"Gilsun Jeong","full_text":"Analysing frames of Euroscepticism in times of crisis: how did Eurosceptic parties problematise the EU during the pandemic crisis and the Ukraine war?\n\nThis paper investigates how Eurosceptic parties in the 2019-2024 European Parliament (EP) problematised the EU and European integration on Twitter during the Covid-19 pandemic crisis and the Ukraine war. The EU attempted to collectively address the challenges imposed by the pandemic crisis and the Ukraine war, especially in areas hit hard by these crises. Consequently, the EU’s collective response to the challenges generated a range of issues and events within the Union, which opened windows of opportunity for Eurosceptic parties. In the light of this, it is important to investigate how Eurosceptic parties constructed their Eurosceptic stances in response to these issues and events amidst the pandemic crisis and the Ukraine war. To examine how Eurosceptic parties problematised the EU during these crises, this research particularly focuses on how Eurosceptic parties in the 2019-2024 EP incorporated different frames of Euroscepticism into their tweets. Drawing on the concept of ‘diagnostic frames’, this paper explores the terms through which Eurosceptic parties problematised the EU during these crises. The analysis centres on four Eurosceptic frames: socioeconomic frames; sovereignty frames; legitimacy frames; and cultural frames. Employing a novel approach utilising text classification, this research identifies and analyses various frames of Euroscepticism that Eurosceptic parties employed on Twitter at different moments throughout the crisis. This paper particularly applies a keyword-based text classification to the dataset consisting of tweets (n. 64,719) published by sixteen Eurosceptic parties in the 2019-2024 EP from nine Member States: France, Germany, Poland, Hungary, Greece, Italy, Spain, Sweden, and the Netherlands.","Discipline":"Political science","keywords":"Text classification, Euroscepticism, Twitter","approach":"text classification","data":"tweets by Eurosceptic parties in the European Parliament (EP)","issue":"frames of Euroscepticism during the pandemic crisis and the Ukraine war","geofocus":"Nine Member States (France, Germany, Poland, Hungary, Greece, Italy, Spain, Sweden, and the Netherlands)","Corresponding Author":"Gilsun Jeong","chair":"Bastián González-Bustamante","discussant":"Martijn Schoonvelde","time":"Friday, 11:15-12:45"},{"slot":"Day1_2","session_title":"Policy Analysis","session":11,"id":102,"session_meansim":45252,"Title":"Grandstanding under the Spotlight: Unveiling European Elites Crisis Communication in the Council of the European Union","authors":"Paula Montano; David Yen-Chieh Liao","full_text":"Grandstanding under the Spotlight: Unveiling European Elites Crisis Communication in the Council of the European Union\n\nCrisis events may motivate political elites to use salient communication in responding to the crisis. This paper examines how European Union ministers employed grandstanding messages to set agendas in reaction to financial crises between 2010 and 2016. Using a transformer classifier trained on a modified dataset from US congressional hearing messages related to grandstanding behaviour, we identified the grandstanding behaviour of EU ministers over time. We employed a difference-in-differences design to estimate the responses of different countries across time in the Council of the European Union. Our preliminary findings suggest that as Euroscepticism in countries increases, European ministers are more likely to use crises as opportunities for grandstanding. This strategy intensified debates and discussions against policies directly impacting their respective countries. Such actions shaped public perceptions of political issues and gained political leverage during the crisis. The implications of these findings yield an explanation of both the impacts of crises on European elites' communication and the influence of strategic crisis communication on agenda-setting.","Discipline":"Political Communication; EU crises; computational text analysis","keywords":"Grandstanding; EU crises; computational text analysis","approach":"transformer classifier","data":"Council of the European Union messages","issue":"crisis communication by European elites","geofocus":"Europe","Corresponding Author":"Paula Montano","chair":"Bastián González-Bustamante","discussant":"Martijn Schoonvelde","time":"Friday, 11:15-12:45"},{"slot":"Day1_2","session_title":"Policy Analysis","session":11,"id":104,"session_meansim":45252,"Title":"Multilingual Word Embeddings for Unravelling the Rule of Law in European Countries","authors":"Bastián González-Bustamante; Jaroslaw Kantorowicz","full_text":"Multilingual Word Embeddings for Unravelling the Rule of Law in European Countries\n\nThis paper analyses the salience of different conceptualisations of the rule of law in the parliamentary debates of 26 European countries from the 2000s, depending on the case, to mid-2022. This cross-national comparison enabled us to evaluate the meaning of the rule of law across different jurisdictions, which is theoretically relevant since, in the literature, it is possible to find thick or thin conceptualisations associated with other concepts such as human rights, the functioning of the legal system or even transparency. We used the country cases corpora of the ParlaMint 4.0 dataset, which comprises speeches in the legislative chambers and over 1.1 billion words. This dataset on parliamentary speeches offers texts in the original languages and machine-translated versions, therefore, it is a helpful resource for multilingual applications of word vectors. Furthermore, in order to run additional checks, we also used the ParlSpeech V2 dataset, which covers legislative speeches from nine of the 26 countries in ParlaMint. Thus, we used a number of applications of multilingual word embeddings (MWEs) to deal with the range of corpora languages (i.e., North and West Germanic, Eastern South and West Slavic, Finnic, Western Romance, among others) and be able to evaluate differences and similarities across countries. We also ran word embeddings on mono-lingual sub-corpora, some bilingual word embeddings (BWEs) and used the machine-translated corpora for robustness checks and cross-lingual validation of our main results.","Discipline":"comparative politics; politico-legal philosophy; empirical legal studies","keywords":"rule of law; multilingual word embedding; multilingual analysis","approach":"multilingual word embeddings","data":"parliamentary debates from 26 European countries","issue":"understanding the concept of the rule of law across different jurisdictions","geofocus":"Europe","Corresponding Author":"Bastián González-Bustamante","chair":"Bastián González-Bustamante","discussant":"Martijn Schoonvelde","time":"Friday, 11:15-12:45"},{"slot":"Day1_2","session_title":"Policy Analysis","session":11,"id":16,"session_meansim":45252,"Title":"Speaking Clearly or Dodging Delicately? Exploring the role of precision and vagueness in intergovernmental deliberations in the Council of Ministers of the European Union.","authors":"Martijn Schoonvelde; James Cross","full_text":"Speaking Clearly or Dodging Delicately? Exploring the role of precision and vagueness in intergovernmental deliberations in the Council of Ministers of the European Union.\n\nThis study examines the role of precision and vagueness in policy debates in the Council of Ministers of the European Union (EU). We hypothesise that ministers manipulate the precision of their interventions to explain support for policy change to their colleagues. We introduce a novel measure of precision constructed using large language models, and validate these measures against human coding efforts. We then demonstrate how precision varies significantly across policy area, member state representative, and time. Our results provide new insights into the manner in which member states justify their voting behaviour to one another and the rhetorical structures that shape Council deliberations.","Discipline":"Political science","keywords":"EU politics; GPT 4; measurement; vagueness; precision","approach":"natural language processing","data":"policy debates in the Council of Ministers of the European Union","issue":"policy change and justification","geofocus":"European Union","Corresponding Author":"Martijn Schoonvelde","chair":"Bastián González-Bustamante","discussant":"Martijn Schoonvelde","time":"Friday, 11:15-12:45"},{"slot":"Day1_2","session_title":"Policy Analysis","session":11,"id":103,"session_meansim":45252,"Title":"The World Internet Conference and China’s Promotion of “Cyber Sovereignty”","authors":"Xiaojuan Yang","full_text":"The World Internet Conference and China’s Promotion of “Cyber Sovereignty”\n\nThe World Internet Conference and China’s Promotion of “Cyber Sovereignty”: Despite ongoing criticism, the Chinese government has relentlessly hosted the World Internet Conference (WIC) for a decade. This research aims to explore the motives behind China's persistent efforts, particularly focusing on its role in advocating cyber sovereignty. By employing Natural Language Processing to analyse its policy declarations, discussion themes, media coverage, etc. the study seeks to comprehend how China utilises WIC to propagate its internet governance vision. The research evaluates the potential outcomes of this strategy, emphasizing its importance in understanding the evolving norms and practices of global cyber governance, especially in the context of the developing world. This research is important in decoding China's influence on shaping the digital landscape, offering insights into the broader implications for international internet policy and governance.","Discipline":"Global Politics","keywords":"Cyber Sovereignty, Natural Language Processing, Comparative Study","approach":"natural language processing","data":"policy declarations","issue":"China’s promotion of cyber sovereignty","geofocus":"Global, with a focus on the developing world","Corresponding Author":"Xiaojuan Yang","chair":"Bastián González-Bustamante","discussant":"Martijn Schoonvelde","time":"Friday, 11:15-12:45"},{"slot":"Day1_2","session_title":"Political Visual Communication in Europe","session":2,"id":158,"session_meansim":48966,"Title":"Analyzing Visual Communication Strategies: A Comparative Study of Populist and Mainstream Political Parties on Instagram Across 28 European Countries (2019-2021)","authors":"Gaetano Scaduto; Silvia Decadri; Moreno Mancosu; Fedra Negri","full_text":"Analyzing Visual Communication Strategies: A Comparative Study of Populist and Mainstream Political Parties on Instagram Across 28 European Countries (2019-2021)\n\nThe relevance of imagery in political communication has traditionally been a significant topic in academic studies. However, the rise of social media platforms has notably amplified interest in this area over the last few decades. In particular, the visual aspects of populist political communications online and their correlation with engagement levels have not been adequately explored. This study utilizes multilevel models to analyze a dataset comprising all Instagram posts published by the leaders of parties represented in the ninth European Parliament (156 leaders from 28 European countries) during the period from March 1, 2019, to December 31, 2021 (n=71,652). Our aim is to identify which visual features are predominantly used by populist versus mainstream political actors, how these features vary across nations, and how they are influenced by the COVID-19 pandemic. Additionally, we seek to determine which visual features employed by populist are most likely to generate higher engagement on Instagram. To detect these visual features, all images have been analyzed using automated processes by Microsoft Computer Vision and Face++ algorithms.","Discipline":"Political Science; Communication Science","keywords":"Visual Communication; Populist Politics; Social Media Analysis","approach":"computer vision","data":"Instagram posts","issue":"visual communication strategies of populist and mainstream political parties","geofocus":"28 European countries","Corresponding Author":"Gaetano Scaduto","chair":"Johannes B. Gruber,","discussant":"Christian Pipal","time":"Friday, 11:15-12:45"},{"slot":"Day1_2","session_title":"Political Visual Communication in Europe","session":2,"id":97,"session_meansim":48966,"Title":"From Salience to Silence? Party Communication on Climate Change on Twitter in 12 European Democracies","authors":"Malo Jan","full_text":"From Salience to Silence? Party Communication on Climate Change on Twitter in 12 European Democracies\n\nWhat drives the incorporation of climate change into the party agenda? In recent years, climate change has gained unprecedented salience in many Western democracies and has become central in 'climate elections'. However, climate salience fluctuates significantly over time, among party families, and across countries. Existing research primarily concentrates on the impact of green parties and is based on case studies or manifestos. Despite significant contributions, there is a gap in systematically assessing what is driving the variation of climate salience in party communication beyond electoral campaigns. The paper presents the results of a comparative study on the impacts of events and party characteristics on party communication at a fine-grained level. Empirically, I rely on a corpus of 3 million tweets from main political parties in 12 European countries from 2010 to 2022. After translating the entire corpus into English, I trained a supervised machine learning classifier to detect the presence of content related to climate change in these tweets. A measure of climate salience is then operationalized as the share of a party's tweets related to climate change at the monthly level. Panel data analysis shows that climate salience is highly variable over time and that climate protests and COPs are important drivers of party attention to climate change. The study makes a contribution by providing a new fine-grained measure of climate change in party communication and by emphasizing the effect of particular events on party attention to climate change.","Discipline":"political science","keywords":"climate politics ; party politics ; supervised learning","approach":"supervised machine learning","data":"Twitter data from 12 European countries","issue":"climate change communication in political parties","geofocus":"Europe","Corresponding Author":"Malo Jan","chair":"Johannes B. Gruber,","discussant":"Christian Pipal","time":"Friday, 11:15-12:45"},{"slot":"Day1_2","session_title":"Political Visual Communication in Europe","session":2,"id":15,"session_meansim":48966,"Title":"Gateway into Politics: Hidden Ideological Signals in TikTok","authors":"Natalia Umansky; Christian Pipal; Mariken van der Velden","full_text":"Gateway into Politics: Hidden Ideological Signals in TikTok\n\nThis paper explores the implications of incidental exposure to political content through these challenges and its potential impact on the political views of individuals. The inherent challenge lies in the captivating nature of TikTok content, where entertainment takes precedence. Users often follow these challenges for their entertainment value, thereby creating a pathway for incidental exposure to political content. Through the presence of ideological cues—ranging from symbols like the rainbow flag to representations of polarizing subjects such as guns—these challenges become a subtle vehicle for the transmission of political messaging. We contend that these cues within entertaining content have the potential to shape the political views of followers, especially those who are politically disengaged or inattentive. The mechanism at play is akin to the well-documented influence of self-perception and well-being, where subtle cues and environmental factors subtly mold one's beliefs and attitudes. We use an original dataset of 2500 TikTok videos posted by U.S. social media influencers in the health and gaming niche, and code them for political cues using a multimodal annotation pipeline. In particular, we separate the visual from the textual, and scale the visual political cues within the ideological spectrum. By examining the impact of these cues on their followers, comments, and subsequent sharing patterns, the paper aims to provide insights into the subtle yet significant role that entertainment-centric platforms play in shaping political ideologies.","keywords":"social media; multimodal communication; computer vision","approach":"content analysis","data":"TikTok videos","issue":"political messaging on TikTok","geofocus":"US","Corresponding Author":"Christian Pipal","chair":"Johannes B. Gruber,","discussant":"Christian Pipal","time":"Friday, 11:15-12:45"},{"slot":"Day1_2","session_title":"Political Visual Communication in Europe","session":2,"id":14,"session_meansim":48966,"Title":"Short-Form, Broad Reach: Multimodal Political Communication on TikTok","authors":"Natalia Umansky; Johannes Gruber; Jason Greenfield; Christian Pipal; Aleksandra Urman","full_text":"Short-Form, Broad Reach: Multimodal Political Communication on TikTok\n\nIn the rapidly evolving digital landscape, TikTok has emerged as a significant platform for political discourse. Using an original dataset of over 20,000 TikTok videos posted by official political party accounts across Europe, we employ multimodal methods leveraging the audio, visual, and text data included in each video to identify the various strategies deployed by these parties to connect to new audiences. Our study not only underscores TikTok's emerging role in political communication but also offers insights into how digital strategies are being aligned with ideological and demographic factors. Our findings contribute to the broader understanding of how novel digital platforms are being leveraged by political entities across Europe to foster enhanced engagement and broaden their electoral appeal.","keywords":"social media; multimodal communication; computer vision","approach":"multimodal analysis","data":"TikTok videos","issue":"political communication on TikTok","geofocus":"Europe","Corresponding Author":"Johannes B. Gruber,","chair":"Johannes B. Gruber,","discussant":"Christian Pipal","time":"Friday, 11:15-12:45"},{"slot":"Day1_2","session_title":"Political Visual Communication in Europe","session":2,"id":94,"session_meansim":48966,"Title":"The TikTok EuroParty database: Analyzing Political Party Activity on TikTok across 30 European Countries","authors":"Johannes B. Gruber, Natalia Umansky, Aleksandra Urman, Christian Pipal, Jason Greenfield","full_text":"The TikTok EuroParty database: Analyzing Political Party Activity on TikTok across 30 European Countries\n\nDespite its rapid global growth, with a current user base of 26% of the population six years after its launch (Reuters 2023), and a predominant presence among younger audiences (38% of users aged 18 to 24), research on TikTok lags behind established platforms like X (formerly Twitter) and Facebook. This discrepancy may be attributed to three key factors, which we address with this contribution: (1) a lack of familiarity with the platform leading to the assumption of a dearth of political content, (2) limited knowledge on processing the platform's multimodal content, and (3) restricted data access.\nWe introduce a dataset focusing on political content, encompassing all posts from all political parties that currently have a seat in one of 30 European countries (20,802 videos by 123 accounts). Our dataset consists of post URLs, metrics (such as like, share and watch counts), information about the accounts, linked to the ParlGov dataset on political parties (Döring et al., 2022), as well as automatically transcribed and translated audio. As TikTok only recently started to offer an API for researchers in Europe, and since this API offers only very limited access to data, the dataset was created using a combination of web-scraping and accessing the “hidden” API that is used by the website tiktok.com for search, access, and post playback. While acknowledging the inherent instability of this approach, we provide a detailed description to guide future researchers in applying similar techniques for data extraction on TikTok or other platforms.","Discipline":"Political Communication","keywords":"TikTok, data, social media","approach":"multimodal analysis","data":"TikTok posts by political parties in 30 European countries","issue":"political activity on TikTok","geofocus":"Europe","Corresponding Author":"Johannes B. Gruber,","chair":"Johannes B. Gruber,","discussant":"Christian Pipal","time":"Friday, 11:15-12:45"},{"slot":"Day1_3","session_title":"Exploring Norms and Power Dynamics","session":28,"id":9,"session_meansim":33611,"Title":"Gendern Mainstreaming? Analysing the Use of Gender-conscious Language by Austrian MPs","authors":"Mariia Tepliakova","full_text":"Gendern Mainstreaming? Analysing the Use of Gender-conscious Language by Austrian MPs\n\nWhile research on opposition to gender and sexual rights has expanded rapidly, the exact nature of the anti-gender backlash remains a subject of contention. Scholarship addressing topics from same-sex marriages to reproductive rights demonstrate their extreme context dependence, often involving diverse actors with distinct historical roots. One context-specific illustration pertains to gendern in German-speaking countries, a gender-conscious language use aiming to express equal treatment for all individuals. While research on the adoption of gender-conscious language by both German MPs and media outlets has advanced, little is known about the behaviour of Austrian counterparts. This became more pressing as the Lower Austrian branch of FPÖ, following an electoral victory, announced its intent to impose Genderverbot on local government, aiming to eliminate gender-neutral language forms in official documents and publications. Given that far-right elements can influence mainstream politics and compromise gender equality, this policy raises significant questions about its implications. This study seeks to explore the use of gender-sensitive language in Austrian politics, examining the actors employing such linguistic strategies and the contexts in which they are applied. Employing quantitative text analysis, which incorporates a pioneering “gendered” R package, this study examines the usage of gender-conscious language by Austrian MPs when discussing both gender-related and mainstream topics in Nationalrat from 2009 to 2019.","Discipline":"Political Science; Gender Studies","keywords":"quantitative text analysis; gender; parliamentary speeches; gender-sensitive language; Austria","approach":"quantitative text analysis","data":"Nationalrat debates","issue":"use of gender-conscious language by Austrian MPs","geofocus":"Austria","Corresponding Author":"Mariia Tepliakova","chair":"Mariia Tepliakova","discussant":"Jaroslaw Kantorowicz","time":"Friday, 13:30-15:00"},{"slot":"Day1_3","session_title":"Exploring Norms and Power Dynamics","session":28,"id":139,"session_meansim":33611,"Title":"More than words: the contestation of social normality and the problem of regime types in international relations","authors":"Federico Salvati","full_text":"More than words: the contestation of social normality and the problem of regime types in international relations\n\nA pressing issue among both scholars and policy-makers is the so-called ongoing contestation of the Liberal International Order (LIO). There is a widespread sensation among both groups that the LIO is going through a moment of profound crisis. Despite the lack of consensus on the origin of this crisis (Lake et al., 2021, Ikenberry, 2018, Jahn, 2018) it is widely accepted that numerous actors are demanding the reform of substantial sections of the international normative framework. Not all contesting actors can be classified as illiberal or opposed to the fundamental assumptions of the LIO (EG Simmer, 2023). Particularly significant however is the role that autocratic states play in the contestation. In the following paper, I am going to analyse how states generate and use socio-normative knowledge in the political debate in international politics. At the same time, I am going to concentrate on the debate about the distinctions between democratic and autocratic regimes, investigating possible differences (and the extant of these differences) in the way the two groups relate to international normativity.","Discipline":"International Relations","keywords":"Autocracy, International law, Liberal Order","approach":"normative analysis","data":"international political debate","issue":"contestation of social normality and regime types in international relations","geofocus":"global","Corresponding Author":"Federico Salvati","chair":"Mariia Tepliakova","discussant":"Jaroslaw Kantorowicz","time":"Friday, 13:30-15:00"},{"slot":"Day1_3","session_title":"Exploring Norms and Power Dynamics","session":28,"id":70,"session_meansim":33611,"Title":"The Changing Concepts of the Rule of Law","authors":"Jaroslaw Kantorowicz; Bastián González-Bustamante","full_text":"The Changing Concepts of the Rule of Law\n\nThis article analyses how the concept of the rule of law has changed over time in the parliamentary debates in the United Kingdom. Despite the importance of this concept, there remains a lack of an unequivocal definition. Indeed, scholarly debates have focused on different conceptualisations of the rule of law, which could be thicker, including, for example, human rights, or thinner by focusing on the quality of the legal system. We used Hansard’s corpora, which comprises about 11 thousand speeches held in both the Lords and Commons Houses that focused on the rule of law and constitutional issues between 1805 and 2020. These speeches enable us to evaluate the change in the concept of the rule of law in parliamentary discourse through a time-sensitive semantic analysis using word vectors. Our empirical strategy relies on the word embedding method, specifically a number of diachronic word2vec model implementations (e.g., times series models, chronologically trained ones, among others) in order to map the semantic relationships between some keywords associated with different conceptualisations of the rule of law over about 200 years in the UK.","Discipline":"comparative politics; politico-legal philosophy; empirical legal studie","keywords":"rule of law; word embedding; word2vec","approach":"word embedding analysis","data":"Hansard’s corpora","issue":"concept of the rule of law","geofocus":"United Kingdom","Corresponding Author":"Jaroslaw Kantorowicz","chair":"Mariia Tepliakova","discussant":"Jaroslaw Kantorowicz","time":"Friday, 13:30-15:00"},{"slot":"Day1_3","session_title":"Exploring Norms and Power Dynamics","session":28,"id":135,"session_meansim":33611,"Title":"The Targets of Data-Driven Messaging: How Political Campaigns use Facebook and Instagram to target and Tailor Digital Political Ads in Six Advanced Democracies","authors":"Vivien Fabry; Fabio Votta","full_text":"The Targets of Data-Driven Messaging: How Political Campaigns use Facebook and Instagram to target and Tailor Digital Political Ads in Six Advanced Democracies\n\nThis study examines the targeting and tailoring of political ads on Meta\nby investigating the congruency between messages and target audiences. By\nutilizing the Meta Ad Targeting dataset, we examine 800k political ads from 6k\nadvertisers in six advanced democracies: Germany, the Netherlands, the United\nStates, Canada, New Zealand, and Australia. In order to classify topics within\nthe messages of political ads we make use of cross-lingual contextualized topic\nmodels (Bianchi et al. 2021).\nThe study finds a significant overlap between the content of digital polit-\nical advertisements and target audiences. The research reveals that political\nadvertisements often concentrate on key issues owned by the parties and that\ntargeting strategies employed in these digital ads are closely aligned with the\nsocio-demographics of each party’s primary voter base.\nThe insights gained from this study shed light on the intricate interplay\nbetween the tailoring of political messaging and the targeted delivery of these\nmessages through social media platforms. This nuanced understanding is crucial\nfor comprehending how political communication is being shaped in the digital\nage.","Discipline":"Political Communication","keywords":"topic models; microtargeting; political communication","approach":"cross-lingual contextualized topic models","data":"Meta Ad Targeting dataset","issue":"targeting and tailoring of digital political ads","geofocus":"6 advanced democracies (Germany, the Netherlands, the United States, Canada, New Zealand, and Australia)","Corresponding Author":"Fabio Votta","chair":"Mariia Tepliakova","discussant":"Jaroslaw Kantorowicz","time":"Friday, 13:30-15:00"},{"slot":"Day1_3","session_title":"Exploring Norms and Power Dynamics","session":28,"id":56,"session_meansim":33611,"Title":"Trans*rights and their Moralization: Analyzing Ten Years of Trans*debates in the US","authors":"Maryana Balezina","full_text":"Trans*rights and their Moralization: Analyzing Ten Years of Trans*debates in the US\n\nSome have deemed recent developments in public trans* rights debates a “moral panic” and have argued that trans* rights issues are establishing themselves to be a new wedge issue in the US. Trans* rights, however, have been actively contested within legal institutions since the early 90s, and current observations about discourse development are limited to qualitative works. This paper aims to provide a quantitative look at the developments of trans* rights debates in the US. Specifically, it asks whether a) trans* debates became more moralized; b) parties underline the same moralized notion but use them in a different context. Using QTA methods (dictionary and word embeddings), I trace the use of moralized language within the last 10 years of US Senate debates. In line with recent scholarship on morality politics, the results indicate that parties tend to use similar moral notions (foundations), but they differ in who these moral notions target. The research is of interest to gender politics and morality politics scholars as it indicates the use of specific moralization elements (words and contents) across a large textual corpus.","keywords":"Quantitative; LGBTQI; USA","approach":"quantitative text analysis","data":"US Senate debates","issue":"moralization of trans* rights","geofocus":"US","Corresponding Author":"Maryana Balezina","chair":"Mariia Tepliakova","discussant":"Jaroslaw Kantorowicz","time":"Friday, 13:30-15:00"},{"slot":"Day1_3","session_title":"German Political Discourse Analysis Panel","session":3,"id":59,"session_meansim":41208,"Title":"Detection of Deliberation – Evaluating a Costume BERT Model for German Online Discussions","authors":"Anke Stoll; Lena Wilms; Marc Ziegele","full_text":"Detection of Deliberation – Evaluating a Costume BERT Model for German Online Discussions\n\nIn social science deliberation is a key concept to analyze online discussions from the angle of democratic theory. The framework of deliberation suggests that in a public sphere, citizens should discuss issues of social and political relevance in a rational, reciprocal, and respectful way (Dahlberg, 2001; Fraser, 1990; Habermas,1996). However, current research in machine learning and computational social science have focused on the detection of harmful content (e.g., incivility). Hence, studies that classify deliberative comments with computational methods are rare.\nIn this paper, we present and evaluate the first model to detect deliberation in German-language online discussions. We fine-tuned a pre-trained German BERT model (Bidirectional Encoder Representations from Transformers, Devlin et al., 2018) on 14,000 manually labeled user comments from news comment sections and participation platforms using crowd annotation. In the coding instructions, deliberative quality is operationalized as contributions that are enriching and valuable to a discussion, such as comments that add arguments, suggestions, or new perspectives to the discussion, or are otherwise helpful, stimulating or appreciative. Results show that the model classify deliberative comments successfully with an accuracy of 0.86 percent (macro average f1-score= 0.86; precision= 0.84; recall= 0.87). Yet, in-depth evaluation revealed potential bias. For example, primarily higher educated annotators share a common understanding of deliberative contributions.\nDuring the presentation, we will focus on potential applications and limitations of the deliberation model and derive overall challenges for machine learning approaches to measure deliberative quality.","Discipline":"Computational Communication Science","keywords":"Deliberation; Machine Learning; Bias","approach":"BERT model","data":"German online discussions","issue":"detection of deliberation","geofocus":"Germany","Corresponding Author":"Anke Stoll","chair":"Christopher Klamm","discussant":"Anke Stoll","time":"Friday, 13:30-15:00"},{"slot":"Day1_3","session_title":"German Political Discourse Analysis Panel","session":3,"id":93,"session_meansim":41208,"Title":"Echoes of the Reichstag? Decoding Populist Rhetoric Across Eras","authors":"Patrick Schwabl; Sean Palicki; Burint Bevis; Clint Claessen","full_text":"Echoes of the Reichstag? Decoding Populist Rhetoric Across Eras\n\nAlthough populist statements are usually bound to current societal challenges, populist rhetoric from the 1920s to the modern day exhibits similarities. Taggart (2000, p. 8) described this as the “chameleonic quality of populism,” where one has to differentiate between what are its “environmental and what are its essential features.” In other words, history may not repeat itself, but it rhymes. For example, populist representation today is again above 30% in Europe (Van Kessel et al., 2023). We argue that analyzing parliamentary speeches over time allows us to answer the question: What meta-structures of populist rhetoric persist across eras?\n\nWe analyze political discourse, using word embeddings to describe the language used by populist parties in the Reichstag (1924-1942) and compare it with modern populist party rhetoric in the German Bundestag (2009-2021). Central to our analysis is the exploration of key terms such as \"Lügenpresse\" (Engl. Fake news) to trace semantic shifts of populist rhetoric over time (Rodman, 2020). Focusing on the political lexicon of the early 20th century, we first examine how populist parties employ specific phrases to propagate ideologies. We then investigate parallels to contemporary political discourse, identifying similarities and differences in how populists use words to display themselves as the lawyer of the people and attack the political establishment.\n\nBy processing digitized Reichstag protocols from the Bavarian State Library (N = 122,580 pages) and data from the German Bundestag API, we analyze word vectors and their nearest neighbors to provide a computational perspective for understanding the dynamics of populist rhetoric. By identifying archetypal elements in populist discourse that transcend party boundaries and time, our research contributes new empirical evidence to understand populism.\n\nReferences\nRodman, E. (2020). A Timely Intervention: Tracking the Changing Meanings of Political Concepts with Word Vectors. Political Analysis, 28(1), 87–111. https://doi.org/10.1017/pan.2019.23\nTaggart, P. A. (2000). Populism. Open Univ. Press.\nVan Kessel, S., De Lange, S., Taggart, P., Rooduijn, M., Halikiopoulou, D., Pirro, A., Froio, C., & Mudde, C. (2023). The PopuList 3.0. https://doi.org/10.17605/OSF.IO/2EWKQ","Discipline":"Political Science; Communication; Computational Social Science","keywords":"word embeddings; populism; Reichstag; Bundestag; Germany","approach":"word embeddings","data":"parliamentary speeches","issue":"persistent features of populist rhetoric across eras","geofocus":"German Reichstag (1924-1942) and modern German Bundestag (2009-2021)","Corresponding Author":"Patrick Schwabl","chair":"Christopher Klamm","discussant":"Anke Stoll","time":"Friday, 13:30-15:00"},{"slot":"Day1_3","session_title":"German Political Discourse Analysis Panel","session":3,"id":19,"session_meansim":41208,"Title":"Lasting impressions: Assessing the public perception of droughts in Germany using word embeddings","authors":"Jan Sodoge; Taís Maria Nunes Carvalho; Christian Kuhlicke; Mariana Madruga de Brito","full_text":"Lasting impressions: Assessing the public perception of droughts in Germany using word embeddings\n\nRecent droughts have imposed severe and unprecedented impacts across Europe and are expected to escalate in frequency and magnitude. While there are analyses of droughts' biophysical and economic impacts, large-scale and quantitative assessments of their public perception remain underexplored. Assessing drought’s public perception is important for understanding how society reacts to such extreme events. It can also support the design of effective communication strategies to address their risks. Here, we investigate how word embeddings can inform the analysis of spatio-temporal patterns of droughts’ perception. Utilizing 1.1 million drought-related newspaper articles from 250 German newspapers between 2000 and 2022, we calculate word embeddings to model the contexts in which drought is described. We estimate the perception by comparing the word embeddings of 'drought' to key indicative terms. These terms reflect on relevant concepts such as ‘risk’ and ‘resilience’ or affected sectors such as ‘forestry’ or ‘agriculture’. These patterns are then correlated with drought indices to examine how extreme drought events affect public perception. Our results reveal that drought events prompted non-linear shifts in perception in Germany, highlighting nuances that contemporary methods, such as internet search behavior fail to capture. Also, our findings underscore the multi-faceted perception of drought events: differences between affected sectors, increasing risk awareness, and a shift from foreign drought events to national impacts. The methodologies suggested here can inform social dynamic models for hydrological extremes, enhance understanding of societal responses to drought risks, and aid in quantifying biases in news coverage for socio-economic drought impact assessments.","Discipline":"geography; sociology","keywords":"word embeddings, drought event, newspaper, extreme events","approach":"word embeddings","data":"newspaper articles","issue":"public perception of droughts in Germany","geofocus":"Germany","Corresponding Author":"Jan Sodoge","chair":"Christopher Klamm","discussant":"Anke Stoll","time":"Friday, 13:30-15:00"},{"slot":"Day1_3","session_title":"German Political Discourse Analysis Panel","session":3,"id":58,"session_meansim":41208,"Title":"Populism and party positions: Evidence from Twitter (Work in Progress)","authors":"Nikola Noske; Anna Kerkhof; Helmut Rainer, Johannes Renz","full_text":"Populism and party positions: Evidence from Twitter (Work in Progress)\n\nSupport for right-wing populist parties has surged in Europe over the past decade, raising concerns about the impact of their rhetoric strategies on democratic discourse. Our project focuses on the case of Germany's Alternative for Germany (AfD), especially after Frauke Petry's election as party leader in July 2015, which marked a sudden and unexpected shift to the right in the party's position. Using tweets from German Bundestag members between 2012 and 2019, we analyze changes in topics, emotional tone, and political positioning. To disentangle the AfD's impact from general developments in language, we employ a difference-in-differences approach. We hypothesize that right-leaning parties, like the Christian Democratic Union (CDU) adjust their positions while left-leaning parties, such as the Social Democrats (SPD) or the Greens, face less pressure to do so. Our study diverges from previous research by analyzing social media data, providing a direct view of popular speech. Instead of focusing on election results, we examine how a party's leadership change influences political discourse. To disentangle the AfD's impact from other factors, we plan to employ a BERT model predicting party affiliations from tweets. We anticipate that the AfD's shift leads to an increase in false positive predictions for political right parties as AfD, indicating linguistic influence. Our analysis focuses on the thematic and emotional aspects of tweets. Additionally, we construct a two-dimensional policy grid to position parties along a \"left-right\" spectrum and a \"populism\" axis. This novel approach will help us assess whether parties' positions have shifted due to the AfD's consolidation on the far right, offering insights into the evolution of political ideologies in Germany.","Discipline":"Economics","keywords":"Populism; BERT; Twitter","approach":"BERT model","data":"tweets from German Bundestag members","issue":"populism and party positions","geofocus":"Germany","Corresponding Author":"Nikola Noske","chair":"Christopher Klamm","discussant":"Anke Stoll","time":"Friday, 13:30-15:00"},{"slot":"Day1_3","session_title":"German Political Discourse Analysis Panel","session":3,"id":114,"session_meansim":41208,"Title":"Should We Stop Fine-Tuning BERT? The Benefits of In-Context Learning on Analyzing Group Mentions and Appeals in German Parliamentary Debates","authors":"Christopher Klamm; Ines Rehbein; Simone Ponzetto","full_text":"Should We Stop Fine-Tuning BERT? The Benefits of In-Context Learning on Analyzing Group Mentions and Appeals in German Parliamentary Debates\n\nQuestions have been raised about the need for fine-tuning BERT on specific tasks given the powerful Large-Language Models (LLMs) introduced recently and their ability for in-context learning. In this study, we compare in-context learning and fine-tuning based on closed and open-source models on the task of classification of group mentions and appeals in German parliamentary debates. Our analysis is based on our novel dataset of parliamentary debates with over 10,000 annotations from 196 different speakers across six German parties from 2017 to 2021. This dataset includes mention types and roles, allowing the analysis of negative and positive stances towards the mentioned groups in the text. Combining LLMs with in-context learning can result in significant benefits compared to fine-tuning BERT with equivalent accuracy. In-context learning is a technique where the model is not fine-tuned but is enriched with context using a set of examples and a task description provided in the prompt. We show that this method can be used for zero- or few-shot learning tasks with a highly reduced need for coded samples, providing a simpler approach. Mitchell et al. (2023) proposed a novel approach of merging the knowledge learned from a small fine-tuned (BERT) model to LLMs with billions of parameters, without fine-tuning the large model for a specific task. We examine whether this new paradigm can combine the advantages of both worlds, especially for political science researchers with limited resources, or if fine-tuning BERT is still the best option for highly customized tasks such as analyzing group mentions.","Discipline":"computational methods; NLP; ML","keywords":"in-context learning, group mentions, parliamentary debates, LLMs, open-source","approach":"in-context learning","data":"German parliamentary debates","issue":"classification of group mentions and appeals","geofocus":"Germany","Corresponding Author":"Christopher Klamm","chair":"Christopher Klamm","discussant":"Anke Stoll","time":"Friday, 13:30-15:00"},{"slot":"Day1_3","session_title":"Multilingual Text Analysis Panel","session":25,"id":41,"session_meansim":25124,"Title":"Application of Machine Learning in Judicial Outcome Classification","authors":"Siyun Jiang","full_text":"Application of Machine Learning in Judicial Outcome Classification\n\nHow can machine learning help classify court decisions? Coded information is often not provided by nondemocratic courts along with their judgments. This paper discusses the use of unsupervised learning models in the analysis of bilingual judgments. It uses latent dirichlet allocation, word vector summaries, and the BERT model on 25,000 appeal cases released by the Judiciary of Hong Kong to extract document-level topic proportions and transfer-learning-based features. It then uses the features to classify the appeal outcomes and compares the models' performance in classification. The paper also estimates the impact of judges’ ethnicity on the coded appeal outcomes. The paper demonstrates how political scientists can obtain previously unavailable information about nondemocratic courts with the help of machine learning techniques.","Discipline":"Political Science","keywords":"Unsupervised learning, court, transparency","approach":"unsupervised learning","data":"bilingual judgments from Hong Kong Judiciary","issue":"classification of court decisions","geofocus":"Hong Kong","Corresponding Author":"Siyun Jiang","chair":"Siyun Jiang","discussant":"Stefan Müller","time":"Friday, 13:30-15:00"},{"slot":"Day1_3","session_title":"Multilingual Text Analysis Panel","session":25,"id":121,"session_meansim":25124,"Title":"Investigating the Impact of Fake News Content Characteristics on Readers’ Credibility Perceptions","authors":"Noelle Lebernegg, Petro Tolochko, Hajo Boomgaarden","full_text":"Investigating the Impact of Fake News Content Characteristics on Readers’ Credibility Perceptions\n\nThe purported surge in false information is frequently attributed to the advent of digital media, facilitating the creation and dissemination of deceptive and inaccurate content, commonly referred to as \"fake news.\" In an effort to empower consumers to discern genuine from misleading information, individuals are advised to exercise caution when encountering certain content characteristics typically avoided in professional journalism. That is, for instance, subjective information or polarizing elements (e.g., click-bait headlines, sensationalism, emotional components, and syntactic cues like the excessive use of all-capitalized terms or punctuation signs). Despite such guidance, a gap persists in understanding how these linguistic and stylistic characteristics impact the perceived credibility. Consequently, this study seeks to investigate the influence of content traits commonly associated with fake news on audience perceptions of credibility. Employing an experimental design, participants will be tasked with evaluating the credibility of both genuine and fake news articles that exhibit varying degrees of a comprehensive selection of content characteristics. To mitigate potential confounding variables related to specific topics or sources, a diverse array of articles (N ~ 6000) with removed origin information will be utilized as stimuli material. The findings of this research hold the potential to inform media literacy interventions and content verification strategies and contribute to the development of effective measures to counteract the spread and acceptance of false information, thereby fostering a more informed and discerning public that is better equipped to navigate the complex landscape of digital information.","Discipline":"Communication Science","keywords":"fake news, credibility perceptions, content characteristics","approach":"content analysis","data":"articles with various content characteristics","issue":"credibility perceptions of fake news","geofocus":"general","Corresponding Author":"Noelle Lebernegg","chair":"Siyun Jiang","discussant":"Stefan Müller","time":"Friday, 13:30-15:00"},{"slot":"Day1_3","session_title":"Multilingual Text Analysis Panel","session":25,"id":5,"session_meansim":25124,"Title":"Sampling from Gold: Comparing sampling text vignettes with expert surveys to assess internal validity in a multilingual context","authors":"Christine Sylvester; Zachary Greene","full_text":"Sampling from Gold: Comparing sampling text vignettes with expert surveys to assess internal validity in a multilingual context\n\nScholars rarely have gold-standard benchmarks to compare estimates from computational models. Existing multilingual approaches leverage the wealth of specialized data originally designed to fit other purposes to come up with some measure of internal validity. These approaches require the assumption that texts under study derive from the same data-generating process as the comparison data. Expert survey estimates or other forms of non-case specific data allow differing information to enter the data generation process such as individual’s perceptions or the broader climate and come at intervals that limit over-time comparisons becoming magnified in a multilingual setting with limited training or validation data. We propose a solution to generating meaningful benchmarks for validation that can be used across multilingual contexts. We create sampled text representations of major actors across multiple dimensions. We apply this approach to compare the predictive accuracy of established measures of party and individual positions. To illustrate the approach, we use estimates of party issue positions derived from a set issue-level scaling models in eight countries from five languages to construct textual sampling vignettes for each party. We select 10-sentence samples drawing from the policy area, party and election window. Trained coders rank vignettes on an 11-point scale, comparable to the scale used by CHES. We compare results from our analysis with specific position estimates from coded vignettes versus expert surveys measuring parties’ issue positions. We expect that our measures outperform existing surveys. Following a statistical sampling-based approach, our method can easily be adapted to a myriad of settings.","keywords":"multilingual text analysis; benchmarks; vignettes; expert surveys","approach":"sampling text vignettes","data":"textual representations of major actors","issue":"internal validity in multilingual context","geofocus":"eight countries from five languages","Corresponding Author":"Zachary Greene","chair":"Siyun Jiang","discussant":"Stefan Müller","time":"Friday, 13:30-15:00"},{"slot":"Day1_3","session_title":"Multilingual Text Analysis Panel","session":25,"id":155,"session_meansim":25124,"Title":"Speeches to Interventions: Forecasting Scalar UN Peacekeeping Deployments from UN General Assembly Debates and Historical Intervention Data","authors":"Alvan Caleb Arulandu; Brian Zhou","full_text":"Speeches to Interventions: Forecasting Scalar UN Peacekeeping Deployments from UN General Assembly Debates and Historical Intervention Data\n\nThe updated UN General Debate Corpus (UNGDC), cataloging every speech from the UN's inception in 1946 to 2022, is a treasure trove of national policy, as the UNGD is the only body where every country can speak. We propose a discourse-driven intervention forecasting framework that uses machine learning to categorize ongoing conflicts based on historical speech data at the UNGD to predict both a peacekeeping deployment and the magnitude of funds and forces that would be committed to addressing a conflict. We employ natural language processing techniques to tokenize, preprocess, and analyze word stem frequencies in the UNGDC, generating a time series of the number of UN mentions for any given country. Superimposed with historical analysis, we show that debate in the UNGDC is a potent indicator to determine UN intervention and response mechanisms for conflicts; further, by aggregating mention statistics across periods of active conflict, we provide quantitative backing for the correlation of mention dynamics and the presence of an active conflict, for a given country. Finally, we present and test an interpretable, shallow decision tree model that can perform intervention type classification and response magnitude recommendation with 91.7% accuracy. Our results, established by computational experiments and statistical testing, suggest that corpus analysis and broader computational diplomacy methods can drive intervention recommendations to improve the UN’s decision-making.","Discipline":"Computational linguistics, popular opinion/discourse, machine learning","keywords":"Computational diplomacy, conflict resolution, natural language processing, decision trees, political communication, diverse data sources","approach":"machine learning","data":"UN General Assembly debates","issue":"forecasting UN peacekeeping deployments","geofocus":"global","Corresponding Author":"Brian Zhou","chair":"Siyun Jiang","discussant":"Stefan Müller","time":"Friday, 13:30-15:00"},{"slot":"Day1_3","session_title":"Multilingual Text Analysis Panel","session":25,"id":37,"session_meansim":25124,"Title":"Understanding Grant Peer Review using Machine Learning","authors":"Alberto de León; Matthias Egger; Anne Jorstad; Katrin Milzow; Stefan Müller; Gabriel Okasa; Michaela Strinzel","full_text":"Understanding Grant Peer Review using Machine Learning\n\nThe peer-review process is central to academic research and research funding. Our study delves into the characteristics of the texts of grant peer review reports. Based on a unique text corpus of over 36,000 project funding reviews submitted to the Swiss National Science Foundation between 2016 and 2023, this paper addresses several essential questions: Conceptually, how can we assess peer review characteristics? Which features of a peer review report can be predicted with state-of-the-art, transformer-based machine learning classifiers? How do review characteristics differ across disciplines and reviewers’ backgrounds? And does the change in evaluation guidelines correlate with the characteristics of peer review texts? To study these questions, we first labelled a large random sample of review sentences across 14 predefined categories addressing specific topics such as strengths and weaknesses, methods, and the suitability or expertise of the applicant for the proposed research. After assessing inter-coder reliability, we fine-tuned and validated transformer models for each category. Extensive validation exercises reveal that machine learning classifiers can accurately predict many, but not all, predefined categories. We also find substantial differences across disciplines and based on reviewers’ backgrounds. Our study has implications for understanding the peer-review process in academic research and research funding. It demonstrates the potential of machine learning in assessing peer review characteristics, providing systematic insights into the ‘black box’ of grant peer review.","Discipline":"Political Science; Medicine; Mathematics and Statistics","keywords":"machine learning; transformers; peer review; research on research; quantitative text analysis","approach":"machine learning","data":"grant peer review reports","issue":"understanding peer review characteristics","geofocus":"Switzerland","Corresponding Author":"Stefan Müller","chair":"Siyun Jiang","discussant":"Stefan Müller","time":"Friday, 13:30-15:00"},{"slot":"Day1_3","session_title":"Policy Analytics Panel","session":24,"id":147,"session_meansim":38435,"Title":"Analyzing Party Competition on Climate Change: A Machine Learning Approach","authors":"Lukas Isermann; Noam Himmelrath; David Schweizer","full_text":"Analyzing Party Competition on Climate Change: A Machine Learning Approach\n\nClimate change is increasingly shaping party competition in Western Europe. Still, previous work has primarily examined environmental protection as a proxy for climate change. Few researchers have made the effort to manually code manifestos to map parties’ attention and positions towards the issue of climate change. Indeed, they have shown that climate change is a distinct issue cutting across traditional party lines and demonstrated the necessity of a reliable measure to analyze contemporary party competition. \nThis article addresses three important shortcomings. First, manual coding of manifestos is hard to replicate and requires many resources for future applications. Second, this approach is not feasible for analyzing political text appearing in higher frequency such as parliamentary speeches, press releases, or social media posts. Third, different conceptualizations complicate comparisons between the existing empirical evidence.\nWe aim to overcome these problems by developing a theoretically sound automated classification process. Following a supervised machine learning approach, we build several binary classifiers allowing us to detect the general topic of climate change, identify political actors’ overall position on climate protection and references to climate change mitigation or adaptation, and differentiate between political demands, blame attribution, and (self-)praise. In the first iteration, we fine-tune transformer models with annotated sentences from parliamentary speeches delivered in the German Bundestag.\nOur classifiers allow us and other researchers to study German party competition on climate change both in the short- and the long-term. In further iterations, we expand our scope by considering both additional languages and forms of political text.","Discipline":"Political Science","keywords":"Climate Change; Manifesto; Parliamentary Speeches","approach":"supervised machine learning","data":"parliamentary speeches","issue":"party competition on climate change","geofocus":"Germany","Corresponding Author":"Lukas Isermann","chair":"Denise J. Roth","discussant":"Daniel Schulte","time":"Friday, 13:30-15:00"},{"slot":"Day1_3","session_title":"Policy Analytics Panel","session":24,"id":54,"session_meansim":38435,"Title":"Automatic Coding of LGBTQI+ and Abortion Morality Issues in Central-Eastern Europe using the Factiva Newspaper Database","authors":"Daniel Schulte","full_text":"Automatic Coding of LGBTQI+ and Abortion Morality Issues in Central-Eastern Europe using the Factiva Newspaper Database\n\nMachine learning and AI offer promising ways to automate the coding of textual data. The Factiva Newspaper Database by Dow Jones Industrial offers newspaper coverage in over 32 languages and is a powerful tool for analyzing trends and distribution of media coverage of different political outcomes of interest. Central-Eastern European (CEE) languages included in the database are Bulgarian, Czech, Estonian, Hungarian, Latvian, Lithuanian, Polish, Romanian, Russian, Slovak, and Turkish. This project aims to develop algorithms (especially using basic media content analysis, Quanteda package in R, and ChatGPT 4.0) to automate the data collection, cleaning and coding required for categorizing the coverage of more than 30 different morality policy issue areas (especially focusing on LGBTQI+ rights and abortion) across the languages of Central-Eastern Europe. The creation of such a dataset using machine learning or AI would contribute to the study of morality in politics across a large number of political science literatures. This project would also help create a template for the automation of coding with Factiva for public policy scholars regardless of their particular sector. This project delves into the challenge of developing coding rules that are equivalent across the languages of the region especially in the domains of LGBTQI+ Rights and abortion rights. The paper discusses several tradeoffs in using different textual analysis techniques and methodological challenges in using Factiva. To discuss these tradeoffs and methodological challenges, the paper presents initial patterns and findings of party coverage of LGBTQI+ and abortion rights across the CEE region.","Discipline":"Political Science","keywords":"LGBTQI+ Rights, Abortion, Party Politics, Central Eastern Europe, quantitative textual analysis, Factiva, ChatGPT, morality policy","approach":"machine learning","data":"Factiva Newspaper Database","issue":"morality policy issues in Central-Eastern Europe","geofocus":"CEE languages (Bulgarian, Czech, Estonian, Hungarian, Latvian, Lithuanian, Polish, Romanian, Russian, Slovak, and Turkish)","Corresponding Author":"Daniel Schulte","chair":"Denise J. Roth","discussant":"Daniel Schulte","time":"Friday, 13:30-15:00"},{"slot":"Day1_3","session_title":"Policy Analytics Panel","session":24,"id":115,"session_meansim":38435,"Title":"Parties and the People – Why Do Parties Support Direct Democracy?","authors":"Sarah Engler, Lucas Leemann, Florian Schaffner","full_text":"Parties and the People – Why Do Parties Support Direct Democracy?\n\nDuring every crisis of representative democracy, there is a surge of demands for more direct forms of participation. Whether it is the populist movement at the end of the 19th century in the US or the Five Star Movement in current-day Italy – discontent with the representative system increases demands for alternative institutions. But what explains the position of the main actors in the formulation of these demands? We ask why political parties call for and/or support direct democracy. We provide two major motivations: ideology and strategy. Analyzing party manifestos of European parties from 1946 onward using a transformer-based machine learning classifier, we show how ideological motivations seem to account for most variation in party positions towards direct democracy. These results contribute to the literature on institutional origins and sheds light on the motivation of a central political actor, parties, when it comes to the introduction of direct democratic institutions.","Discipline":"Comparative politics; empirical democracy research; party strategies; direct democracy","keywords":"party manifestos; classification; transformer models","approach":"machine learning","data":"party manifestos","issue":"direct democracy","geofocus":"Europe","Corresponding Author":"Florian Schaffner","chair":"Denise J. Roth","discussant":"Daniel Schulte","time":"Friday, 13:30-15:00"},{"slot":"Day1_3","session_title":"Policy Analytics Panel","session":24,"id":35,"session_meansim":38435,"Title":"Targeted Hostility: Hateful Communication in YouTube Comments towards Journalists, Politicians, and Scientists","authors":"Denise J. Roth; Sanne Kruikemeier; Rens Vliegenthart","full_text":"Targeted Hostility: Hateful Communication in YouTube Comments towards Journalists, Politicians, and Scientists\n\nRecent empirical evidence attests that scientists, journalists, and politicians are frequently and increasingly targeted by online hate (O’Grady, 2022). Exposure to such extreme forms of threats and intimidation can have detrimental implications for individuals and society, such as fear, anxiety, and self-censorship (Väliverronnen & Saikkonnen, 2021). To date, we know little about specific variations in malicious communication online targeted at public figures. By analyzing YouTube comments collected with the official YouTube Data API (v3) from both Dutch and US channels, we aim to develop a new integrative theoretical model to better understand variations in malicious communication online. We argue that varying characteristics at the individual level of the targeted actor (e.g., age, gender, ethnicity, or political affiliation), the content-level (e.g., issue-type or communication style of online messages), and the context-level (e.g., cross-national differences) account for different degrees of hateful communication. \nAs one of the most widely used online platforms in the Netherlands and the US, YouTube comments offer a valuable window into public sentiment and interactions around specific content, making them an insightful source for studying the prevalence and dynamics of online hate speech directed at public figures (Thelwall, 2018). We plan to collect comments linked to videos from politicians, political parties, news channels, and research institutes. We will use word-embedding models to identify the content features and use supervised machine learning based on crowd-crowding to identify the frequency and forms of online malicious communication (Kroon et al., 2022). In subsequent steps, we plan to include data from various other social media sites, to account for platform differences.","Discipline":"Political Communication; Communication Science","keywords":"hate-speech detection; word-embeddings; supervised machine learning","approach":"supervised machine learning","data":"YouTube comments","issue":"hateful communication towards journalists","geofocus":"Netherlands and US","Corresponding Author":"Denise J. Roth","chair":"Denise J. Roth","discussant":"Daniel Schulte","time":"Friday, 13:30-15:00"},{"slot":"Day1_3","session_title":"Policy Analytics Panel","session":24,"id":7,"session_meansim":38435,"Title":"Who drives policy change? A Novel Machine Learning Approach for Mineral Policy Analysis","authors":"Felicia Robertson; Ahmed Elragal; Simon Matti; Annica Sandstrom","full_text":"Who drives policy change? A Novel Machine Learning Approach for Mineral Policy Analysis\n\nWho affects political decision-making and policy development is a central puzzle for political scientists to solve. Politicians and organized interest groups are known to affect political decisions, but research on the conditions and to what extent these actors interact and negotiate agreements regarding policy stability and change is still very limited. We ask \\textit{who initiates, drives, and determines when and how policies change?} To explain policy change, the paper combines state-of-the-art research within the political sciences with novel methodological techniques from data science research and predictive algorithms on mining policy change over time. We use machine learning techniques to collect data from official documents and written statements of coalitions’ actors between the years of 1990 and 2023. The paper contributes with a novel empirical approach and insights on policy process dynamics, develops new methods at the intersection of social sciences and AI algorithms, and generates theoretical knowledge about drivers and obstacles to disputed policy change.","Discipline":"Political science; Data science","keywords":"Public Policy; Policy Change; Sustainable Societal Transition; Natural Language Processing; Machine Learning","approach":"machine learning","data":"official documents and written statements","issue":"policy change","geofocus":"mining policy","Corresponding Author":"Felicia Robertson","chair":"Denise J. Roth","discussant":"Daniel Schulte","time":"Friday, 13:30-15:00"},{"slot":"Day1_4","session_title":"Global Governance Panel","session":21,"id":33,"session_meansim":41298,"Title":"Central Banking Under Pressure: A Textual Measure of Dominance and Coordination","authors":"Lauren Leek","full_text":"Central Banking Under Pressure: A Textual Measure of Dominance and Coordination\n\nMonetary policy has in many countries, both democratic and autocratic, been delegated -- to various degrees -- to institutionally independent central banks to protect them from political interference. Yet, monetary policy-making does not operate in a vacuum. The policy choices of the central bank are intricately linked to government policies, including its fiscal policy stance as well as its choices regarding financial market regulation. We present a novel, manually validated database of coordination efforts and central bank pressures of governments and financial markets, i.e., 'dominance', which allow us to map these inter-linkages in monetary-policy setting. Our database is based on textual data of speeches by 118 central bank officials worldwide since 1997 using multi-stage prompting of a Large Language Model (ChatGPT 3.5). Using this database, we find that financial pressures have been very prevalent across time, especially for autocratic and developing countries. In democratic countries fiscal pressures are very prevalent too.","Discipline":"Political Economy; Central Bank Communication","keywords":"Political economy; Large Language Models; Prompt crafting;","approach":"textual analysis","data":"speeches by central bank officials","issue":"coordination efforts and central bank pressures of governments and financial markets","geofocus":"worldwide","Corresponding Author":"Lauren Leek","chair":"Helena Heberer","discussant":"Robin J. Rentrop","time":"Friday, 15:15-16:45"},{"slot":"Day1_4","session_title":"Global Governance Panel","session":21,"id":28,"session_meansim":41298,"Title":"Drifting towards the East? An AI-supported analysis of the sentiment of Central-Eastern European parliaments towards great powers","authors":"Miklós Sebők; Levente Pakot; Orsolya Ring; Csaba Molnár; Ákos Holányi; István Üveges","full_text":"Drifting towards the East? An AI-supported analysis of the sentiment of Central-Eastern European parliaments towards great powers\n\nIn recent literature on Central-Eastern European politics, the development of the multipolar world order is shown to have undermined the strong pro-Western foreign policy consensus in the region as a number of political actors have voiced their desire to improve bilateral relations with rising Eastern powers. This paper aims to systematically analyse the extent and the nature of this possible foreign policy shift using text mining and machine learning methods on a corpora of parliamentary speeches from Croatia, Czechia and Hungary between 1994 and 2017. Using saliency and sentiment measures relating to Western and Eastern great powers, we demonstrate that there is a growing saliency towards Eastern powers in the 2010s without decreasing saliency towards Western powers with the exception of Czechia. Our findings suggest some degree of pragmatic rebalancing between the East and West instead of a new Eastern foreign policy orientation.","Discipline":"Political Science","keywords":"great powers, foreign policy, Central-Eastern Europe, text mining, sentiment, machine learning, legislative speeches","approach":"text mining and machine learning","data":"parliamentary speeches from Croatia","issue":"foreign policy shift towards Eastern great powers","geofocus":"Central-Eastern Europe","Corresponding Author":"Ákos Holányi","chair":"Helena Heberer","discussant":"Robin J. Rentrop","time":"Friday, 15:15-16:45"},{"slot":"Day1_4","session_title":"Global Governance Panel","session":21,"id":78,"session_meansim":41298,"Title":"The Communicative Power and Representation of Women","authors":"Helena Heberer; Chitralekha Basu","full_text":"The Communicative Power and Representation of Women\n\nHow much political power do women have in contemporary European democracies, and how well are their preferences represented by politicians? Moreover, how much does the improved descriptive representation of women in key political settings translate into their improved political representation in other respects? We build on recent work arguing that communicative power – or, the power to influence public opinion - is a key dimension of political power, and therefore, that “communicative representation”- or, how much speech by elite actors (such as legislators) reflects and responds to citizen opinion across issues - is an important component of political representation in democracies (Basu 2023). \n\nDrawing on this perspective, we assess the communicative power and representation of women, relative to men, in eight European parliamentary democracies in the 2010s by mapping the results of public opinion surveys to text data on legislative speeches. We base our evaluation on the representation of women’s preferences on eight policy areas, including issues where the gender gap in preferences is relatively understudied (like immigration). We also consider whether the preferences of women are better represented in speech by female legislators, and whether some women – based on their age, class or education – are better represented by women in power than others. In so doing, we adopt an intersectional perspective, taking seriously the impact of “multiple marginalization” on the communicative power and representation of some women.","keywords":"Representation; Gender; Political Communication","approach":"text analysis","data":"public opinion surveys and legislative speeches","issue":"communicative power and representation of women","geofocus":"eight European parliamentary democracies in the 2010s","Corresponding Author":"Helena Heberer","chair":"Helena Heberer","discussant":"Robin J. Rentrop","time":"Friday, 15:15-16:45"},{"slot":"Day1_4","session_title":"Global Governance Panel","session":21,"id":95,"session_meansim":41298,"Title":"The Spirit of Accommodation under threat? A Longitudinal Analysis of Belgian MPs’ Interactions in Parliamentary Speeches","authors":"Ward Peeters","full_text":"The Spirit of Accommodation under threat? A Longitudinal Analysis of Belgian MPs’ Interactions in Parliamentary Speeches\n\nA very important, but understudied, part of the consociational theory of Lijphart (1968) is that in divided societies stability can only be attained when at the elite level politicians replace their competitive attitude with a cooperative one. Some argue that in Belgium, once described as ‘one of the most thorough examples of consociational democracy’, this spirit of accommodation is under threat. Voters of the two main regions are increasingly growing further apart, there are almost no federal parties, and the political elites seem to live in their regional bubble. This makes it plausible that there is no more need to talk with the other region for the political elites. Adding to this debate, this paper measures whether this regionalization of politics has been trickled down to the parliamentary speeches of MPs in the federal parliament. It studies the interactions between MPs in their parliamentary speeches from 1962 till now. Do politicians predominantly address and interrupt politicians from their own language group? And how is this evolved over time? If MPs do not even interact with each other in the federal parliament, where politicians try to convince each other, leading to more consensual decisions, the spirit of accommodation could indeed be under threat.","Discipline":"Political Science; federalism; parliaments","keywords":"Parliamentary speeches; consociationalism; spirit of accommodation","approach":"longitudinal analysis","data":"Belgian MPs’ interactions in parliamentary speeches","issue":"regionalization of politics and the spirit of accommodation","geofocus":"Belgium","Corresponding Author":"Ward Peeters","chair":"Helena Heberer","discussant":"Robin J. Rentrop","time":"Friday, 15:15-16:45"},{"slot":"Day1_4","session_title":"Global Governance Panel","session":21,"id":25,"session_meansim":41298,"Title":"Who represents the interests of young voters? Substantive youth representation in Germany and the United Kingdom","authors":"Robin J. Rentrop","full_text":"Who represents the interests of young voters? Substantive youth representation in Germany and the United Kingdom\n\nThis paper aims to bridge a crucial gap in the existing research on youth’s political representation. It explores the research question whether young MPs are more likely to substantively represent issues important to young adults, and seeks to identify the conditions under which young MPs are more likely to engage in substantive youth representation. Prior research has delved into the causes of the descriptive youth underrepresentation, arguing that older parliaments negatively impact substantive youth representation. The current literature is relying on the implicit assumption that more young parliamentarians positively impact substantive youth representation. However, this claim remains untested. To this end, this paper analyses whether young MPs substantively represent youth interests in parliamentary speeches across a two-decade span in the legislative arenas of the UK and Germany. Grounded in the theory that descriptive and substantive representation are interconnected, I posit that an increased presence of young MPs should enhance overall representation of youth-specific interests. To empirically explore this, I employ a multilingual supervised token classification approach. The study utilizes a multilingual sample of hand-annotated speeches to train a supervised token-level classifier to automatically discern legislators' commitment to youth issues. Considering the nuanced influence of moderating factors on legislative behaviour, I also investigate whether youth representation is moderated by parties' electorate's age as well as MPs’ experience. Beyond contributing to the existing literature, this research not only tests a critical assumption but also has broader implications for understanding the intricate link between descriptive and substantive representation, particularly concerning youth.","Discipline":"political science","keywords":"youth representation; parliamentary speeches, supervised machine learning","approach":"supervised token classification","data":"parliamentary speeches","issue":"substantive representation of young voters","geofocus":"Germany and UK","Corresponding Author":"Robin J. Rentrop","chair":"Helena Heberer","discussant":"Robin J. Rentrop","time":"Friday, 15:15-16:45"},{"slot":"Day1_4","session_title":"Political Discourse Analysis Panel","session":17,"id":81,"session_meansim":1,"Title":"Expanding Your Vocabulary: Topic Integration Combining Automation and Human Expertise","authors":"Roy Gardner; Matthew J Martin; Ashley M Moran; Andrés Cruz; Guillermo Perez; Zachary Elkins","full_text":"Expanding Your Vocabulary: Topic Integration Combining Automation and Human Expertise\n\nTopic discovery and integration are essential to keep vocabularies—the set of concepts underlying a textual corpus—relevant. New topics come from a number of sources, including recent additions to a corpus, reconceptualizations of a domain, or concepts from other domains. We present a methodology that combines automation and human expertise to assess candidate topics. To develop the methodology we used a vocabulary created by the Comparative Constitutions Project (CCP) that tracks more than 330 topics within a corpus of national constitutions. The methodology enables users to formulate candidate topics that comprise grammatically well-formed labels and descriptions. A sentence-level semantic similarity model is used to search for constitution sections that are similar in meaning to a topic, provided the topic is not similar in meaning to any existing topic. Search results are output as a CSV file in which users identify the constitution sections that best match the meaning of the topic. Domain experts collaborate on the design of topics by iteratively refining the topic formulation until it captures all applicable sections. A panel of scholars then decides whether to accept topics into the CCP vocabulary, after which matching constitution sections are automatically tagged with accepted topics. Using our methodology, several new topics have been added to the CCP vocabulary, some of which we use here to illustrate our process and results. The methodology provides researchers with a systematic way to expand existing vocabularies.","Discipline":"Political Science; Social Science","keywords":"topic integration; vocabularies; constitutions","approach":"topic integration","data":"constitution sections","issue":"expanding vocabulary","geofocus":"national constitutions","Corresponding Author":"Roy Gardner","chair":"Roy Gardner","discussant":"Lucienne Engelhardt","time":"Friday, 15:15-16:45"},{"slot":"Day1_4","session_title":"Political Discourse Analysis Panel","session":17,"id":65,"session_meansim":41226,"Title":"Polarising the “Christian West”: “Us” and “Them” in Populist Radical Right Parties’ Rhetoric","authors":"Lucienne Engelhardt","full_text":"Polarising the “Christian West”: “Us” and “Them” in Populist Radical Right Parties’ Rhetoric\n\nAffective polarisation is on the rise in many democracies. At the same time, populist radical right parties (PRRPs) are often seen as a driver of affective polarisation. Yet, we know little about how these parties link Christian narratives to ingroup-outgroup dynamics. This is remarkable as PRRPs frame their political discourse in religious terms by referring to countries’ Christian-shaped heritage despite having, at least in the European context, a predominantly non-religious electorate. This study addresses these strategic references by examining the Christianity-related rhetoric in the political communication of PRRPs in comparison to the way Christian Democratic parties refer to Christianity. I argue that PRRPs emphasise intergroup dynamics by using religious references in an exclusionary way. To do so, I consider potential differences in the context in which these connotations are used by PRRPs vis-à-vis Christian Democratic parties.\nUsing data from ParlSpeech V2, I focus on parliamentary speeches given by politicians from PRRPs and Christian Democratic parties in seven European countries. Methodologically, I conduct automated text analysis relying on a transformer-based approach. I apply a pre-trained and then fine-tuned model to identify religious connotations and their co-occurrence with types of inclusive-exclusive rhetoric. Insights from my analysis contribute to a cross-national and between-party understanding of the rhetoric around Christianity, shedding light on PRRPs’ linkage of religious references to group dynamics.","keywords":"Polarisation; group dynamics; populist radical right parties; Christianity","approach":"automated text analysis","data":"parliamentary speeches from PRRPs and Christian Democratic parties in seven European countries","issue":"polarisation and ingroup-outgroup dynamics in populist radical right parties","geofocus":"Europe","Corresponding Author":"Lucienne Engelhardt","chair":"Roy Gardner","discussant":"Lucienne Engelhardt","time":"Friday, 15:15-16:45"},{"slot":"Day1_4","session_title":"Political Discourse Analysis Panel","session":17,"id":46,"session_meansim":41226,"Title":"The Internet’s Role in the Rise of Conspiracy Theories: Insights from Media Coverage","authors":"Maël Kubli; Emma Hoes","full_text":"The Internet’s Role in the Rise of Conspiracy Theories: Insights from Media Coverage\n\nOur study investigates the relationship between the internet’s evolution and the way and extent to which the media has covered conspiracy theories, additionally shifting the focus from psychological factors to analyzing media narratives. Covering the period from 1990 to 2022, we delve into how the advancement from Web 1.0 to 3.0 has influenced the depiction and discourse of conspiracy theories in newspapers across Switzerland, Germany, and the USA. Our methodology is threefold: Firstly, we establish a timeline to track the frequency of conspiracy theory mentions in various ideologically diverse, reputable newspapers, providing a longitudinal view of their presence in public media. Secondly, we analyze the framing of these theories in the news, observing how the narrative has shifted alongside technological advancements. Lastly, we identify fundamental conspiracy theories that have persisted or emerged over this period, compiling a comprehensive list of related keywords for analysis. This study aims to bridge the gap in existing research by offering insights into whether the evolution of the internet is associated with an increase of coverage about conspiracy theories. By dissecting media coverage of these theories over three decades, we seek to understand both the prevalence and the portrayal of conspiracy theories in the era of digital information and global connectivity.","Discipline":"Political Science; Communication Science","keywords":"Conspiracies, Computational Methods, Bertopic,","approach":"content analysis","data":"newspapers across Switzerland","issue":"role of internet in rise of conspiracy theories","geofocus":"Switzerland, Germany, and the US","Corresponding Author":"Maël Kubli","chair":"Roy Gardner","discussant":"Lucienne Engelhardt","time":"Friday, 15:15-16:45"},{"slot":"Day1_4","session_title":"Political Discourse Analysis Panel","session":17,"id":10,"session_meansim":41226,"Title":"The mobilizing effect of class appeals on the new and old working class","authors":"Magdalena Breyer; Robin Weisser; Denise Traber","full_text":"The mobilizing effect of class appeals on the new and old working class\n\nThe composition of social classes, especially the working class, has changed markedly over the last decades. Research shows that this had an impact on political parties’ strategies, decreasing their level of attention to the working class. However, there is another side to the changing class composition beyond the declining number of traditional, industrial workers. Service workers, often women and non-white, represent a growing share of the working class. They often work under precarious, but individualized working conditions and are less likely to be unionized. This paper assesses the role of political parties for the mobilization of service workers as a growing group within the working class. We argue that how parties, particularly left-wing parties, define the working class and appeal to it has an effect on whether disadvantaged groups are politically mobilized. We compare parties’ working class appeals in their manifestos in five European countries, the UK, Germany, Switzerland, France, and Sweden, analyzing shifts from 1990 until today using word embeddings. In a first step, we assess how much and in which way parties appeal to the ‘traditional working class’ compared to ‘service workers’ and other disadvantaged groups. In a second step, we evaluate whether these party strategies have an effect on turnout rates among these groups. Our results speak to an important puzzle, namely why the salience of class politics seems to decline despite growing precarious employment. We show that when parties fail to recognize the changing face of the working class, this may result in unequal political participation.","Discipline":"Political science","keywords":"Political communication; Group appeals; Social class; Quantitative text analysis","approach":"word embeddings","data":"party manifestos in 5 European countries","issue":"mobilization of service workers","geofocus":"Europe (UK, Germany, Switzerland, France, and Sweden)","Corresponding Author":"Magdalena Breyer","chair":"Roy Gardner","discussant":"Lucienne Engelhardt","time":"Friday, 15:15-16:45"},{"slot":"Day1_4","session_title":"Political Rhetoric Analysis","session":15,"id":84,"session_meansim":54773,"Title":"Dumbing Down? The Determinants of Language Complexity in Politicians' Parliamentary and Online Communication in 14 Countries","authors":"Rebecca Kittel; Bruno Castanho Silva","full_text":"Dumbing Down? The Determinants of Language Complexity in Politicians' Parliamentary and Online Communication in 14 Countries\n\nPoliticians are known to adjust their rhetoric to their audience. They may change the tone, style, and even position expressed in their communication depending on strategic considerations. One aspect that has not been investigated under this frame is language complexity: what individual and contextual factors determine when politicians use more or less complex language in their communication? On the one hand, higher complexity may serve as a signal of competence, while on the other lower complexity may be perceived as more ``genuine'' communication, trying to bring the speaker closer to ``common people''. These incentives are expected to play out differently for different groups of politicians when adapting (or not) their language to the audience. We expect politicians to lower the complexity of their communication when talking directly to followers in relation to peers, but based on theories of gendered perceptions of competence, we expect women to be more consistent with the complexity of their communication than men. We also expect center-right politicians to use less complex communication with the public when threatened in the polls by a far right challenger. We test these and other expectations on a dataset matching politicians' parliamentary speeches from 14 countries to all their contemporaneous Facebook posts, between 2018 and 2022, and applying measures of language complexity to each mean of communication.","Discipline":"Political Science","keywords":"language complexity; elite communication; legislative debates; social media","approach":"text analysis","data":"parliamentary speeches and Facebook posts","issue":"language complexity in politicians","geofocus":"14 countries","Corresponding Author":"Rebecca Kittel","chair":"Zachary Greene","discussant":"Magdalena Breyer","time":"Friday, 15:15-16:45"},{"slot":"Day1_4","session_title":"Political Rhetoric Analysis","session":15,"id":43,"session_meansim":54773,"Title":"Emotions over time. Are political debates more passionate than before?","authors":"István Üveges; Orsolya Ring; Gabriella Szabó","full_text":"Emotions over time. Are political debates more passionate than before?\n\nScholarly interest in emotions and political talks has increased over the past decade, with particular attention to the strategic and institutional ways in which emotions in politics are used and disseminated. While there has been ample literature on affectivity in political debates, less is known regarding the longitudinal characteristics of emotionalization. This paper offers a long-term big-data investigation into the differences between parliamentary speeches regarding the display of basic emotions in Hungary. Our sentence-level quantitative analysis reveals the dynamics over time covered over a longer period. The second question asks whether a trend can be detected in the communication of political actors being more saturated with emotional expressions on specific issues/events (e.g., security issues, migrations, rights to LGBTQ+ people, economic crisis, COVID-19 pandemic, or climate changes). The time frame of the project covers the period 2010-2022. The AI-supported analysis relies on multiple steps, including a fine-tuned BERT model for emotion identification complemented by Named Entity Recognition and topic modeling. The preliminary findings of the computational analysis on 27 888 832 sentences of 193 921 speeches confirm the tendency of emotionalization: the manifestations of emotions increase over time, which is especially true for joy and anger. Our data indicate that joy is mostly expressed by the MEPs of the government parties, while the parliamentary opposition tends to use anger, disgust, and sadness-related language more frequently. During the presentation, we discuss the results of the topic modeling and provide further quantitative insights into the tendency of emotional displays in politics.","Discipline":"Political Science","keywords":"emotion analysis; parliamentary speeches; fine-tuned BERT model; topic modeling","approach":"sentiment analysis","data":"parliamentary speeches in Hungary","issue":"longitudinal characteristics of emotionalization in political debates","geofocus":"Hungary","Corresponding Author":"István Üveges","chair":"Zachary Greene","discussant":"Magdalena Breyer","time":"Friday, 15:15-16:45"},{"slot":"Day1_4","session_title":"Political Rhetoric Analysis","session":15,"id":156,"session_meansim":54773,"Title":"Focused debate or party-political theater? Comparing the bill focus of parliamentary speeches in European parliaments","authors":"Lukas Hetzer; Sven-Oliver Proksch; Christian Rauh; Jan Schwalbach; Miklós Sebők","full_text":"Focused debate or party-political theater? Comparing the bill focus of parliamentary speeches in European parliaments\n\nParliaments are often criticized for being mere party-political theaters rather than fora for substantial debate of proposed bills. But to what extent does this hold true? When do MPs provide bill-focused arguments and when do MPs resort to general grandstanding which goes beyond the actual content of a bill? In this paper we theorize various incentives regarding speech (e.g., intra-debate order, speaker (e.g., party affiliation, executive role) and bill characteristics (e.g., initiator, procedural stage) to speak 'on topic' in bill debates. We test our expectations with a new data set - ParlLawSpeech - that offers linked full-text vectors of parliamentary speeches and the bills and laws that federal parliaments (AT, HR, CZ, DK, DE, HU, ES) and the European Parliament decide on. This unique data allows us to assess the bill-focus of plenary speeches by measuring the semantic similarity of bills on the plenary agenda and corresponding individual MP speeches. To this end, we construct various measures of bill focus (based on bag-of-words, tf-idf, and embedding approaches), which we validate through hand-coded speech texts. Initial findings based on data from the German Bundestag and the Austrian Nationalrat suggest that speakers from government parties and with an executive role show higher levels of bill focus and that bill focus declines as each debate progresses. Our findings provide a novel perspective on the dynamics in parliamentary democracies and shed light on MP’s incentives to remain 'on topic' in parliamentary debates.","Discipline":"Political Science","keywords":"parliamentary speech; legislative texts; embedding models; ParlLawSpeech","approach":"text analysis","data":"parliamentary speeches in European parliaments","issue":"bill focus in parliamentary debates","geofocus":"Europe","Corresponding Author":"Lukas Hetzer","chair":"Zachary Greene","discussant":"Magdalena Breyer","time":"Friday, 15:15-16:45"},{"slot":"Day1_4","session_title":"Political Rhetoric Analysis","session":15,"id":4,"session_meansim":54773,"Title":"Power of the Spoken Word: Targeted Representation by MEPs Language Choice","authors":"Fransisco's Gonzalez","full_text":"Climate Change Tropes popular media: beyond the genre of climate-fi","keywords":"MEPs; language representation; multilingual text analysis","approach":"text analysis","data":"parliamentary speeches in the European Parliament","issue":"targeted representation through language choice","geofocus":"EU","Corresponding Author":"Christine Sylvester","chair":"Zachary Greene","discussant":"Magdalena Breyer","time":"Friday, 15:15-16:45"},{"slot":"Day1_4","session_title":"Political Rhetoric Analysis","session":15,"id":17,"session_meansim":54773,"Title":"To Tax or to Tap: Dependent Revenue Policymaking in Zambia","authors":"Ben Cormier; Mark S. Manger; Jacob Winter","full_text":"To Tax or to Tap: Dependent Revenue Policymaking in Zambia\n\nMany developing country governments pursue pro-cyclical fiscal policies, taxing too little and borrowing too much when the economy is booming, only to reverse gear just when it is weakening. Such ill-fated fiscal choices often result in overborrowing, sovereign debt crises, and defaults. Despite the severe social consequences, the political processes leading to these economic disasters are not well understood. When do domestic policymakers prioritize one revenue source over the other? We hypothesize that political business cycles interact with global economic conditions to inform revenue preferences. Focusing on the case of Zambia, a country that has recently experienced a severe debt crisis, we draw on studies of legislative politics and use parliamentary speeches to uncover the positions taken by legislators. Using quantitative text analysis of 20 years of parliamentary debate, we show that legislators’ revenue preferences are strongly influenced by global interest rates and the price of export commodities, limiting the degree to which governments can pursue any fiscal strategy independent of global economic conditions. We thus document dependency in developing world fiscal policymaking: it is not merely domestic constituencies and political business cycles that dictate fiscal policy, but their position in the structure of the global economy. Our paper adds a novel dimension to the literature on developing country policy autonomy and contributes to an unfolding debate in political economy on the roots of recurring debt overhangs and debt crises.","Discipline":"Political Science; Economics","keywords":"sovereign debt; legislative speech; fiscal policy; Zambia; BERT models","approach":"text analysis","data":"parliamentary speeches","issue":"revenue policymaking in Zambia","geofocus":"Zambia","Corresponding Author":"Mark S. Manger","chair":"Zachary Greene","discussant":"Magdalena Breyer","time":"Friday, 15:15-16:45"},{"slot":"Day1_4","session_title":"Radicalization Narratives","session":32,"id":86,"session_meansim":2339,"Title":"“We are doomed!“: Detection of Fear Speech as Radicalization Narrative in Far-Right Communication","authors":"Julian Hohner; Simon Greipl; Heidi Schulze; Patrick Schwabl; Diana Rieger","full_text":"“We are doomed!“: Detection of Fear Speech as Radicalization Narrative in Far-Right Communication\n\nFear speech is a strategic communication tool used to incite general negative sentiment and evoke the perception of a crisis among the own peer group. The perception of ongoing crisis is a fertile ground for radicalization, making fear speech a key component in radical communication. However, fear is often voiced through ambiguous references, which has hindered research to classify such a latent construct.\n\nWe utilize a combination of new computational techniques to increase the performance of classifying latent constructs such as fear speech. We collected over six million German Telegram posts from 3905 manually classified far-right actors between 2020 and 2022 to train the classifier. We split the data into half and used the first half for ‘Domain-Adaptation’, a process in classification tasks to pre-train our ‘off-the-shelf’ language model to the language used in the training data. The other half was used to create the training & testing set that is sampled by salient crisis topics that emerged during our observation period, which we concluded based on BERTopic Model Container. As the notion of fear speech varies across thematic crises, we increase the classifier's performance by providing different topics in the training data. Overall, we annotated 6048 posts that contain (different kinds of) fear speech. The classifier achieved an F1 score of .82 and .79 on the validation set, with a precision of .79. Our results shed light on the usage of fear speech by far-right actors (21% of the total communication) and which topics they use to incite fear.","Discipline":"Social Science, Communication Science; Political Science","keywords":"Large-Language-Model; Classification; Domain-Adaptation; BERTopic-Modelling; Fear-Speech; Crisis Communication; Far-Right Communication","approach":"computational techniques","data":"Telegram posts","issue":"fear speech as radicalization narrative","geofocus":"Germany","Corresponding Author":"Julian Hohner","chair":"Julian Hohner","discussant":"Chico Camargo","time":"Friday, 15:15-16:45"},{"slot":"Day1_4","session_title":"Radicalization Narratives","session":32,"id":24,"session_meansim":2339,"Title":"A Crowdsourced Map of YouTube Recommendations during the Brazilian 2022 Elections","authors":"Ana Julia Bonzanini Bernardi; Ranadheer Malla; Isabela Inês; Rodger Richer; Camila Tsukuki; Caio Machado; Beatrice Bonami; Chico Camargo","full_text":"A Crowdsourced Map of YouTube Recommendations during the Brazilian 2022 Elections\n\nMuch like for many recent other transitions of power, the 2022 Brazilian general elections were rife with claims of illegitimacy of the electoral process, and plenty of misleading political content, about the potential role of Brazil's Supreme Electoral Court, congress, and army in a potential presidential coup. The Viu Politica project analyzed videos recommended on YouTube during this period, leveraging a browser plug-in that allowed volunteers to tag political videos. From 65 volunteers, 1,281 tagged videos and 9,519 recommended videos from 2,195 channels were gathered. By combining LDA topic modelling and network analysis of YouTube recommendations, we map out the main themes covered by all videos, along with the most central clusters of channels in the recommendation network. We also analyse a mouth-to-mouth recommendation network, where YouTubers feature each other in their channels, effectively negotiating cultural capital. Finally, this study investigates the feasibility of crowdsourced studies of recommender systems and social media platforms such as YouTube, along with particular challenges of studying political discourse in the Global South.","Discipline":"Computational Social Science; Political Communication","keywords":"YouTube; recommendation algorithms; community detection; Brazil; elections; political communication","approach":"topic modeling","data":"YouTube videos","issue":"political content during the Brazilian 2022 elections","geofocus":"Brazil","Corresponding Author":"Chico Camargo","chair":"Julian Hohner","discussant":"Chico Camargo","time":"Friday, 15:15-16:45"},{"slot":"Day1_4","session_title":"Radicalization Narratives","session":32,"id":141,"session_meansim":2339,"Title":"Codes of Legitimacy and Words of Power: Semantic Diffusion and Systemic Language in International Politics","authors":"federico salvati","full_text":"Codes of Legitimacy and Words of Power: Semantic Diffusion and Systemic Language in International Politics\n\nRecent research has supported the idea that international political speech has drastically taken democratic/liberal tones over the last few years (Dingwerth, 2020). The idea underlying this discussion is that after the end of the Cold War, the construction of legitimate political discourse within the international system cannot be accomplished without the employment of liberal/Western concepts. This would reflect the dominant position of these values with the LIO (Liberal International System).\nIn my paper, I want to investigate the concrete diffusion of these concepts focusing on the\nUNGA General Debate. I will investigate first of all if there is strong proof this diffusion happened at all. I am particularly interested in seeing if such diffusion is actually systemic or if it belongs to a particular set (or sets) of countries. After that, I will focus on the mechanisms that this diffusion displays. In the paper, I will use quantitative text-mining techniques to investigate such diffusion.\nMore specifically, I will employ Markov Chains and SIR (Susceptible Infected Recovered) viral spreading model. I will use these models to trace and outline the dynamic of diffusion isolating patterns and groups that have made such diffusion possible. I will finally outline what are the consequences of my results, assessing what kind of information my investigation gives us on the construction of legitimate political discourse and normative hegemony within the\ninternational system.","Discipline":"International Relations","keywords":"Text mining, semantics, hegemony, legitimacy, UNGA","approach":"text-mining techniques","data":"UNGA General Debate","issue":"diffusion of democratic/liberal concepts in international politics","geofocus":"Global","Corresponding Author":"federico salvati","chair":"Julian Hohner","discussant":"Chico Camargo","time":"Friday, 15:15-16:45"},{"slot":"Day1_4","session_title":"Radicalization Narratives","session":32,"id":36,"session_meansim":2339,"Title":"How much to seed a (partially) seeded topic model?","authors":"Salsabil M. Abdalbaki; Johan A. Dornschneider-Elkink; Derek Greene","full_text":"How much to seed a (partially) seeded topic model?\n\nTopic models are an increasingly common method in political science, because of the high prevalence of textual data. Topic models are fully data-driven – the algorithm identifies topics based on the frequency and co-occurrence of words. Semi-supervised topic models like seeded LDA and partially seeded LDA depend on creating a pre-defined dictionary of seeded topics of interest and seed words representing these topics. These seed words may reduce the model’s fit, where the researcher’s expectations start to drive the output, not the data. Unfortunately, very little guidance exists on how many seed words to add for a seeded topic, or how many topics to seed. In this paper, we investigate the impact of the level of supervision on the coherence and fit of the resulting topic model. The Guardian API and Media Frame Corpus 4.0 are utilized for running 100 replications. We use KeyBERT to extract the relevant seed words. The Hungarian algorithm is used to match the topics of different topic models and we focus on Kullback–Leibler divergence and topic coherence to evaluate the performance of each model. Experiments confirm that the divergence of a partially seeded LDA from unseeded LDA increases and the topic coherence of the partially seeded LDA decreases as too many topics are seeded with too many seed words. We provide some guidance with regards to the maximum amount of reasonable seeding.","Discipline":"Computational Media Framing; Natural Language Processing","keywords":"Computational Media Framing; KeyATM; Semi-supervised Topic Modeling","approach":"seed-based topic model","data":"Guardian API and Media Frame Corpus 4.0","issue":"seeding topic models in political science","geofocus":"NONE","Corresponding Author":"Salsabil M. Abdalbaki","chair":"Julian Hohner","discussant":"Chico Camargo","time":"Friday, 15:15-16:45"},{"slot":"Day1_4","session_title":"Radicalization Narratives","session":32,"id":38,"session_meansim":2339,"Title":"Multi-level politics in action: How national elections make European policies more responsive to public opinion","authors":"Michele Scotto di Vettimo","full_text":"Multi-level politics in action: How national elections make European policies more responsive to public opinion\n\nThis paper analyses the link between policy-specific preferences for European integration and European Union (EU) policies between 1994 and 2019.\nIt has been shown that the EU institutional arrangement enables national-level factors to influence the link between public opinion and EU-level policies. I argue that EU policy-making is skewed towards public preferences of those states where national elections are closer in the future. \nTo support this claim, I use a Bayesian item response theory approach to construct policy area-specific series of public preferences for EU integration starting from 201 Eurobarometer questions. Then, I collect the summaries of all EU legislative acts tabled between 1994 and 2019, and use a supervised word embedding approach to measure the extent to which they expand EU authority. \nThe results indicate that EU authority expansion is more associated with average public support for policy integration in a specific area when national-level public preferences are weighted by the proximity to national elections. \nThis paper contributes to the existing literature on the opinion-policy link in the EU under territorial representation by showing the key role that national elections play in EU-level policy-making.","keywords":"Latent semantic scaling; classification; European Union","approach":"Bayesian item response theory","data":"Eurobarometer questions","issue":"public opinion and EU policies","geofocus":"Europe","Corresponding Author":"Michele Scotto di Vettimo","chair":"Julian Hohner","discussant":"Chico Camargo","time":"Friday, 15:15-16:45"},{"slot":"Day1_5","session_title":"Political Communication Analysis","session":36,"session_meansim":0.3619,"Title":"Computational Homeostasis in Large Language Models: Insights and Parallels with Human Psychological Processes","authors":"Hubert Plisiecki; A. Sobieszek","full_text":"Computational Homeostasis in Large Language Models: Insights and Parallels with Human Psychological Processes\n\nIn this paper, we explore the concept of emotional homeostasis, crucial for maintaining psychological stability, and how its disruption leads to conditions like depression, characterized notably by rumination – a pattern of persistent negative thinking. This psychological phenomenon is paralleled with a specific operational pattern in Large Language Models (LLMs), where repetitive and nonproductive word generation can be seen as a form of 'computational rumination,' indicating a disruption in the model's functional equilibrium. We delve into this analogy by simulating the process of rumination in LLMs to better understand the underlying mechanisms that enable LLMs to generate coherent and novel text, and the factors that disrupt this process. This could not only provide insights into the operational dynamics of LLMs but also offer some tentative hypotheses on human cognitive processes. Through a series of analyses, this study aims to illuminate the parallel paths of achieving and maintaining balance in both human psychology and artificial intelligence systems. We discuss the practical implications of our findings, proposing strategies for more effective use of LLMs and drawing insights that could enrich our understanding of human cognitive processes. This interdisciplinary approach offers a novel viewpoint in the intersection of psychology and AI, with potential benefits for both fields.","Discipline":"Psychology; Machine Learning","keywords":"Homeostasis, Large Language Models, Psychology of Emotions","approach":"analogy between LLMs and human psychological processes","data":"LLMs and human cognition","issue":"emotional homeostasis and rumination","geofocus":"intersection of psychology and AI","Corresponding Author":"Hubert Plisiecki","chair":"Decadri Silvia","discussant":"Hubert Plisiecki","time":"Friday, 16:45-18:15"},{"slot":"Day1_5","session_title":"Political Communication Analysis","session":36,"session_meansim":0.4585,"Title":"Congressional Bill Text as Data: Estimating and Scaling an Immigration Policy Space in the Presence of Unstable Left-Right Party Coalitions","authors":"Lauren M. Rowlands","full_text":"Congressional Bill Text as Data: Estimating and Scaling an Immigration Policy Space in the Presence of Unstable Left-Right Party Coalitions\n\nImmigration reform is a significant and salient topic. From the extant literature, we know \nthat immigration policy does not map well onto the left-right party divide. In order to better \nunderstand the micro-level determinants of members’ decisions surrounding immigration reform — what a “yea” and “nay” actually mean on roll-calls – it is useful to examine the\ncontraction/expansion-oriented language within the bills they are voting on. I estimate and scale a left-right (contract-expand) immigration policy dimension by using a dataset (corpus) of 80 immigration-related Congressional bills, all associated with final passage votes. These bills span \nfrom the first expansionist era in the 1950s, through the restrictionist movements post-9/11, and beyond the modern comprehensive reform efforts to 2012. I employ three methods of content analysis: 1) the hand-coding of bills (by section and in the aggregate) as either an expansion or contraction of immigration rights; 2) Principal Components Analysis (PCA), an unsupervised, dimensionality reduction algorithm, which quantifies the principal axes in a corpus and uses those axes to describe the corpus itself; and, 3) Wordfish, a scaling algorithm which estimates policy positions based on word frequencies in texts. I find that these methods are highly correlative in their generation of a contract-expand domain, which gives insight into the ideal points of legislators within immigration policy.","Discipline":"Political Science","keywords":"Congress; Immigration; Content Analysis; Dimensionality Reduction Methods","approach":"content analysis","data":"Congressional bill text","issue":"immigration policy","geofocus":"US","Corresponding Author":"Lauren M. Rowlands","chair":"Decadri Silvia","discussant":"Hubert Plisiecki","time":"Friday, 16:45-18:15"},{"slot":"Day1_5","session_title":"Political Communication Analysis","session":36,"session_meansim":0.4585,"Title":"From MP to Leader. The necessity to seduce the median vote to win elections.","authors":"Alberto de León; Matthias Egger; Anne Jorstad; Katrin Milzow; Stefan Müller; Gabriel Okasa; Michaela Strinzel","full_text":"From MP to Leader. The necessity to seduce the median vote to win elections.\n\nParty leaders present their position across diverse topics at different political stages. This study delves into the rhetoric of political leaders during national party conferences, asserting that their speeches undergo strategic adaptations when assuming influential national roles, particularly in the pursuit of broader support. While party ideology remains influential in shaping public opinion, contemporary politics underscores the pivotal role of leaders in shaping political landscapes. This research, grounded in the median voter theory, posits that leaders strategically tailor their discourse on specific issues based on their hierarchical position within the party. Utilizing data spanning UK party conferences from 1998 to 2021, I employ the unsupervised text analysis method WORDFISH to scale leaders' speeches on a unidimensional scale. The analysis involves assessing the distance to the median position from MPs transitioning to leaders and those retaining regular MP status, thereby delineating nuanced distinctions. By examining national party conference speeches, I compare leaders' speeches in their capacity as regular MPs versus when assuming the role of party leader. I expect that leaders tend toward a moderate position on pertinent issues when in leadership roles, strategically leveraging support from the median electorate. These results hold relevant implications for comprehending leaders' rhetoric and political behaviour within multilevel institutions, using quantitative text analysis with classical party leader theories.","Discipline":"political science","keywords":"political parties; leaders, speeches, text analysis; median voter","approach":"unsupervised text analysis","data":"UK party conferences speeches","issue":"leaders","geofocus":"UK","Corresponding Author":"Alberto de Leon","chair":"Decadri Silvia","discussant":"Hubert Plisiecki","time":"Friday, 16:45-18:15"},{"slot":"Day1_5","session_title":"Political Communication Analysis","session":36,"session_meansim":0.4585,"Title":"Post-Defeat Communication Strategies of Political Candidates on Twitter-X","authors":"Silvia Decadri; Giovanni Pagano","full_text":"Post-Defeat Communication Strategies of Political Candidates on Twitter-X\n\nScholars have studied political candidates’ communication during electoral campaigning at large. To this date, research has concentrated either on candidates’ communicative effort to win voters’ favor, or on their communication style once elected. In this study, we venture down a little-trodden path and investigate the post-election communication of defeated political candidates on social media: We focus on their Twitter-X posting to understand how these individuals adapt their messaging strategies following electoral defeat. To this aim, we build a novel dataset encompassing more than 2,500 candidates, across six countries, running for seats in the European Parliament in the context of the 2019 election campaign. Leveraging three weeks of pre-election Twitter activity and a subsequent three-week post-election period, we investigate the shifts in communication strategies adopted by candidates who faced defeat at the ballot box. Using computational text-analytic methods, we aim at unveiling nuanced shifts in the defeated candidates' messaging tone, thematic emphasis, and strategic repositioning. In particular, we investigate whether defeated candidates shift towards a populist rhetoric and an emotional tone, (re-)align with broader party narratives, or engage in rebranding efforts. Finally, we explore potential connections between these post-defeat communication strategies and subsequent political candidacies, shedding light on the incentive structure given by party selection processes, as well as on the adaptability and resilience of candidates in response to electoral setbacks.","keywords":"electoral campaigning;social media;electoral defeat;thematic emphasis;emotional speech","approach":"computational text analysis","data":"Twitter posts from defeated political candidates","issue":"post-election communication strategies","geofocus":"Europe","Corresponding Author":"Decadri Silvia","chair":"Decadri Silvia","discussant":"Hubert Plisiecki","time":"Friday, 16:45-18:15"},{"slot":"Day1_5","session_title":"Political Narrative Analysis","session":13,"id":83,"session_meansim":42666,"Title":"Beyond Human Subjects: Large Language Models as Participants in Political Experimentation","authors":"Selim Yaman; Mustafa Taha Koçyiğit","full_text":"Beyond Human Subjects: Large Language Models as Participants in Political Experimentation\n\nWe introduce a novel framework that employs large language models (LLMs) to simulate political experiments. Building upon the foundation laid by Argyle et al. (2023), our work advances from AI-generated survey response predictions to the complete simulation of political lab experiments. We demonstrate this through the replication of two seminal political science studies: one examining the impact of inaction inertia in international negotiations, and the other investigating gender differences in candidate emergence. Our simulations, powered by 'silicon samples' generated by LLMs, allow for a detailed simulation of human behavior within controlled environments. The behavioral responses of our LLM-powered agents consistently align with the original studies, validating the applicability of LLMs in modeling complex human behaviors in a political context. Our framework opens up new possibilities, providing an additional tool for researchers to study political phenomena, including the capability to explore scenarios via artificial group experiments and large-scale simulations that were previously challenging due to ethical or logistical constraints. The successful implementation of our framework presents promising directions for further research into political behavior using LLM-powered autonomous agents.","Discipline":"Political Methodology; Political Science; Computational Social Sciences","keywords":"large language models; autonomous agents; political experiment","approach":"large language models","data":"survey responses and political experiments","issue":"political experimentation with AI","geofocus":"none","Corresponding Author":"Selim Yaman","chair":"Callum Craig","discussant":"Ella MacLaughlin","time":"Friday, 16:45-18:15"},{"slot":"Day1_5","session_title":"Political Narrative Analysis","session":13,"id":108,"session_meansim":42666,"Title":"More than the Sum of its Parts? Measuring Image Types in Political Communication","authors":"Tobias Heidenreich; Phoebe Maares; Olga Eisele; Duoduo Hua; Ting Zhang","full_text":"More than the Sum of its Parts? Measuring Image Types in Political Communication\n\nThis study presents a path to measuring image types in political communication involving an innovative mixed-methods approach. First, building on visual and political communication literature, we identify image types in an inductive, qualitative coding process. Second, using a large dataset containing EU institutions' visual social media posts, we engage with manual and automated content analysis methods. \nWe employ transformer models and contrast methodological choices in the automated measurement of image types. Informed by manually coded data, our study uses 1) transfer learning to finetune models on the image level, trained on entire pictures, and 2) object detection to link image types with recurring features relevant to each category and make them measurable through individual aspects.\nThis comparative analysis demonstrates the efficacy of the different approaches, providing a hands-on example of, so far, very scarce approaches to deal with visual data in an automated manner as well as showcasing their validation. The theoretical link and the qualitative work to collect, describe, and connect image types with the literature, moreover, enables the approach to be harnessed for substantial research. Exploring the implications of the methodological choices, we add to the understanding on how visual cues convey political messages and how they might relate to certain goals. Contributing to methodological advancements in the fields of communication and political science, this study thus provides an innovative view on digital data, combining in-depth reflection of critical constructs with large scale analysis.","Discipline":"Communication Science","keywords":"image types; mixed methods; automated visual content analysis; political communication; EU; social media","approach":"transformer models and object detection","data":"EU institutions","issue":"image types in political communication","geofocus":"Europe","Corresponding Author":"Tobias Heidenreich","chair":"Callum Craig","discussant":"Ella MacLaughlin","time":"Friday, 16:45-18:15"},{"slot":"Day1_5","session_title":"Political Narrative Analysis","session":13,"id":53,"session_meansim":42666,"Title":"Multilingual Stance Detection in Political Speech: Interpretation, Applications, and Limitations","authors":"Stefan Müller; Yen-Chieh Liao","full_text":"Multilingual Stance Detection in Political Speech: Interpretation, Applications, and Limitations\n\nMeasuring the stance of political actors on specific policies provides valuable in-\nsights for understanding policy-making, changes in political preferences, and party\ncompetition. In this paper, we fine-tune various multilingual transformer machine\nlearning models based on annotated texts of stances in over 53,000 comments on\nTwitter (Mohammad et al. 2017) and more than 67,000 comments to 150 political\nquestions in German, English, and Italian (Vamvas and Sennrich 2020). We validate\nand compare various multilingual transformer frameworks, including Multilingual\nBERT, Multilingual DistilBERT, and XLM-RoBERTa. After identifying the most\nsuitable fine-tuned model, we compare the stance classification with human-coded\npositions of politicians’ support for the annual budget, positions and roll-call votes\nduring energy policy debates, and stances on specific policies, such as abortion and\nimmigration. We discuss the scope and limiations of stance classification compared\nto existing approaches, such as unsupervised and supervised text scaling, sentiment\nanalysis, human judgement, and generative AI (GPT-4 and LLaMA 2). Drawing\nfrom our systematic comparison and validation of various methods, we provide recommendations for researchers aiming to apply stance detection to political texts.","Discipline":"political science","keywords":"multilingual transformer, political stance, NLP","approach":"multilingual transformer machine learning models","data":"Twitter comments and political questions in German","issue":"stance detection in political speech","geofocus":"global","Corresponding Author":"Yen-Chieh Liao","chair":"Callum Craig","discussant":"Ella MacLaughlin","time":"Friday, 16:45-18:15"},{"slot":"Day1_5","session_title":"Political Narrative Analysis","session":13,"id":22,"session_meansim":42666,"Title":"Predicting the Future: When and how do political elites make predictions in situations of uncertainty?","authors":"Barbara Vis; Ella MacLaughlin","full_text":"Predicting the Future: When and how do political elites make predictions in situations of uncertainty?\n\nPolitical elites regularly (have to) make predictions, i.e., assessments about the future. Oftentimes, these predictions are made under uncertainty, ranging from situations in which information is lacking (resolvable uncertainty) to situations characterized by manifold unknowns, ambiguity and vagueness (radical uncertainty). By influencing political elites’ decisions, these predictions can impact numerous people’s lives. Yet, remarkably little is known about when and how political elites make predictions in situations of uncertainty; this paper is the first to address this lacuna.\n\nWe focus on the case of Covid-19 as a quintessential phenomenon of uncertainty, taking as our context the Netherlands: a country with comparatively much accountability for their pandemic measures. We first hand-coded all 56 Dutch Covid-19 press conferences for (1) expressions of uncertainty, (2) predictions by politicians, and (3) traits of predictions (e.g., based on expert advice). We then use this gold-standard to validate a newly developed RoBERTa-based machine learning algorithm for classification.\n\nThis approach allows us to explore the over-time development of expressed uncertainty and politicians’ predictions, and to examine the relationship with specific traits of predictions. While “objective” uncertainty about Covid-19 decreased over time, our analysis neither shows an over-time reduction in expressed uncertainty, nor a theoretically plausible increase in predictions. Through our systematic yet explorative analysis of how developments in expressed uncertainty relate to the frequency and characteristics of predictions, we can theorize about the reasons behind this puzzle, providing preliminary insights on when and how politicians make predictions in situations of uncertainty.","Discipline":"Political science","keywords":"predictions, political elites’ behavior, machine learning","approach":"machine learning","data":"Covid-19 press conferences","issue":"predictions by political elites in uncertain situations","geofocus":"Netherlands","Corresponding Author":"Ella MacLaughlin","chair":"Callum Craig","discussant":"Ella MacLaughlin","time":"Friday, 16:45-18:15"},{"slot":"Day1_5","session_title":"Political Narrative Analysis","session":13,"id":134,"session_meansim":42666,"Title":"Victimhood Narratives in the United States Congress 1960-2023","authors":"Callum Craig","full_text":"Victimhood Narratives in the United States Congress 1960-2023\n\nCollective victimhood is the perception that a group has been intentionally harmed by the actions of another. Feelings of collective victimhood have been demonstrated to have a strong effect on intergroup bias, outgroup hostility and support for violence. However, little attention has been paid to the use of these narratives by political elites within the context of electoral politics. Along with a descriptive analysis of victimhood narratives in congress, I argue that political elites will utilize these narratives to build support and direct attacks against their political opposition. To test this theory, I will leverage the 7 year time gap between the introduction of C-SPAN to both chambers of Congress for a difference-in-differences design. If these narratives are used instrumentally an increase in the reach of congressional speeches would cause an increase in the use of victimhood narratives. To measure the use of victimhood narratives I will build a novel machine-learning classifier to predict the presence of these narratives in speeches parsed from the congressional record. This will provide valuable insight into the use of potentially dangerous and/or polarizing narratives by political elites.","Discipline":"Political Science","keywords":"Collective Victimhood, American Politics, Communication","approach":"machine learning","data":"congressional speeches","issue":"political elites and victimhood narratives","geofocus":"United States (1960-2023)","Corresponding Author":"Callum Craig","chair":"Callum Craig","discussant":"Ella MacLaughlin","time":"Friday, 16:45-18:15"},{"slot":"Day1_5","session_title":"Sustainability and Social Media","session":8,"id":80,"session_meansim":30766,"Title":"Contextualized versus static embeddings to identify biases in news","authors":"Damian Trilling; Guusje Thijs, Anne Kroon","full_text":"Contextualized versus static embeddings to identify biases in news\n\nNews often contains stereotypes -- but it is not always easy to measure them. Previous research has demonstrated ethnic biases based on word co-occurrences, dependency parsing, and by training static word embeddings. This revealed gender and ethnic stereotypes in news corpora in multiple countries.\n\nOne potential drawback is that static word embeddings cannot deal with homonyms -- for instance, the Dutch word \"oplichten\" can mean \"to defraud\", \"to swindle\", but also \"to lighten up\" or \"to lift\". Modern contextualized embeddings (such as BERTje) can assign different embeddings to these homonyms and hence may be a promising tool.\n\nWe try out different approaches on a corpus of 107,965,966 unique sentences from 7,441,914 Dutch news articles from a broad range of 28 outlets, as well as lists with in- and out-groups and with stereotypes. We train Word2Vec models and additionally train a BERTje model, and calculate measures like cosine similarities between word vectors as well as overlap of predicted words with our lists.\n\nOur results show that despite some differences regarding the specific ordering of the ethnicities, the overall picture between static and contextualized approaches\nis remarkably similar: in both approaches, out-groups can be shown to be substantively more framed as low-status and high-threat than in-groups.\n\nWe found that are target-neutral templates (like \"Moroccans are [MASK]\") performed much worse than target attribute-approaches (like \"[MASK] are [attribute]\") where [attribute] is a stereotypical attribute. We also show that while the original BERTje model contained only very limited ethnic biases, additionally training it with our corpus\nintroduced the biases to the model which we also found using the static embedding approach.","Discipline":"communication science","keywords":"static word embeddings; contextualized word embeddings; bias; stereotypes; news; transformers","approach":"contextualized embeddings","data":"Dutch news articles","issue":"identifying biases in news","geofocus":"Netherlands","Corresponding Author":"Damian Trilling","chair":"Damian Trilling","discussant":"Lena Masch","time":"Friday, 16:45-18:15"},{"slot":"Day1_5","session_title":"Sustainability and Social Media","session":8,"id":55,"session_meansim":30766,"Title":"From Parliament to Pixels: Exploring the Congruence between MPs' Substantive Representation of Women’s Interests in Parliament and their Visual Representation of female Voters on Instagram","authors":"Jana Boukemia","full_text":"From Parliament to Pixels: Exploring the Congruence between MPs' Substantive Representation of Women’s Interests in Parliament and their Visual Representation of female Voters on Instagram\n\nCandidates strategically use carefully curated images to prime female voters' gender identity and to build a symbolic bond with their female electorate. Given the growing significance of visual appeals in MPs' online campaigns, researchers need to understand what such visual appeals mean for political representation. Specifically, it is still unclear whether MPs who represent women's substantive interests in parliament also use visuals to convey their support for these issues, or if these visual appeals have little bearing on the actual work that these legislators do on behalf of women. Following a 'critical actors' perspective, I contend that MPs who table and sign more Early Day Motions in the British parliament pertaining to women-specific interests also feature more Instagram posts depicting female voters. To estimate how much of an MP's work relates to women-specific issues, I manually categorize 1'814 Early Day Motions tabled between May 2022 and October 2023 and calculate the ratio of women-specific to non-women-specific Early Day Motions for each MP. In a second step, I use a face detection classifier to calculate the fraction of Instagram posts depicting female voters on each MPs Instagram profile during the same period. Using this methodology, I can determine whether MPs use visual communication tools to demonstrate their dedication to women's interests, or whether the images they post are largely symbolic. By bridging the gap between legislative activities and online persona, I can better grasp the multifaceted strategies employed by Members of Parliament to engage with the issues that resonate with female constituents.","Discipline":"Political Science","keywords":"Images, Visual Politics, Gender Representation","approach":"content analysis","data":"Early Day Motions in British parliament and Instagram posts","issue":"representation of women","geofocus":"Britain","Corresponding Author":"Jana Boukemia","chair":"Damian Trilling","discussant":"Lena Masch","time":"Friday, 16:45-18:15"},{"slot":"Day1_5","session_title":"Sustainability and Social Media","session":8,"id":145,"session_meansim":30766,"Title":"Mapping Political Social Media Influencers on German TikTok","authors":"Christian Pipal","full_text":"Mapping Political Social Media Influencers on German TikTok\n\nThe rising prominence of political social media influencers (PSMIs) is garnering increased attention in political communication. Despite this, the extent and operational dynamics of these influencers remain underexplored. This study aims to fill this gap by examining the PSMIs landscape on German TikTok. Through the analysis of over 3,000 influencers who share political content, I construct a network of German TikTok PSMIs. Using advanced natural language processing and computer vision methods, I assess the volume, ideological leanings, content characteristics, and engagement approaches in their political post to develop an empirical typology of PSMIs. The findings uncover distinct patterns in the political engagement strategies of TikTok influencers in Germany, significantly enhancing our understanding of PSMIs' role in political communication, contributing to a deeper insight into the dissemination and reception of political ideas in the digital era.","Discipline":"Communication Science, Political Science","keywords":"social media influencers, TikTok, content analysis","approach":"network analysis","data":"German TikTok influencers","issue":"political social media influencers","geofocus":"Germany","Corresponding Author":"Christian Pipal","chair":"Damian Trilling","discussant":"Lena Masch","time":"Friday, 16:45-18:15"},{"slot":"Day1_5","session_title":"Sustainability and Social Media","session":8,"id":151,"session_meansim":30766,"Title":"Smiling, laughing, and crying? Emotional self-presentations of political candidates on social media","authors":"Lena Masch; Dylan Paltra; Felix Schmidt; Marius Sältzer","full_text":"Smiling, laughing, and crying? Emotional self-presentations of political candidates on social media\n\nPolitical candidates use social media platforms increasingly in many Western democracies, especially during election campaigns, to appeal directly to their potential voters. Sharing emotional content and expressing emotions could be used as a strategy form of self-presentation and political communication. We expect that party affiliation and personal characteristics predict whether political candidates display emotions frequently on social media and which emotions they display. We expect that candidates for far-right populist parties display more anger compared to mainstream political candidates. We also expect to find a moderating effect for gender. We further test whether candidates’ self-reported personality traits can further be linked to the expression of certain emotions and their frequency.\nWe measure the emotional social media communication using face and perceived-emotion recognition algorithms. Based on reference images for individual candidates of eight German state elections, we identify how often they display emotional expressions in their posts. We link this data to candidate surveys conducted during the 2021-2022 elections containing personal preferences towards social media use as well as psychological items such as their personality traits. We test whether candidates of populist parties are more likely to display more emotions in general, and specifically negative emotions such as anger compared to mainstream politicians, and whether these emotional displays can, in turn, be linked to specific personality traits, such as agreeableness.","Discipline":"political science; communication research","keywords":"political communication; social media; visual analysis; facial recognition; emotion recognition","approach":"face and perceived-emotion recognition algorithms","data":"social media posts of political candidates","issue":"emotional self-presentations of political candidates","geofocus":"Germany","Corresponding Author":"Lena Masch","chair":"Damian Trilling","discussant":"Lena Masch","time":"Friday, 16:45-18:15"},{"slot":"Day1_5","session_title":"Sustainability and Social Media","session":8,"id":101,"session_meansim":30766,"Title":"The potential of social media influencers to promote sustainable consumption patterns","authors":"Erik de Vries; Sophie Boerman","full_text":"The potential of social media influencers to promote sustainable consumption patterns\n\nPrevious content analyses have shown that YouTube influencer videos are packed with commercial messages (Opree et al., 2022), and that greenfluencers on Tik- Tok mostly communicate about climate change and focus on individual respon- sibility (Huber et al., 2022) . However, the proportion of commercial and eco- friendly influencer content on social media platforms remains unclear. In this study we will analyze the posts of the most popular Dutch influencers on Insta- gram, YouTube and TikTok to gain insight into the following questions: \n\n1) What is the proportion of commercial content (i.e., promoting consuming more) and eco-content (i.e., promoting consuming less and more sustain- able behaviour) in influencer content? \n2) Which topics (e.g., climate change, pro-environmental behaviour, sustain- able fashion, greenwashing, consuming less, promoting purchases) do in- fluencers talk about on Instagram in the context of climate change and sustainability? \n3) How are the different messages related to measures of engagement (i.e., likes, comments, shares)? \n\nIn order to determine the content of the posts, we will use lbl2vec (Schopf et al., 2021, 2022) along with sets of specific keywords for the various labels. This approach leverages Doc2Vec (based on Le & Mikolov, 2014) to generate both document and word vectors, and determine the vector of the label by finding the centroid of the document vectors that are closest to the keyword vector. These centroids are then used to compute similarity scores between document vectors and label vectors.","Discipline":"Environmental Communication; Popular Media and Culture","keywords":"word embeddings; influencers; unsupervised learning","approach":"label2vec","data":"posts of popular Dutch influencers on Instagram","issue":"promoting sustainable consumption patterns","geofocus":"Netherlands","Corresponding Author":"Erik de Vries","chair":"Damian Trilling","discussant":"Lena Masch","time":"Friday, 16:45-18:15"},{"slot":"Day1_5","session_title":"Textual Analysis of Political Positions","session":14,"id":140,"session_meansim":27965,"Title":"An Improved Framework for Scaling Party Positions from Texts using Transformer and Supervised Dimension Reduction","authors":"Hung H. V. Nguyen","full_text":"An Improved Framework for Scaling Party Positions from Texts using Transformer and Supervised Dimension Reduction\n\nPrevious research in both Natural Language Processing (NLP) and political science has proven the superiority of the Transformer architecture compared to word frequencies and word embeddings on multiple text analysis tasks. In this article, I introduce a novel framework for scaling party positions from texts using Transformer. Besides a sizable boost in text representation, I demonstrate how the scaling framework also benefits from a supervised dimension reduction technique, one which reduces complex contextual embeddings produced from Transformer into meaningful position scores for political science research. This Transformer-based scaling framework is scalable, reproducible, and extensible across languages, political domains, and theoretical models. A dataset of party positions for seventeen Western democratic societies is released along with the paper.","Discipline":"Political Methodology","keywords":"party position scaling; Transformer; supervised dimension reduction","approach":"Transformer architecture","data":"party positions from texts","issue":"scaling party positions from texts","geofocus":"Western democratic societies","Corresponding Author":"Hung H. V. Nguyen","chair":"Fabian Habersack","discussant":"Hung H. V. Nguyen","time":"Friday, 16:45-18:15"},{"slot":"Day1_5","session_title":"Textual Analysis of Political Positions","session":14,"id":90,"session_meansim":27965,"Title":"Electoral Systems and Party Convergence on Issue Attention","authors":"David Yen-Chieh Liao; Yu-Ceng Liao; Yi-ting Wang","full_text":"Electoral Systems and Party Convergence on Issue Attention\n\nThis paper is to measure party convergence and variability in issue attention by looking at what and why legislators are more likely to oversight the ministry officials on some specific topics or another during the question time. We answer this question using the case of the Taiwan Legislative Yuan, and data on written parliamentary questions through an electoral reform from 1993 to 2020, over 116,248 questions. We find that the institutional changes shapes legislators’ attention to the topics in relation to their own co-partisan: legislator converge issue attention when there is high variability in the distribution of topics under Single Member District (SMD) and diverges when there is low variability under Single Non-transferable Vote (SNTV). In addition, legislators elected under the Single Non-Transferable Vote (SNTV) system tend to show more divergence by focusing on specific topics, while those from single-member districts typically converge their attention, asking about various public policy issues at random.","Discipline":"parliamentary study","keywords":"electoral system; party convergence; issue attention; parliamentary questions; Wordfish Scaling Method","approach":"content analysis","data":"written parliamentary questions","issue":"party convergence and variability in issue attention","geofocus":"Taiwan","Corresponding Author":"David Yen-Chieh Liao","chair":"Fabian Habersack","discussant":"Hung H. V. Nguyen","time":"Friday, 16:45-18:15"},{"slot":"Day1_5","session_title":"Textual Analysis of Political Positions","session":14,"id":89,"session_meansim":27965,"Title":"Evaluating the performance of Large Language Models for Framing Function Identification","authors":"Emily Robinson; Chico Camargo;Ranadheer Malla","full_text":"Evaluating the performance of Large Language Models for Framing Function Identification\n\nFraming, as conceptualized by Entman, entails the deliberate selection and emphasis of particular aspects of perceived reality within communicated texts. These framing functions, encompassing problem definitions, causal interpretations, moral evaluations, and treatment recommendations, distill information into abstract forms. Traditional frame identification relied on qualitative methods, limiting data analysis due to manual work. Recently, computational methods leveraging machine learning in natural language processing have gained traction for frame identification, yet, a challenge remains in unifying the research, due to differing interpretations of what actually constitutes a frame.\n\nThis paper argues that framing interpretations often falter due to the disconnect between framing, frames, and social constructionist processes like reasoning and moral evaluations. We propose an approach, building on Guo et al.'s (2012) research, suggesting that analyzing frames through the lens of framing functions can unify research by identifying the function(s) which are operationalised to create any frame. This analysis delves deeper than just discerning patterns that persistent over time (a frame) and instead reveals the cognitive and human aspects underpinning all frames (framing functions).\n\nOur paper introduces a computer-assisted methodology using generative AI to identify framing functions in texts. Leveraging GPT-3.5 Turbo and Vicuna13B, we evaluate their efficacy in discerning nuanced language patterns within framing functions. While both models showed comparable performance, GPT-3.5 Turbo outperformed Vicuna13B. Despite limitations, GPT-3.5 Turbo closely mirrored human inter-coder reliability, signalling potential for scalable framing function identification. This technique offers significant opportunities for quantitative frame analysis in enhancing research scalability within the field.","Discipline":"Data science; social science;communication","keywords":"Framing;LLM;Communication","approach":"generative AI","data":"texts","issue":"framing functions identification","geofocus":"computational methods","Corresponding Author":"Emily Robinson","chair":"Fabian Habersack","discussant":"Hung H. V. Nguyen","time":"Friday, 16:45-18:15"},{"slot":"Day1_5","session_title":"Textual Analysis of Political Positions","session":14,"id":40,"session_meansim":27965,"Title":"Silent conflict in parliament: Investigating the role of absences in scaling MPs’ ideological positions under conditions of high party unity","authors":"Marcelo Jenny; Fabian Habersack","full_text":"Silent conflict in parliament: Investigating the role of absences in scaling MPs’ ideological positions under conditions of high party unity\n\nThe existing literature on parliamentary behavior and party unity provides substantial insights into how legislators’ policy positions are scaled, by drawing primarily on their voting patterns and methods such as DW-NOMINATE or Optimal Classification. However, as MPs face various incentives to toe the party line, high party unity in many cases obstructs the use of these methods. Given this challenge, we know surprisingly little about the role of absenteeism. In this study, we argue that motivated absences can serve as an alternative dimension for scaling MPs’ ideological ideal points especially in cases like the Austrian National Council, which are marked by strong party discipline. Considering MPs’ absences from plenary voting sessions in the current legislative term of the National Council, we scale MPs’ ideal points and validate our measure externally against alternative scaling approaches. Our study contributes to our knowledge of how MPs navigate the challenging relationship between party allegiance and individual policy stances, especially in scenarios where voting records may not fully capture these nuances.","Discipline":"political science (comparative politics / parliamentarism)","keywords":"parliamentary behavior; vote scaling; party unity; austria","approach":"absence analysis","data":"plenary voting sessions","issue":"scaled MPs’ ideological positions under high party unity conditions","geofocus":"Austrian National Council","Corresponding Author":"Fabian Habersack","chair":"Fabian Habersack","discussant":"Hung H. V. Nguyen","time":"Friday, 16:45-18:15"},{"slot":"Day1_5","session_title":"Textual Analysis of Political Positions","session":14,"id":18,"session_meansim":27965,"Title":"Unpacking Translation Effects: Influences of Target Language Choice on the Results of Topic Modeling in Multilingual Environment","authors":"Nadezhda Ozornina","full_text":"Unpacking Translation Effects: Influences of Target Language Choice on the Results of Topic Modeling in Multilingual Environment\n\nFor the consolidation of multilingual texts for topic modeling, machine translation is one of the most prominent approaches. However, when applying machine translation, the impacts of target language choice on the outcomes of topic modeling remain unclear. This study tests these impacts via two strategies: (a) consolidating texts into one of the documents’ original languages and (b) translating texts into an intermediary language not present in the initial data. To compare possible outcomes, a corpus of parallel texts from the United Nations written in Russian and German (N = 3760) is examined. The entire dataset is consolidated into one of the original languages by translating Russian texts into German, followed by the application of structural topic modeling algorithms. The results are then compared with outcomes derived from topic modeling after translating the same data into an intermediary language (English). The similarity between parallel text collections for both models is measured using topical prevalence and topical content metrics. The findings indicate that using an intermediary language for machine translation leads to a more symmetrical distribution of topics and a higher percentage of overlapping top words compared to consolidating the texts into one of the original languages. However, translating into an intermediary language significantly reduces the vocabulary as compared to retaining some texts in their original language. The findings are validated on different numbers of topics and top words. Based on the results, the implications of using different target languages for machine translation are discussed and recommendations for future studies are developed.","Discipline":"Communication Science","keywords":"Topic Modeling, Machine Translation, Multilingual Text Analysis","approach":"topic modeling","data":"parallel texts from the United Nations written in Russian and German","issue":"influence of target language choice on topic modeling results","geofocus":"multilingual environment","Corresponding Author":"Nadezhda Ozornina","chair":"Fabian Habersack","discussant":"Hung H. V. Nguyen","time":"Friday, 16:45-18:15"},{"slot":"Day2_1","session_title":"China Media and Propaganda Analysis","session":27,"id":122,"session_meansim":37761,"Title":"Divisive Imagery: Affective Polarisation Analysis in Climate Activism Visuals","authors":"Petro Tolochko; Nicola Righetti; Annie Waldherr","full_text":"Divisive Imagery: Affective Polarisation Analysis in Climate Activism Visuals\n\nUnderstanding the impact of visual content on social media in the context of climate activism is pivotal for reasons such as communication efficacy, public engagement, mobilisation, and awareness. This paper attempts to investigate the realm of affective polarisation within climate activism, with a specific focus on the polarising effects induced by various climate change visuals. Recognising the critical role of emotions in shaping public opinion, this study seeks to understand the complexities of polarisation dynamics surrounding climate activism visuals.\n\nThe study focuses on social media comment threads which have been started with visual content as the root. Initial sentiment and emotion analysis, facilitated by a large language model, provides a granular understanding of the emotional landscape within social media threads. Affective polarisation is operationalised as information entropy of the emotional content of the thread to understand the degree of emotional divergence or convergence. This allows for the identification of polarising climate visuals and provides a quantitative measure of the extent of affective polarisation. Lower information entropy signifies a cohesive emotional response, indicating that the visual content resonates similarly with the audience. Conversely, a high information entropy reveals a spectrum of emotional reactions, suggesting that the visual content elicits higher polarisation. The visuals will further be categorised with unsupervised clustering methods to understand what types of content elicit more affective polarisation.\n\nThe study contributes valuable insights into the interplay between visual content and affective polarisation in the realm of climate activism on social media, appealing to researchers, policymakers, and activists alike.","Discipline":"Communication Science; Political Science","keywords":"Affective Polarisation; Information Entropy; Visual Content; Emotions Analysis","approach":"sentiment analysis","data":"social media comment threads","issue":"affective polarisation in climate activism visuals","geofocus":"Social media","Corresponding Author":"Petro Tolochko","chair":"Linette Lim","discussant":"Franziska Wagner","time":"Saturday, 10:00-11:30"},{"slot":"Day2_1","session_title":"China Media and Propaganda Analysis","session":27,"id":88,"session_meansim":37761,"Title":"Do Authoritarian Regimes Thrive in Less Transparent Social Media Spaces? Quasi-Experimental Evidence from Twitter","authors":"Allison Koh","full_text":"Do Authoritarian Regimes Thrive in Less Transparent Social Media Spaces? Quasi-Experimental Evidence from Twitter\n\nSocial media platforms have become increasingly important spaces in global information ecosystems, making them susceptible to manipulation by state actors seeking to advance their political agendas. While the transnational spread of state-sponsored content on social media has garnered widespread attention, the role of platforms in facilitating their reach remains largely unexplored. Using a quasi-experimental design, I examine the effects of unannounced platform policy changes on the influence of state actors from China, Iran, and Russia. Using digital traces from Twitter accounts linked to these countries, I analyze engagement metrics, tweet volumes, and topic models to identify patterns in online behavior before and after Twitter removed labels for government and state-affiliated media content. I argue that, after Twitter removed labels from state actors’ profiles, these accounts experienced increased engagement on Twitter and, in tandem, shifted their online behavior to increase their influence on the platform. In particular, I hypothesize that state-affiliated media particularly benefited from this policy change. My results confirm that, compared to official government and diplomat accounts, state-affiliated media outlets significantly increased their online activity and experienced more engagement on Twitter after the platform removed their profile labels. Further exploratory analyses highlight key differences between countries. While Chinese and Russian accounts significantly increased their online activity, only Russian accounts experienced a boost in engagement. Iranian accounts did not experience any significant increases in online activity or engagement. This research has important implications for understanding how authoritarian regimes might leverage the vulnerabilities of social media beyond their borders.","Discipline":"Political Science","keywords":"global authoritarianism; propaganda; disinformation; quasi-experiment; Twitter; social media","approach":"quasi-experimental design","data":"Twitter accounts linked to China","issue":"influence of state actors on social media","geofocus":"across countries","Corresponding Author":"Allison Koh","chair":"Linette Lim","discussant":"Franziska Wagner","time":"Saturday, 10:00-11:30"},{"slot":"Day2_1","session_title":"China Media and Propaganda Analysis","session":27,"id":32,"session_meansim":37761,"Title":"Hostile enemies: Measuring China’s de-legitimizing propaganda towards foreign journalists","authors":"Linette Lim","full_text":"Hostile enemies: Measuring China’s de-legitimizing propaganda towards foreign journalists\n\nThere is a substantial literature on how authoritarian states employ pro-regime propaganda to legitimate their power. However, less is known about how regimes use de-legitimizing propaganda to neutralize perceived threats and protect its authoritarian public sphere. Using the case of China, I show how the party-state employs de-legitimizing propaganda to discredit resident foreign journalists and the values they represent. These critical messengers, who view the role of the press as a watchdog, have been singled out for criticism in official speeches by current Chinese leader Xi Jinping. To quantify this de-legitimizing propaganda, I apply a semi-supervised scaling method to over 20,000 Chinese state media articles from 2003 to 2022 that mention foreign media. I do this by creating bespoke ‘seed words’ framing the institution of journalism as friendly and as hostile. I find that hostility towards the institution of journalism increased after potentially destabilizing events, and that Chinese state media’s hostile language tends to be targeted at specific media outlets in the US and UK.","keywords":"authoritarian propaganda; quantitative text analysis; chinese politics","approach":"semi-supervised scaling method","data":"Chinese state media articles","issue":"de-legitimizing propaganda towards foreign journalists","geofocus":"China","Corresponding Author":"Linette Lim","chair":"Linette Lim","discussant":"Franziska Wagner","time":"Saturday, 10:00-11:30"},{"slot":"Day2_1","session_title":"China Media and Propaganda Analysis","session":27,"id":26,"session_meansim":37761,"Title":"The Art of Storytelling: Pro-regime Narratives on Chinese Social Media","authors":"Ting Luo; Yan Wang","full_text":"The Art of Storytelling: Pro-regime Narratives on Chinese Social Media\n\nBuilding upon a sociological approach of framing and the narrative policy framework, this research develops a theoretical framework of event-based narratives and demonstrates the detailed storytelling in the pro-regime messages promoted on the Chinese social media platform Weibo (the Chinese counterpart of Twitter/X). We drew a random sample of all Weibo verified users and collected all their posts between January and May 2022, yielding a total of over three million posts by government, media, and celebrities users. We modified the package ‘RELATIO,’ developed by Ash, Gauthier, and Widmer (2023), with a linguistic algorithm that suits better with Chinese text processing. By capturing the action, the agent performing that action, and the patient being acted upon, we unraveled the storytelling and meaning construction from the subject-object-action network of four trending socio-economic events at the time—the Beijing Winter Olympics, the Russian invasion of Ukraine, the Shanghai Lockdown, and the chained mother likely to be a victim of human trafficking found in Jiangsu Province. We identified different mainstream consensus and communication tactics that differ between state-initiated events and non-state-initiated events, as well as domestic events and international events, from the narratives shown in the texts. We also compared the narratives by government, media, and celebrities’ accounts, as well as the diffusion pattern of key narratives based on their time stamps. Our work sheds new light on how pro-regime mainstream consensus is constructed and communicated in authoritarian regimes and provides a new theoretical framework to understand information control in authoritarian regimes.","Discipline":"Political communication; Political science","keywords":"Political narratives; Text mining; Authoritarian social media; Event-based narratives","approach":"narrative policy framework","data":"Weibo posts","issue":"pro-regime narratives on Chinese social media","geofocus":"China","Corresponding Author":"Ting Luo","chair":"Linette Lim","discussant":"Franziska Wagner","time":"Saturday, 10:00-11:30"},{"slot":"Day2_1","session_title":"China Media and Propaganda Analysis","session":27,"id":130,"session_meansim":37761,"Title":"Unraveling Government Discourse: A Decadal Analysis of State Heads' Communication on Environmental Issues in the Age of Social Media","authors":"Franziska Wagner","full_text":"Unraveling Government Discourse: A Decadal Analysis of State Heads' Communication on Environmental Issues in the Age of Social Media\n\nGovernment communication is a nuanced and strategic endeavour, particularly when navigating the dynamic landscape of social media, where it is marked by agency-centred or citizen-centred approaches. Social media, with its specific affordances, has served as the epicentre for public discourse, reshaping government-citizen relations. However, despite its pivotal role, there exists a notable gap in understanding the discursive elements employed for these purposes. This study delves into this gap by focusing on government communication pertaining to environmental issues, employing a comparative research methodology to scrutinise the discourse utilised by heads of states on social media over the past decade.\n\nThe selected timeframe corresponds not only to the surge in the prevalence and institutionalization of social media in government communication but also aligns with the escalating salience of environmental issues, particularly climate change. Leveraging advanced deep learning techniques, this research aims to unravel the intricate patterns within unstructured text data and multi-modal content found in social media communication. By doing so, it seeks to provide a comprehensive understanding of how governments articulate their stance on environmental issues in the digital age.\n\nIn offering a detailed analysis of government communication strategies, this research not only enhances our comprehension of democratic processes but also underscores the evolving landscape of political discourse in the age of social media. The findings hold significant implications for policymakers, communication strategists, and scholars alike, providing valuable insights into the evolving dynamics of governance, public engagement, and environmental advocacy.","Discipline":"Political Science; Communication Science","keywords":"government communication; deep learning; social media; multi-modality; environment; climate change","approach":"deep learning","data":"social media communication of state heads","issue":"government discourse on environmental issues","geofocus":"global","Corresponding Author":"Franziska Wagner","chair":"Linette Lim","discussant":"Franziska Wagner","time":"Saturday, 10:00-11:30"},{"slot":"Day2_1","session_title":"Moral Rhetoric Across Nations","session":10,"id":132,"session_meansim":40057,"Title":"Measuring a Multiverse of Morality — A Comparison of Automated Content Analysis Approaches in Party Manifestos","authors":"Marvin Stecker; Frederic R. Hopp","full_text":"Measuring a Multiverse of Morality — A Comparison of Automated Content Analysis Approaches in Party Manifestos\n\nMoral Foundations Theory predicts alignment between political ideologies and the support of certain moral values. Yet, while survey and experimental research on individuals' values supports the theory, research focussing on communication by political actors has found conflicting, inconclusive findings. At the same time, advances in automated text analysis have enabled new measurement strategies of operationalising moral foundations. We investigate whether this diversity of measurements might partially explain inconclusive findings, using a large corpus of political manifestos in four different languages. Our results show that, despite starting from the same theoretical concept, different measurements and underlying methodologies lead to very different results for scoring moral foundations. Replicating a previous study on political parties' ideology and their use of moral foundations, we find that this relationship can be rejected, partially supported or fully supported, depending on the methodology employed. We discuss the relevance of our findings for research on moral rhetoric using automated text analysis.","Discipline":"Political Science","keywords":"multiverse analysis; moral foundations; party manifestos","approach":"automated content analysis","data":"party manifestos in four languages","issue":"moral foundations theory and political ideologies","geofocus":"Multiple countries","Corresponding Author":"Marvin Stecker","chair":"Tobias Widmann","discussant":"Isabella Rebasso","time":"Saturday, 10:00-11:30"},{"slot":"Day2_1","session_title":"Moral Rhetoric Across Nations","session":10,"id":82,"session_meansim":40057,"Title":"Measuring and predicting the moralisation of political identities in open-ended responses across 7 countries.","authors":"Isabella Rebasso, Markus Wagner","full_text":"Measuring and predicting the moralisation of political identities in open-ended responses across 7 countries.\n\nPeople who describe out-partisans in terms of individual traits, rather than social groups, also report higher dislike for them. We argue that this is linked to the moralizing of political identities. Thinking that some are Conservatives because they are rich or religious, and others are Democrats because they are young or live on the East Coast, involves little moral judgement. Thinking that some are Conservatives because they are racist, while others are Democrats because they are selfish, assigns agency over a political identity to the individual. \nIn this paper, we aim to measure this moralisation of political identities (MPI), and references to social groups (RSG) in people’s descriptions of supporters of political parties in 7 countries (US, UK, Canada, Germany, Austria, Denmark, and Spain).\nTo measure MPI, we will use the multi-lingual moral dictionary developed by Simonsen and Widmann (2023). RSG will be measured using a similar dictionary-based approach. Further, we will investigate several covariates of both measures.\nWe expect that 1) MPI and RSG are negatively related, 2) (expressive) partisans are more likely to express MPI, less likely to use RSG, 3) partisan animosity is positively related to MPI, negatively related to RSG. We expect that people who have out-party contacts are less likely to use MPI, but more likely to use RSG in their descriptions of these groups. \nFinally, we will explore an interesting puzzle: People are more likely to view groups they dislike as homogenous. Yet, viewing partisans as homogenous would decrease the individualisation and moralisation of this identity. Measuring perceived ideological and sociodemographic homogeneity, we argue that only perceived ideological homogeneity is related to MPI. We expect a significantly weaker relationship with perceived sociodemographic homogeneity. We expect a positive relationship between RSG and perceived sociodemographic homogeneity but a significantly weaker relationship with perceived ideological homogeneity. \n\nData collection has started in December 2023 and will continue through spring 2024.","Discipline":"Political Science","keywords":"affective polarization, identity moralization, moral dictionary","approach":"moral dictionaries","data":"open-ended responses","issue":"moralisation of political identities","geofocus":"7 countries (US, UK, Canada, Germany, Austria, Denmark, and Spain)","Corresponding Author":"Isabella Rebasso","chair":"Tobias Widmann","discussant":"Isabella Rebasso","time":"Saturday, 10:00-11:30"},{"slot":"Day2_1","session_title":"Moral Rhetoric Across Nations","session":10,"id":31,"session_meansim":40057,"Title":"Moral Rhetoric and LGBTQ+ Issues: A Cross-National Analysis of Parliamentary Debates","authors":"Julius Diener; Clara Husson; Nicola Palma","full_text":"Moral Rhetoric and LGBTQ+ Issues: A Cross-National Analysis of Parliamentary Debates\n\nA relevant body of literature contends that, when discussing socio-cultural issues, such as abortion, immigration, and same-sex marriage, political actors tend to resort to moral rhetoric. Relying on the Moral Foundation Theory (MFT) we analyze parliamentary debates concerning legislation related to LGBTQ+ issues. The theory posits that these issues, involving matters of social justice, equality, and identity, can activate multiple moral foundations, contributing to the moralization of the political discourse. Following this perspective, we explore how legislators draw upon the five distinct moral foundations when discussing LGBTQ+-related laws. The research will also examine the role of political ideology in shaping the recourse to moral appeals, offering insights into the dynamics of the moralization process related to legislation on LGBTQ+ issues.\nWe test our expectations on parliamentary speeches from 5 parliaments in 4 languages, the UK, Germany, Austria, Spain and France, between 1988 and 2019. We apply a translated and validated version of the moral foundations dictionary to study the general levels and different foundations of morality over time and between party families. Overall, we find that levels of moralization of LGBTQ+ issues have remained relatively stable over time. We do however find notable changes in the moral foundations that some party families appeal to when addressing LGBTQ+ issues. Additionally, we zoom in on the time around the legalization of same-sex marriage in these countries. Our findings give nuance to the recent scholarly debate over polarization/moralization and the culture war theory.","Discipline":"Political Science","keywords":"LGBTQ+ Issues; Moral Foundations; Text Analysis","approach":"moral foundation theory","data":"parliamentary debates concerning LGBTQ+ legislation","issue":"moral rhetoric in politics","geofocus":"UK, Germany, Austria, Spain, and France","Corresponding Author":"Julius Diener","chair":"Tobias Widmann","discussant":"Isabella Rebasso","time":"Saturday, 10:00-11:30"},{"slot":"Day2_1","session_title":"Moral Rhetoric Across Nations","session":10,"id":11,"session_meansim":40057,"Title":"Rhetorical Norms: Radical Right Success and the Nature of Partisan Discourse","authors":"Tobias Widmann; Kristina Simonsen","full_text":"Moral-Emotional Elite Rhetoric and Voter Support\n\nDespite the extensive literature on the mobilizing effects of moral and emotional rhetoric, empirical evidence based on longitudinal data and various electoral levels remains limited. This study examines the mobilizing impact of moral-emotional elite rhetoric in Germany, particularly whether politicians can bolster voter support through specific moral-emotional appeals. Our approach utilizes computational text analysis with fine-tuned large language models and an original dataset that merges parliamentary speeches with electoral outcomes spanning over seven decades. We anticipate that the results from two-way fixed-effects regression models will offer profound insights into the electoral significance of elite communication. Additionally, these results are expected to reveal nuances in the mobilizing effects of various moral-emotional appeals. Overall, our findings have significant implications for the mobilization strategies of elites that extend beyond policy positions and the substantive content of political discourse.","Discipline":"Political Science","keywords":"computational text analysis; elite communication; moral emotions","approach":"computational text analysis","data":"parliamentary speeches and electoral outcomes","issue":"mobilizing effects of moral-emotional rhetoric","geofocus":"Germany","Corresponding Author":"Tobias Widmann","chair":"Tobias Widmann","discussant":"Isabella Rebasso","time":"Saturday, 10:00-11:30"},{"slot":"Day2_1","session_title":"Political Discourse Analysis Across Latin America","session":29,"id":138,"session_meansim":33514,"Title":"Government-Opposition Dynamics in Presidential Systems. A Comparative Analysis of Parliamentary Speeches in Latin America","authors":"Daniel Saldivia Gonzatti; Jan Schwalbach","full_text":"Government-Opposition Dynamics in Presidential Systems. A Comparative Analysis of Parliamentary Speeches in Latin America\n\nLegislative representatives are central figures of democratic systems. Their behavior has a decisive influence on policy outcomes and on the entire political process. In turn, their behavior is shaped by the institutional context, which differs significantly between presidential and parliamentary democracies. However, comparative analyses largely focus on parliamentary systems or case studies. We argue that central parliamentary dynamics such as government-opposition divide do not travel to presidential systems in Latin America due to the differences in legislative-executive relationships. We hypothesize that MPs from governing parties will be less united in parliamentary debate and less coordinated with the executive in presidential systems. Contrarily, electoral alliances in government should be more cohesive. To test our hypotheses, we gathered all parliamentary records from Chile, Mexico, and Uruguay for more than 20 years. This novel data set of full-text annotated speeches offers the possibility of comparing daily behavior of MPs in three presidential democracies with a common language. Using different text-as-data approaches, we analyze how united government and opposition parties are throughout various legislative cycles. Measuring party cohesion is important for our understanding of representation and for efficient policy processes. Our results shed light on our understanding of how MPs in presidential systems behave and to what extant this is dependent on country and time-specific factors.","Discipline":"Comparative politics","keywords":"parliaments; speeches; latin america","approach":"text-as-data analysis","data":"parliamentary records from Chile","issue":"government-opposition dynamics in presidential systems","geofocus":"Latin America","Corresponding Author":"Daniel Saldivia Gonzatti","chair":"Erkan Gunes","discussant":"Jana Bernhard","time":"Saturday, 10:00-11:30"},{"slot":"Day2_1","session_title":"Political Discourse Analysis Across Latin America","session":29,"id":109,"session_meansim":33514,"Title":"Ideological dimensions in the 21st century Latin America: A semantic scaling of presidential speeches","authors":"Camilo Cristancho","full_text":"Ideological dimensions in the 21st century Latin America: A semantic scaling of presidential speeches\n\nMass politics has a turbulent tradition in the Latin American context and has shifted from catchall parties which emphasized centrist appeals and leaders’ personalities to more populist parties who tend to converge on responses to economic crises and external factors. Ideological differences have played a fluctuating role in party attachments depending on national contexts and policy agendas. This implies the need to understand how ideology changes in time and across multiple dimensions in order to identify its role in mandate representation. This paper leverages two decades of everyday presidential speeches in multiple arenas in six countries (N=30,000) to estimate ideal points of presidential speeches in several dimensions using semantic scaling methods and largescale generative language models. It validates the results against external benchmarks and uses existing data on ideology, policy positions, and populism in Latin America in combination with semantic analyses to interpret the multiple dimensions of the ideological spectrum and the cognitive meanings attached to them. A twenty year comparative series of granular data from presidential speeches provides insight into the dynamics of party systems and how the left-right dimension reflects contextual risks and opportunities.","Discipline":"political science; latin american studies","keywords":"semantic scaling; large language models; presidential speech","approach":"semantic scaling","data":"presidential speeches","issue":"ideological dimensions in Latin America","geofocus":"six countries in Latin America (N=30,000)","Corresponding Author":"Camilo Cristancho","chair":"Erkan Gunes","discussant":"Jana Bernhard","time":"Saturday, 10:00-11:30"},{"slot":"Day2_1","session_title":"Political Discourse Analysis Across Latin America","session":29,"id":116,"session_meansim":33514,"Title":"Path Dependence in Instruction-Tuned LLM Inference: Evidence from Multiclass Text Classification Experiments with GPT-4","authors":"Erkan Gunes","full_text":"Path Dependence in Instruction-Tuned LLM Inference: Evidence from Multiclass Text Classification Experiments with GPT-4\n\nInstruction-tuned LLMs have potential to offer an alternative way to automate text classification tasks in social science research. Classifying large amount of text with instruction-tuned LLMs may require batch labelling as a cost-reducing strategy, especially with proprietary models. However, batch labelling involves presenting documents or text snippets in a sequential order within a single prompt and the autoregressive nature of most LLMs suggests the sequence information is presented in a prompt may affect LLM inference. In this work, I present results from experiments on zero-shot multiclass classification of congressional bill titles into policy issue topic categories using the GPT-4 model. Instead of presenting a single title in each prompt, I present bill titles in batches of one hundred titles. I conducted multiple experiments using the same random subset of the congressional bills dataset but shuffled the subset for each experiment. The results suggest that GPT-4's predictions in a batch are path dependent, but the strength of that phenomenon varies across topic categories. This phenomenon is especially pronounced in GPT-4's predictions for the “other” label, which pertains to private bills introduced in the US Congress. I discuss the implications of that phenomenon for text classification performance with instruction-tuned LLMs and the ways potential negative effects on classification performance could be addressed.","Discipline":"Political Science","keywords":"text classification, large language models, path dependence","approach":"instruction-tuned LLM inference","data":"congressional bill titles","issue":"path dependence in text classification","geofocus":"US","Corresponding Author":"Erkan Gunes","chair":"Erkan Gunes","discussant":"Jana Bernhard","time":"Saturday, 10:00-11:30"},{"slot":"Day2_1","session_title":"Political Discourse Analysis Across Latin America","session":29,"id":39,"session_meansim":33514,"Title":"Structuring Quantitative Image Analysis with Metric Depth","authors":"Christian Arnold;Andreas Küpfer","full_text":"Structuring Quantitative Image Analysis with Metric Depth\n\nWhen photographers---and other editors of image material---produce an image, they make a statement about what matters by situating some objects in the foreground and others in the background. While this prominence of objects is a key analytical category to qualitative scholars, recent quantitative approaches to automated image analysis have not yet made this important distinction but treat all areas of an image similarly. We rely on the pixels' image depth to detect such object prominence, which allows us to combine the best of the two worlds: The conceptual precision of distinguishing between foreground and background from qualitative analyses with the scalability of quantitative approaches. Joining those two aspects makes quantitative approaches conceptually more meaningful. We showcase our approach in two applications. Adding image depth increases the analytical leverage of the framework proposed in Torres (forthcoming). In a second application, we also illustrate how to use image depth to identify visual key messages in images of news articles.","Discipline":"Political Communication","keywords":"Image-as-Data;Visual Communication;Image Classification","approach":"metric depth","data":"images","issue":"object prominence in images","geofocus":"n/a","Corresponding Author":"Andreas Küpfer","chair":"Erkan Gunes","discussant":"Jana Bernhard","time":"Saturday, 10:00-11:30"},{"slot":"Day2_1","session_title":"Political Discourse Analysis Across Latin America","session":29,"id":126,"session_meansim":33514,"Title":"Trust in Government: An Integrated Approach through Closed and Open-Ended Survey","authors":"Jana Bernhard, Katharina Pfaff","full_text":"Trust in Government: An Integrated Approach through Closed and Open-Ended Survey\n\nOpen-ended survey responses represent a valuable resource for uncovering the nuances of public sentiment. This research delves into the specific context of trust in the Austrian government, with a primary focus on the challenge of extracting rich and meaningful information from open-ended survey data.\nThis study investigates a) trust in the Austrian government by analyzing open-ended survey responses through automated text analysis methods, including topic modeling, sentiment analysis, and named entity recognition and b) focuses on how well these automated approaches fare against manual analysis. The examination of 562 responses uncovers challenges associated with the brevity of participant inputs, particularly impacting traditional topic modeling algorithms such as LDA and BERTopic. Despite these challenges, GPT 3.5 exhibits promise in identifying significant topics, including populism and corruption. Sentiment analysis reveals an overarching negative sentiment in participants' comments on government trust. Named entity recognition identifies key actors, prominently the ruling parties (OEVP and the Green Party), with manual coding proving superior in capturing nuanced identifications. \nMethodologically, the study sheds light on challenges related to response brevity, automated sentiment attribution to specific actors, and the cost-effectiveness of automated analysis. Substantively, the research uncovers incongruities between responses to open-ended and closed-ended questions, prompting an inquiry into participant attributes influencing these disparities.\nIn conclusion, this research enriches the scholarly discourse on government trust and the application of automated text analysis in social research. The findings underscore the importance of meticulous planning and consideration of data characteristics when navigating the complexities of open-ended survey response analysis, ensuring a comprehensive understanding of trust dynamics in the Austrian government context.","Discipline":"Social Science Methods; Political Communication","keywords":"Open-Ended Responses; Topic Modeling; Sentiment Analysis; LLM; NER; Trust","approach":"automated text analysis","data":"open-ended survey responses","issue":"trust in government","geofocus":"Austria","Corresponding Author":"Jana Bernhard","chair":"Erkan Gunes","discussant":"Jana Bernhard","time":"Saturday, 10:00-11:30"},{"slot":"Day2_1","session_title":"Political Sentiment Analysis in Asia","session":20,"id":1,"session_meansim":36225,"Title":"Shifting Sentiments: Labor Market Policies and Online Views in Singapore’s Evolving Workforce","authors":"Meshal Alkhowaiter","full_text":"Shifting Sentiments: Labor Market Policies and Online Views in Singapore’s Evolving Workforce\n\nUnlike many advanced economies, Singapore lacks minimum wage laws and social security for\nforeign labor in its private sector. This has led private firms to heavily rely on low-cost foreign\nemployees over Singaporean workers, with foreign workers comprising about 47% of the\nworkforce in 2022. The government's support for this policy aimed to boost international\ncompetitiveness, drawing global financial and IT firms. Historically, this situation faced little\nopposition from citizens when Singapore’s population was small, and citizens could easily land a\npublic or private sector job.\nBut as Singapore’s population grew, frustration amongst citizens expressed online increased\ndramatically and this anger online was channeled towards the government, companies, and\nforeign labor. In the past 4 years in particular, unemployment increased amongst Singaporeans\nwhich led to various economic and labor demands by citizens to force Singaporean firms to\nemploy citizens (e.g., nationalization quotas) and this has coincided with an often xenophobic\nrhetoric in online forums against non-Singaporeans.\nUsing thousands of 2019-2023 posts from Hardwarezone, a Reddit-like forum popular among\nunemployed Singaporeans, I address key questions. Firstly, I explore whether online sentiment\namong the unemployed correlated with labor policy changes. Secondly, I analyze the\ngovernment's responsiveness to economic policy demands voiced online. Thirdly, I examine\nshifts in citizen sentiment and resentment before and after major labor reforms. Finally, I provide\nplausible explanations to explore why the Singaporean government was reactive to certain\neconomic demands by its citizens although the current government ruled by the PAP party faces\nlittle to no pressure internally and has been winning every election since 1959.","Discipline":"Comparative politics","keywords":"authoritarianism, nationalization quotas, economic demands","approach":"sentiment analysis","data":"posts on Hardwarezone forum","issue":"citizen sentiment towards labor market policies and foreign labor","geofocus":"Singapore","Corresponding Author":"Meshal Alkhowaiter","chair":"Joanna Strycharz","discussant":"Simon Luck","time":"Saturday, 10:00-11:30"},{"slot":"Day2_1","session_title":"Political Sentiment Analysis in Asia","session":20,"id":146,"session_meansim":36225,"Title":"The Tone of Power: Sentiment Analysis of the Russian Presidential Discourse","authors":"Olga Litvyak; Andrey Shadurskiy","full_text":"The Tone of Power: Sentiment Analysis of the Russian Presidential Discourse\n\nDespite advances in computational techniques, sentiment analysis of Russian-language data poses significant challenges due to linguistic complexities and a relative lack of resources, especially when compared to English. This study tackles these challenges by applying and evaluating various sentiment analysis methods, including both dictionary-based and machine learning (ML) approaches, to a unique corpus of Russian presidential speeches. In particular, the paper focuses on the Annual Presidential Addresses delivered by Vladimir Putin since 2012. Typically delivered at the start or end of the year the Annual Presidential Addresses to the Federal Assembly, despite having no legally binding power set the direction of policy agenda in Russia. As such, they are key to understanding the dynamics of Russia's political agenda. Our research initially focuses on the efficacy of rule-based methods, testing established lexicons like RuSentiLex and LINIS Crowd and assessing their adaptability to Russian text. Acknowledging the constraints of the dictionary approaches, we subsequently juxtapose dictionary-based outcomes with ML techniques, examining the trade-offs inherent in each method when applied to the Russian language. Our study not only sheds light on the political discourse in Russia but also contributes to the sentiment analysis field by exploring the application of diverse dictionary-based and ML techniques to less-resourced languages. Along with providing insights into the nuances of political communication in Russia we highlight the challenges and future perspectives in the sentiment analysis for Russian language texts.","Discipline":"Political Science","keywords":"Sentiment Analysis; Text analysis; Russia","approach":"sentiment analysis","data":"Russian presidential speeches","issue":"political discourse in Russia","geofocus":"Russia","Corresponding Author":"Olga Litvyak","chair":"Joanna Strycharz","discussant":"Simon Luck","time":"Saturday, 10:00-11:30"},{"slot":"Day2_1","session_title":"Political Sentiment Analysis in Asia","session":20,"id":128,"session_meansim":36225,"Title":"To what extent do news media influence policy responsiveness? Cross-national evidence from Europe","authors":"Simon Luck","full_text":"To what extent do news media influence policy responsiveness? Cross-national evidence from Europe\n\nTo what extent do the news media influence policy responsiveness? While existing empirical studies scrutinise the degree and conditions under which policymakers respond to public opinion, a gap exists concerning the systematic analysis of the impact of news media on policy responsiveness. Here, we analyse the impact of the speed and extent of negative sentiment changes in newspaper coverage on the likelihood of policy alignment with public opinion. Conceptually grounded in the rational anticipation mechanism, it is posited that politicians respond to voter preferences in anticipation of electoral sanctions. The hypothesis is that heightened speed and scope of negative sentiment changes incentivise politicians to align policies with public opinion as an anticipatory strategy against potentially negative public sentiment caused by bad press.\n\nThe empirical analysis spans six European countries over the period 1980-2014, encompassing 458 implemented policies. Using a dataset of more than 2.5 million news articles from 12 news agencies, self-developed R functions based on Latent Semantic Scaling are used for sentiment analysis to obtain speed and magnitude estimates. As there are no off-the-shelf methods for measuring the speed and extent of sentiment change in textual data, the development of different functions and operationalisations is discussed with regard to their conceptual accuracy and empirical validity. Contrary to expectations, preliminary findings do not support the hypothesis that heightened speed of sentiment changes increases policy alignment with majority opinion. Instead, the preponderance of positive sentiment changes, measured by their magnitude vis-à-vis negative sentiment, fosters more favourable conditions for greater policy congruence.","Discipline":"Computational Social Science","keywords":"Responsiveness; Media Effects; Text-as-Data;","approach":"sentiment analysis","data":"newspaper coverage","issue":"policy responsiveness to news media","geofocus":"Europe","Corresponding Author":"Simon Luck","chair":"Joanna Strycharz","discussant":"Simon Luck","time":"Saturday, 10:00-11:30"},{"slot":"Day2_1","session_title":"Political Sentiment Analysis in Asia","session":20,"id":144,"session_meansim":36225,"Title":"Validity of computational attitude and attitude strength measures for social media data","authors":"Joanna Strycharz; Gabriel Garlough-Shah; Joseph Yun","full_text":"Validity of computational attitude and attitude strength measures for social media data\n\nStudying latent constructs such as attitudes has been crucial in communication and advertising theory development. In recent research, it has been acknowledged that while attitudes are important for beliefs and behavior, strong attitudes have a greater impact. Thus, both attitude and attitude strength take an important role in communication research. In this study, we investigate how attitude and attitude strength measurements can be improved in the context of digital communication.\n\nSeveral measurement instruments are available when studying such latent constructs such as attitude. While questionnaires remain one of the most used instruments in communication research, text and social media analytics are gaining popularity. However, little is known about the validity of such computational instruments. In this contribution, we will share insights into validity of computational attitude measures for social media and provide researchers with considerations when applying them.\n\nTo provide a comprehensive overview, two types of validity are tested: 1) conceptual validity by correlating computational measures with measures external to text (indirect survey measures), 2) predictive validity by studying the ability of computational measures to predict outcomes in communication theories. Different sentiment analysis methods, dictionary-based approaches, and supervised machine learning (pre-trained encoder-based transformer models, our own models trained on a coded sample of social media posts, GPT4) are used.\n\nCurrently, social media posts on three viral campaigns have been coded for attitude and its strength. We are using this annotated dataset for finetuning. Data will be collected in January to apply the finetuned models in conceptual and predictive validity tests.","Discipline":"communication science; advertising research","keywords":"computational attitude; conceptual validity; predictive validity","approach":"sentiment analysis","data":"social media posts","issue":"validity of computational attitude and attitude strength measures","geofocus":"n/a","Corresponding Author":"Joanna Strycharz","chair":"Joanna Strycharz","discussant":"Simon Luck","time":"Saturday, 10:00-11:30"},{"slot":"Day2_2","session_title":"Climate Change Discourse Analytics","session":30,"id":12,"session_meansim":44218,"Title":"A Few Hypocrites: Few Shot Learning for Detecting Implicit Hypocrisy Accusations in Sustainability and Climate Debates","authors":"Paulina Garcia Corral; Avishai Green; Hendrik Meye; Myrthe Reuver; Anke Stoll; Xiaoyue Yan","full_text":"A Few Hypocrites: Few Shot Learning for Detecting Implicit Hypocrisy Accusations in Sustainability and Climate Debates\n\nHypocrisy allegations are pervasive in political discussions, particularly within liberal democracies that inherently exhibit a divide between rhetoric and actions. Yet, in deliberative democracy, the role of hypocrisy accusations remains uncertain. Do they contribute to democratic discourse by revealing contradictions and refining positions, or do they hinder it by diverting attention from crucial topics, such as climate change, and shifting the focus toward personal allegations? We delve into these inquiries within the context of climate change debates. Our focus is on understanding how accusations of hypocrisy vary between advocates and skeptics of climate action, as well as examining the frequency and nature of such accusations. To address these questions, we formulated an annotation codebook for hypocrisy allegations and annotated a dataset of comments in Climate Change subreddit posts (IAA alpha = 0.77). We subsequently tested our annotation scheme by fine-tuning traditional transformer-based models for benchmarking and also evaluated it with few-shot based language models. Our preliminary findings underscore the complexity of this task. In upcoming work, we will apply the model more broadly and use the results to analyze the nature of hypocrisy allegations by different actors within online climate-change discourse.","Discipline":"Political communication; Computational Social Science","keywords":"Hypocrisy; Climate change discourse; Few-shot learning","approach":"few-shot learning","data":"Reddit comments in Climate Change subreddit posts","issue":"implicit hypocrisy accusations in sustainability and climate debates","geofocus":"online climate change discourse","Corresponding Author":"Myrthe Reuver","chair":"Tristan J.B Cann","discussant":"Myrthe Reuver","time":"Saturday, 11:45-13:15"},{"slot":"Day2_2","session_title":"Climate Change Discourse Analytics","session":30,"id":27,"session_meansim":44218,"Title":"Climate advocates in the media: who they are and why it matters","authors":"Clara Vandeweerdt; Frederik Hjorth","full_text":"Climate advocates in the media: who they are and why it matters\n\nAnecdotally, climate change advocates in the Western world have a particular identity profile: we imagine them as young, highly educated urban residents, most often white and female. Other identities—older people, political conservatives, farmers—are associated with hesitancy towards climate action. If the people that are (and are not) portrayed as climate change advocates in the media fit these stereotypes, this could reinforce the perception that climate action is only compatible with the norms and interests of some social groups. This pre-registration plan covers a project documenting the gender, age, ethnicity, and urban/rural identities of all climate advocates on the radio and in newspapers in Germany, the UK and the US (Study 1); and experimentally investigating the persuasive effect of climate messages if the sender and receiver’s identity are a (mis)match (Study 2). Since Study 1 provides us with statistics about how often each demographic is actually featured in media outlets, we can combine the findings to estimate how portrayals in the current media environment influence people’s climate opinion. Ultimately, the results will speak to media and climate movements, who may be able to broaden the base for climate action by putting forward more diverse advocates. They may also highlight the importance of cross-cutting organizations (e.g. the Evangelical Environmental Network) for giving climate ownership to new groups. Finally, the project rolls out a new, general-purpose methodology for analyzing who pushes which issues in traditional media. We will present the pre-registration plan as well as preliminary descriptive findings.","Discipline":"Political science; computational social science","keywords":"Climate change; public opinion; media; political behavior; political communication","approach":"content analysis","data":"radio and newspapers in Germany","issue":"climate change advocacy","geofocus":"Western world","Corresponding Author":"Clara Vandeweerdt","chair":"Tristan J.B Cann","discussant":"Myrthe Reuver","time":"Saturday, 11:45-13:15"},{"slot":"Day2_2","session_title":"Climate Change Discourse Analytics","session":30,"id":79,"session_meansim":44218,"Title":"Computational Analysis of Manipulated Visual Content in Climate Change Discourse on Twitter","authors":"Isaac Bravo; Katharina Prasse; Stefanie Walter; Margret Keuper","full_text":"Computational Analysis of Manipulated Visual Content in Climate Change Discourse on Twitter\n\nThis study explores the effects of manipulated visual content on climate change debates on Twitter by answering the following research question: Do ‘real’ vs manipulated images about climate change on Twitter lead to different levels of engagement and interactions between believers and skeptics (deniers) in anthropogenic climate change? Combining social science and computer science, this study adopts a multimodal and computational approach combining automated image and text analysis to examine more than 700,000 images, their Tweets and replies by Twitter users in the year 2019. Using hash functions, and a \"lab-scenarios\" approach commonly used in computer science to detect manipulated images, we retrieve pairs of near-identical images, and analyse the manipulation between the real and the manipulated image within each pair. Then, we use different computational techniques Latent Semantic Scaling (LSS) to identify believers and skeptics (deniers) in Tweet texts and comments, and topic modelling (BERTopic) to explore how these users portray the engagement. Results reveal differences in the levels of engagement between manipulated and real images. These differences concern not only the type of visual content that engages deniers and believers but also encompass how these users react to it regarding valence. This research contributes to understanding the role of imagery in the climate change debate, introducing a novel and multimodal approach that combines advanced visual detection with multiple text analysis techniques.","Discipline":"social science; computer science; environmental communication","keywords":"manipulated content; image analysis; climate change.","approach":"computational image analysis","data":"Twitter images and texts","issue":"manipulated visual content in climate change discourse","geofocus":2019,"Corresponding Author":"Isaac Bravo; Katharina Prasse","chair":"Tristan J.B Cann","discussant":"Myrthe Reuver","time":"Saturday, 11:45-13:15"},{"slot":"Day2_2","session_title":"Climate Change Discourse Analytics","session":30,"id":6,"session_meansim":44218,"Title":"No Planet B? Party Competition on Climate Change","authors":"David Schweizer","full_text":"No Planet B? Party Competition on Climate Change\n\nParty competition in Western Europe is increasingly shaped by climate change. Natural disasters such as floods, droughts, and wildfires are particularly tangible phenomena of climate change. Parties’ responses to these events have the potential to shape public opinion and influence individual attitudes on the critical matter of climate change. While scholars have examined the effect of natural disasters on public opinion and citizens extensively in recent years, political parties themselves have been neglected so far. \n\nBuilding on theories of spatial and temporal issue competition, I argue that natural disasters have a differentiated impact on political parties. First, however, such drastic events require a political response. Therefore, the salience of climate change should increase among all parties. Second, I expect that polarization increases. That is, parties’ positions towards climate policies and their tone diverge more strongly depending on party family as well as the respective national party landscape. Finally, I argue that these effects are also moderated by the spatial and cultural distance to the disaster. \n\nI test my expectations comparatively by analyzing parties’ press releases and parliamentary speeches in Germany between 2010 and 2022. Using a supervised machine learning approach, I generate salience and positional measures and construct a time-series cross-sectional party-month data set. These data allow me to exploit the occurrence of natural disasters for causal effect estimation. The results contribute to our understanding of party competition in general and, more specifically, how climate change is exacerbating the divide between green and populist radical right parties.","Discipline":"political science","keywords":"climate change;party competition;text analysis","approach":"supervised machine learning","data":"party press releases and parliamentary speeches in Germany","issue":"climate change and party competition","geofocus":"Germany","Corresponding Author":"David Schweizer","chair":"Tristan J.B Cann","discussant":"Myrthe Reuver","time":"Saturday, 11:45-13:15"},{"slot":"Day2_2","session_title":"Climate Change Discourse Analytics","session":30,"id":73,"session_meansim":44218,"Title":"The colour of climate change: analysing climate imagery at scale","authors":"Tristan J.B. Cann; Ned Westwood, Sylvia Hayes, Ranadheer Malla, Saffron O'Neill","full_text":"The colour of climate change: analysing climate imagery at scale\n\nClimate change, and associated impacts on modern life, see significant media coverage. In addition to news reports, actors both supporting and opposing climate action make extensive use of a range of communication platforms to spread their messages and influence peoples’ values, attitudes and behaviours. \n\nVisual content plays a key role in climate engagement and are an important part of setting the communicative ‘frame’. In previous work, we have used qualitative approaches to understand how images are used to frame climate protest, extreme weather events and energy infrastructure but challenges remain for evaluating these images at scale with computational methods.\n\nWe address this gap by exploring image datasets through computational analysis. We analysed the results of a Getty Images search for photographs tagged as “smokestacks” or “wind turbines” using the HSV representation. We found differences in colour use (hue, saturation, brightness) across these types of energy infrastructure. Images of smokestacks commonly included red and orange hues, for example, through featuring dramatic sunsets, connoting ‘danger’. Turbine imagery on the other had included green hues, to connote a ‘natural’ and ‘green' energy choice. \n\nWe will extend these preliminary computational efforts using object detection and image embedding techniques. Using these techniques in concert will allow us to better understand previous patterns of image composition such as overrepresentation of beaches in coverage in heatwaves. Direct image analysis addresses concerns from visual communications scholars around the use of text as an intermediary when studying images and clearer understanding of its shortcomings.","Discipline":"Computer Science; Geography; Political communication","keywords":"Media imagery; image decomposition; visual framing","approach":"computational analysis","data":"Getty Images search","issue":"climate imagery","geofocus":"scale","Corresponding Author":"Tristan J.B Cann","chair":"Tristan J.B Cann","discussant":"Myrthe Reuver","time":"Saturday, 11:45-13:15"},{"slot":"Day2_2","session_title":"Comparative Political Communication Across Nations","session":5,"id":152,"session_meansim":52411,"Title":"Agenda Setting on Digitalisation and its Socioeconomic Implications in Germany","authors":"Stephanie Gast Zepeda","full_text":"Agenda Setting on Digitalisation and its Socioeconomic Implications in Germany\n\nDigitalisation is a megatrend, and how policymakers talk about digitalisation and its socioeconomic implications matters, as it reflects the way the digital transformation is shaped. Even in the digital age, traditional media still act as an intermediary between policymakers and the public, and understanding the flow of information between policymakers and traditional media remains crucial. \nI relate German parliamentary debates to media coverage on digitalisation and its socioeconomic implications, to analyse to what extent media reporting influences the agenda and framing on digitalisation supported by policymakers over time, and who dominates the agenda.\nFor the German parliamentary debates, I rely on Rauh & Schwalbach’s (2020) ParlSpeech V2 dataset covering speeches until 2019, and scrape more recent parliamentary speeches from the Bundestag Open Data service. As for media coverage, I rely on newspaper articles and transcripts of news broadcasting programmes in German public TV. I first use hierarchical topic models to identify and compare the contexts in which digitalisation is talked about in the traditional media versus in parliament. I then do a multilevel network analysis, where I model the flow of information between policymakers and media over time, by identifying when issues become prominent and when political parties or individual politicians are mentioned in articles related to digitalisation. \nThis approach helps us understand how close or distant policymakers and the media are to one another in their agenda on digitalisation and its socioeconomic implications, and how certain topics and information spread over time.","Discipline":"Political Communication","keywords":"agenda setting, digitalisation, network","approach":"hierarchical topic models and multilevel network analysis","data":"German parliamentary debates and newspaper articles","issue":"digitalisation and its socioeconomic implications in Germany","geofocus":"Germany","Corresponding Author":"Stephanie Gast Zepeda","chair":"Nicolai Berk","discussant":"Luis Sattelmayer","time":"Saturday, 11:45-13:15"},{"slot":"Day2_2","session_title":"Comparative Political Communication Across Nations","session":5,"id":34,"session_meansim":52411,"Title":"Changing the channel: Investigating the congruence in issue salience and issue framing between party election manifestos and candidate tweets","authors":"Elise Frelin;Louise Luxton","full_text":"Changing the channel: Investigating the congruence in issue salience and issue framing between party election manifestos and candidate tweets\n\nOne of the primary functions of party manifestos during election campaigns is to communicate a probable policy platform to appeal to voters. Less examined is how that policy platform is communicated by the party and its candidates across other channels, in particular, on social media. This is important, as it is often argued that voters do\nnot read party manifestos and instead are reliant on mediums such as social media for information about parties and candidates. Hence, whether and how candidates communicate their policy platforms to voters on different channels matters. The audience on platforms such as Twitter tends to be highly politically aware, including journalists from\nthe traditional media. Twitter is thus a useful arena for disseminating the party’s important manifesto issues in a strategic way. Moreover, as Twitter is a dynamic medium, issue emphasis can change over time to reflect tactical priorities. \n\nWe employ keyword topic modelling to examine issue attention in the election manifestos and candidate tweets of parties during election campaigns across several European countries. In order to construct and maintain ownership perceptions, candidates should be focused on emphasising their parties’ strategically selected manifesto issues in their own communication channels. Hence, we expect issue salience to be similar across channels. However, given that the party manifestos and candidates’ Twitter are different in terms of audience, where Twitter reaches a specific, highly interested audience and manifestos rarely reach outside of the party, we expect that issue framing will be different to take advantage of these contrasts. The results offer nuanced insight into parties’ strategic campaign communication across different channels and indicate a more prominent role of manifestos and traditional campaign materials than studies of social media often indicate.","Discipline":"political science","keywords":"keyword topic modelling;election campaigning;issue competition","approach":"topic modeling","data":"party election manifestos and candidate tweets","issue":"issue salience and framing between party election manifestos and candidate tweets","geofocus":"Europe","Corresponding Author":"Elise Frelin","chair":"Nicolai Berk","discussant":"Luis Sattelmayer","time":"Saturday, 11:45-13:15"},{"slot":"Day2_2","session_title":"Comparative Political Communication Across Nations","session":5,"id":112,"session_meansim":52411,"Title":"From Print to Post: Comparing issue emphasis and negative campaigning in traditional and social media","authors":"Chendi Wang; Ofra Klein","full_text":"From Print to Post: Comparing issue emphasis and negative campaigning in traditional and social media\n\nThis study delves into the dynamics of political communication, examining issue emphasis and conflict representation across traditional mass media and social media platforms. It scrutinises political parties' campaign strategies in five European countries (Germany, France, UK, Poland, and Italy) from 2015 to 2022, aiming to discern differences in issue-specific campaigning between these two media environments. The research further explores the prevalence and nature of negative campaigning, particularly parties' targeting of other parties and individuals. By comparing the incidence of such strategies in traditional and social media, the study highlights potential variations in the conduct and manifestation of negative campaigning across diverse media contexts. Empirical evidence is garnered from a unique electoral campaign dataset for newspaper coverage analysis. To dissect social media data, we employ Large Language Models (LLMs) to classify the issue, target, and sentiment towards the target and issue in social media posts. This innovative methodology allows for a thorough and nuanced exploration of the shifting terrains of political communication in the digital age. Our findings illuminate the complexities of issue representation and negative campaigning within and across media types, enriching our understanding of contemporary political communication practices.","Discipline":"Political Science","keywords":"party politics; political campaign; social media,","approach":"comparative analysis","data":"newspaper coverage and social media posts","issue":"issue emphasis and negative campaigning in traditional and social media","geofocus":"Europe (Germany, France, UK, Poland, Italy)","Corresponding Author":"Chendi Wang","chair":"Nicolai Berk","discussant":"Luis Sattelmayer","time":"Saturday, 11:45-13:15"},{"slot":"Day2_2","session_title":"Comparative Political Communication Across Nations","session":5,"id":111,"session_meansim":52411,"Title":"Measuring issue ownership in media text. A computational text analysis of 25 years of media coverage in Germany and France","authors":"Malo Jan; Luis Sattelmayer","full_text":"Measuring issue ownership in media text. A computational text analysis of 25 years of media coverage in Germany and France\n\nIssue ownership is a widely used concept in theories of party competition and electoral behavior. For measurement, scholars have relied on ownership perception by voters through surveys and hand-coding of party communications and media. While valuable, these measures are limited and fail to capture the dynamics of issue ownership outside electoral campaigns. In this paper, we leverage CSS methods to develop a new measure of issue ownership based on media coverage. Following Walgrave et al.’s (2015) distinction, we try to identify to what extent parties are associated with and deemed competent on issues in the French and German media over the last 25 years. We constructed a unique corpus of millions of articles of French and German newspapers during that period. First, we use NER identifying documents mentioning the parties and associated politicians. To measure how parties’ association with issues, we then classify the main issue of these sentences according to the CAP coding scheme using existing supervised classifiers. Thirdly, we train transformer models to classify whether parties are portrayed as more or less competent when associated with these issues in their media coverage. The results provide insights into the nature of the issue ownership, the development and thematic changes of party competition in France and Germany. By using our developed method and the collected data, we provide a novel measurement method that goes beyond existing hand measurement and is scalable. Lastly, we make a substantive contribution to the literature on the impact of issue ownership on party competition.","Discipline":"Political Science","keywords":"issue ownership; named-entity recognition; supervised learning","approach":"computational text analysis","data":"media coverage in Germany and France","issue":"issue ownership","geofocus":"France and Germany","Corresponding Author":"Luis Sattelmayer","chair":"Nicolai Berk","discussant":"Luis Sattelmayer","time":"Saturday, 11:45-13:15"},{"slot":"Day2_2","session_title":"Comparative Political Communication Across Nations","session":5,"id":61,"session_meansim":41226,"Title":"Measuring public opinion using newspaper comments","authors":"Nicolai Berk; Laura Bronner; Laurenz Derksen; Francisco Tomás-","full_text":"Measuring public opinion using newspaper comments\n\nHow representative are online newspaper comments of broader public opinion? Online newspaper comments are often treated by readers, journalists and political actors as reflecting the public’s attitudes on key issues; however, they are written by a small, unrepresentative subset of newspaper readers, who are themselves a subset of citizens. Using a novel dataset of all submitted (published and unpublished) comments from several Swiss and German online newspapers, we describe the process of measuring commenters’ attitudes towards specific issues, comparing the use of document embeddings, latent semantic scaling, as well as natural language inference (NLI). Based on the resulting measure, we discuss the extent to which shifts in public opinion on important political topics can be tracked and even predicted by newspaper comment data. We take advantage of the varied sources (different newspapers) and the panel structure of these comments (tracking the same users over time) to address some of the same issues that increasingly plague public opinion polls: unrepresentative respondents; differential nonresponse following political events; and (newspaper) “house” effects.","Discipline":"Political Science; Political Communication","keywords":"Online Discourse; Scaling; Public Opinion","approach":"document embeddings","data":"online newspaper comments","issue":"measuring public opinion","geofocus":"Switzerland and Germany","Corresponding Author":"Nicolai Berk","chair":"Nicolai Berk","discussant":"Luis Sattelmayer","time":"Saturday, 11:45-13:15"},{"slot":"Day2_2","session_title":"Policy Language Analysis","session":6,"id":110,"session_meansim":413,"Title":"A global analysis of drought policy documents","authors":"Taís Maria Nunes Carvalho; Jan Sodoge; Mariana Madruga de Brito","full_text":"A global analysis of drought policy documents\n\nDroughts can be approached either by their physical aspects or by how they affect socioeconomic systems. Either way, droughts are not all the same, and must be managed differently depending on the context they occur. Drought plans usually are prepared at the water basin, city, or country level to provide drought management guidelines for practitioners and policymakers. These documents can be a valuable source of information on how drought impacts differ across regions and how water users and stakeholders respond to them. However, a systematic analysis of these has been hampered by the wide variety of languages involved and the unstructured format of the data. To address this, here we use natural language processing to evaluate (i) drought framing, (ii) drought impacts, and (iii) the adaptation strategies applied. We collected 144 drought plans across 93 countries and 13 languages. We used topic modeling and named entity linking to analyze them. We found out regional similarities between adaptation measures, which differ across countries based on the management/political approach (e.g. centralized or decentralized water management). Further, we discover that drought policies differ across countries based on their experiences with drought, i.e. regions with a long history of drought have more detailed and diverse adaptation measures. Our methodology showcases the effective application of natural language processing techniques to systematically assess planning documents. This enables the identification of synergies among regions facing these disasters.","keywords":"drought plans; topic modeling; adaptation","approach":"natural language processing","data":"drought policy documents","issue":"drought management and adaptation strategies","geofocus":"93 countries","Corresponding Author":"Taís Maria Nunes Carvalho","chair":"Sofia Gil-Clavel","discussant":"Marina Schenkel","time":"Saturday, 11:45-13:15"},{"slot":"Day2_2","session_title":"Policy Language Analysis","session":6,"id":23,"session_meansim":413,"Title":"How leaders communicate policies on social media: Insights from COVID-19 in Brazil and the US","authors":"Marina Schenkel","full_text":"How leaders communicate policies on social media: Insights from COVID-19 in Brazil and the US\n\nThe COVID-19 pandemic underscored the central role of social media in governmental communication of public health responses. This study focuses on Brazil and the United States, cases where national leaders often contradicted public health guidance and fuelled polarisation against governors. Notably, the politicisation of COVID-19 measures varied across the spectrum of recommended policies. Even within similar policy domains (e.g., vaccine mandate vs. vaccine availability), distinct communicative strategies were employed. Existing literature lacks a comprehensive examination of which policy types experienced greater polarisation and the underlying factors driving the communication of contrarian viewpoints. This study investigates the nuances of health emergency response narratives during the pandemic's three-year span, utilising a novel dataset comprising over 175,000 Facebook posts, 107,500 Instagram posts, and 14,500 YouTube video transcripts from the official accounts of 92 governors and presidents in Brazil and the US (January 2020 - December 2022). I rely on an open-source Large Language Model approach to categorise the corpus into Regulatory, Distributive, and Redistributive policies as per Lowi's framework (1972). I further examine the association between ideology, populist rhetoric, and political alignment with the federal government in shaping contrarian perspectives within each policy category. This paper shows the divergent strategies of American and Brazilian political executive leadership in a major crisis, emphasizing the influence of policy type on social media communication.","Discipline":"Political Science; Public Policy","keywords":"Political Communication; Social Media; Public Policy; COVID-19; Text Analysis","approach":"natural language processing","data":"social media posts from official accounts","issue":"communication of policies during COVID-19 pandemic","geofocus":"Brazil and US","Corresponding Author":"Marina Schenkel","chair":"Sofia Gil-Clavel","discussant":"Marina Schenkel","time":"Saturday, 11:45-13:15"},{"slot":"Day2_2","session_title":"Policy Language Analysis","session":6,"id":75,"session_meansim":413,"Title":"Reassessing the Political Landscape of the United Nations General Assembly (UNGA): A Novel Approach to Identifying Issue-specific Co-Voting Patterns","authors":"Daniel Voelsen; Paul Bochtler; Rebecca Majewski","full_text":"Reassessing the Political Landscape of the United Nations General Assembly (UNGA): A Novel Approach to Identifying Issue-specific Co-Voting Patterns\n\nThe paper proposes a new approach to classifying all UNGA resolutions from session 49 (1995/1996) to the present. In a first step, the approximately 9,000 resolutions are parsed from their PDF format into individual paragraphs, resulting in a novel corpus of about 250.000 paragraphs of text on international politics. We then coded a training dataset, used to enhance a pre-trained language model (DeBERTaV3), which classifies the paragraphs into issue categories. Next, the resolutions are assigned to issue categories based on the percentage of paragraphs classified as belonging to a particular category (with variable cut-off points).\nThis fine-grained approach to identifying issue categories goes beyond what existing datasets of UNGA resolutions provide. Using the example of \"global health\", we illustrate how this approach makes it possible to track the level of attention to what has long been considered a \"niche issue\" in the context of the UNGA.\nOur approach to issue categories allows for taking the study of co-voting patterns within the UN one step further. For decades, scholars have used UNGA voting records as a proxy for state preferences, interpreting correlations in co-voting as indicative of political alignment among states. Governments also pay close attention to who votes with them, as seen recently in the votes on the war in Ukraine. However, these analyses have not been able to account for differences between states on specific issues. Using our approach to identifying issue categories, we can show subtle shifts in alliances depending on the issue at hand.","Discipline":"political science","keywords":"United Nations General Assembly; co-voting; DeBERTaV3","approach":"natural language processing","data":"UNGA resolutions","issue":"issue-specific co-voting patterns","geofocus":"United Nations General Assembly","Corresponding Author":"Rebecca Majewski","chair":"Sofia Gil-Clavel","discussant":"Marina Schenkel","time":"Saturday, 11:45-13:15"},{"slot":"Day2_2","session_title":"Policy Language Analysis","session":6,"id":105,"session_meansim":413,"Title":"Taking the Green Pill","authors":"Lorcan McLaren","full_text":"Taking the Green Pill\n\nEmotions drive support for climate action policy, as well as individual pro-climate behaviours. Two key factors in eliciting an emotional response in the context of climate change are: (1) moral language, and (2) psychological distance. Using speeches from the European Parliament (2014-2024), this paper develops and validates automated methods to measure moral language and psychological distance in text. Moral language is conceptualised in terms of Moral Foundations Theory, while psychological distance is operationalised as linguistic concreteness with a focus on the spatial and temporal dimensions. Moral language and psychological distance have independently been shown to influence climate action attitudes and behaviour in experimental settings. In larger-n settings, existing state-of-the-art methods for measuring moral language and psychological distance rely on dictionaries or other bag-of-words approaches. This paper seeks to address the inherent shortcomings of these methods by employing large language models [LLMs] in the classification process. In doing so, I shed light on the framing of environmental issues, and generate insights into the dynamics of climate politics.","Discipline":"Political science","keywords":"text-as-data; emotion; persuasion; climate politics","approach":"natural language processing","data":"speeches from the European Parliament","issue":"climate action policy and behaviors","geofocus":"Europe","Corresponding Author":"Lorcan McLaren","chair":"Sofia Gil-Clavel","discussant":"Marina Schenkel","time":"Saturday, 11:45-13:15"},{"slot":"Day2_2","session_title":"Policy Language Analysis","session":6,"id":48,"session_meansim":413,"Title":"Using Natural Language Processing and Networks to Automate Structured Literature Reviews: An Application to Farmers Climate Change Adaptation","authors":"Sofia Gil-Clavel; Tatiana Filatova","full_text":"Using Natural Language Processing and Networks to Automate Structured Literature Reviews: An Application to Farmers Climate Change Adaptation\n\nThe fast-growing number of research articles makes it problematic for scholars to keep track of the new findings related to their areas of expertise. Furthermore, linking knowledge across disciplines in rapidly developing fields becomes challenging for complex topics like climate change that demand interdisciplinary solutions. The rise of machine-learning-supported text analysis has been instrumental in processing thousands of articles. Yet, how text relationships are built remains a black box for domain experts, making it difficult to relate connected concepts to existing theories conceptualizing cause-effect relationships and permitting hypothesis building and testing. This paper presents an approach to sensibly use Natural Language Processing by extracting articles' findings to synthesize variable relations using networks while relating to key concepts dominant in relevant disciplines. As an example, we apply our methodology to analyze farmers’ adaptation to climate change and compare the results with mainstream text summarization methods. Results show that using Natural Language Processing and networks descriptively offers an interpretable way to synthesize literature review findings that outperform mainstream automated text synthesis methods. This methodology gives not only the direction and the frequency of the association between the words but also the frequency the word appears in the articles, which is instrumental when performing literature reviews.","Discipline":"Natural Language Processing; Data Visualization; Computational Social Science.","keywords":"Natural Language Processing; Networks; Literature Review; Interpretative","approach":"natural language processing","data":"thousands of research articles","issue":"climate change adaptation","geofocus":"various disciplines","Corresponding Author":"Sofia Gil-Clavel","chair":"Sofia Gil-Clavel","discussant":"Marina Schenkel","time":"Saturday, 11:45-13:15"},{"slot":"Day2_2","session_title":"War Propaganda Analytics","session":12,"id":142,"session_meansim":41559,"Title":"Application of Multimedia Knowledge Graph: Systematic Narratives of the 2022 Ukraine War in US and Chinese Media","authors":"Seo Eun Yang; Xuechen Chen","full_text":"Application of Multimedia Knowledge Graph: Systematic Narratives of the 2022 Ukraine War in US and Chinese Media\n\nThis study introduces a multimedia knowledge graph that automatically creates a coherent, structured knowledge from unstructured and diverse multimedia data to analyze the strategic narratives of the 2022 War in Ukraine as portrayed in US and Chinese media. The coverage of the Russian invasion of Ukraine has exhibited significant variations within these two media ecosystems, along with their respective relationships with Russia. Following the framework of strategic narrative structure (Roselle, Miskimmon, and O’Loughlin, 2014), this research provides a quantitative analysis of the differences in media narratives between the US and China. It involves extracting complementary information from both text and related images, integrating this cross-modal knowledge, and measuring narrative similarities across news articles based on how they portray the world's structure, key actors involved, and its mechanisms. By utilizing a cutting-edge pre-trained deep learning model within a multimedia knowledge graph setup, the methodology automatically extracts textual content, textualizing visual features, delineates their interconnectedness, and tracks changes over time. This study reveals that the Chinese news outlets tended to focus more on the diplomatic and economic implications of conflicts while the American press emphasized the military and humanitarian aspects of the war.\n\nMiskimmon, A., O'loughlin, B., & Roselle, L. (2014). Strategic narratives: Communication power and the new world order. Routledge.","Discipline":"Computational Social Science;Political Communication;International Relations","keywords":"Knowledge Graph; Quantitative media discourse analysis; deep learning","approach":"multimedia knowledge graph","data":"US and Chinese media","issue":"strategic narratives of the 2022 Ukraine War","geofocus":"US and China","Corresponding Author":"Seo Eun Yang","chair":"Aidar Zinnatullin","discussant":"Seo Eun Yang","time":"Saturday, 11:45-13:15"},{"slot":"Day2_2","session_title":"War Propaganda Analytics","session":12,"id":29,"session_meansim":41559,"Title":"Dissecting Disagreements in Russian Pro-War Telegram Channels: Unraveling the Dynamics of Authoritarian Regime Consolidation","authors":"Aidar Zinnatullin; Marco Albertini; Giampiero Giacomello","full_text":"Dissecting Disagreements in Russian Pro-War Telegram Channels: Unraveling the Dynamics of Authoritarian Regime Consolidation\n\nThe paper explores the contention and agreement within the universe of Russian pro-war Telegram channels, demonstrating the extent of consolidation and dissent on issues related to the regime's stability.\nWe study the 20 most popular channels according to the number of subscribers. We collected all the posts from February 24, 2022, until October 14, 2023. The corpus contains approximately one million posts with relevant metadata.\nFirst, we used network analysis to map the connections within this universe of channels, considering their re-posting patterns. To provide the overview of the discourse produced, we conducted structural topic modeling (Roberts et al., 2019) of the posts, using as a covariate the network cluster where a channel belongs. Next, we used Name Entity Recognition to detect the actors discussed by the channels (e.g., generals, the Russian Ministry of Defence, the President's Administration, Wagner mercenaries, etc.). We use Latent Semantic Scaling (Watanabe, 2021) to measure the sentiment change of the pro-war channels towards these actors. An essential aspect of our work involves the analysis of Yevgeny Prigozhin’s role on the agenda of pro-war channels. We employ a difference-in-differences methodology to explore the changes in content before and after his failed mutiny and subsequent demise.\nThe findings are expected to contribute to a deeper understanding of digital discourse in the Russian autocracy, concerning consolidation and conflict among the supporters of the decision to start the war in Ukraine, thereby offering insights into the regime's internal coherence and potential fault lines.","Discipline":"Political Science","keywords":"Latent Semantic Scaling; Topic Modeling; Network Analysis; difference-in-differences Russia; Ukraine; Telegram","approach":"network analysis","data":"Telegram channels","issue":"disagreements within Russian pro-war Telegram channels","geofocus":"Russia","Corresponding Author":"Aidar Zinnatullin","chair":"Aidar Zinnatullin","discussant":"Seo Eun Yang","time":"Saturday, 11:45-13:15"},{"slot":"Day2_2","session_title":"War Propaganda Analytics","session":12,"id":137,"session_meansim":41559,"Title":"The Role of Telegram in the Russo-Ukrainian War: A New Propaganda Model","authors":"Roman Kyrychenko; Aleksi Knuutila","full_text":"The Role of Telegram in the Russo-Ukrainian War: A New Propaganda Model\n\nThe ongoing Russo-Ukrainian war has witnessed the emergence of social media as a significant battleground for propaganda. This study focuses on the role of the messaging platform Telegram in disseminating propaganda during the conflict. By analyzing a corpus of Telegram channels related to the war, comprising over 14 million posts, this research aims to uncover the strategies employed by Russian and Ukrainian factions to influence public opinion. The study proves that Russia employs a new propaganda model to disseminate the narratives efficiently for the enemy's auditory.\n\nThe study uses various machine learning methods to analyze the content and structure of the Telegram channels. Content analysis and clustering techniques, such as sentence embeddings and UMAP, identify similarities and differences in the narratives shared by different channels. Graph analysis, including the PageRank algorithm and Louvain method, is employed to detect influential channels and community structures within the network.\n\nPreliminary findings suggest that both pro-Russian and pro-Ukrainian channels actively engage with each other, challenging the notion of echo chambers. Mediating channels, including Russian liberal media outlets and anonymous channels disseminating \"insider\" information, play a significant role in facilitating interaction between the opposing factions. The study also reveals the presence of coordinated networks of channels which share similar characteristics and content.\n\nOverall, this research contributes to understanding the role of social media platforms, specifically Telegram, in disseminating propaganda during the Russo-Ukrainian war. The findings shed light on the strategies employed by both sides to shape public opinion.","Discipline":"sociology; computational social science","keywords":"propaganda; Telegram; network analysis","approach":"machine learning","data":"Telegram channels","issue":"propaganda during the Russo-Ukrainian war","geofocus":"Russia and Ukraine","Corresponding Author":"Roman Kyrychenko","chair":"Aidar Zinnatullin","discussant":"Seo Eun Yang","time":"Saturday, 11:45-13:15"},{"slot":"Day2_2","session_title":"War Propaganda Analytics","session":12,"id":66,"session_meansim":41559,"Title":"The United Nations and the Russia-Ukraine War in News Media Worldwide: Supervised Machine Learning and Generative AI-based Analysis","authors":"Michal Parizek; Jakub Stauber","full_text":"The United Nations and the Russia-Ukraine War in News Media Worldwide: Supervised Machine Learning and Generative AI-based Analysis\n\nThe Russian invasion of Ukraine represents a direct attack on the international order. The Russia-Ukraine war also brings to the spotlight the United Nations and the UN Security Council (SC) as the centrepiece of global governance. On the one hand, the UN is heavily criticised for its inability to maintain security and compel Russia to stop its aggression. On the other hand, the UN is understood by many states especially in the Global South as the only global body to represent their core interests. For the legitimacy of the UN, which of these images of the UN dominates, globally, is of utmost importance. We offer the first estimate of the prevalence of the images of the UN in the context of the war in online news media across a high number of states. We do so by deploying natural language processing tools to analyse over 5 million news articles from 136 states in 2022-2023. First, we use a supervised ML model based on a fine-tuned deBERTa-v3 large with classification accuracy of 80% for the different images of the UN. Second, we use open-source (Llama-2) and closed-source (GPT-4) generative AI models to detect the nuanced ways in which the UN is portrayed in the context of the war. Combining the results from these techniques, we identify major geographical variation in how the UN is depicted in the context of the war in news media worldwide.","Discipline":"International Relations; Comparative Politics","keywords":"News media; machine learning; LLM; generative AI; United Nations; war; Ukraine","approach":"supervised machine learning","data":"online news articles","issue":"portrayal of the United Nations in relation to the Russia-Ukraine War","geofocus":"136 states","Corresponding Author":"Michal Parizek","chair":"Aidar Zinnatullin","discussant":"Seo Eun Yang","time":"Saturday, 11:45-13:15"},{"slot":"Day2_2","session_title":"War Propaganda Analytics","session":12,"id":42,"session_meansim":41559,"Title":"Uncovering disinformation: analyzing the thematic patterns and emotional content of Hungarian fake news portals during the COVID-19 pandemic and the Ukrainian war","authors":"Orsolya Ring, László Kiss","full_text":"Uncovering disinformation: analyzing the thematic patterns and emotional content of Hungarian fake news portals during the COVID-19 pandemic and the Ukrainian war\n\nThe increasing number and the speed of the spread of fake news is a growing challenge in the fight against disinformation. Experience shows that the number and importance of fake news is amplified during elections, pandemics, armed conflicts, and after terrorist attacks. Our research question does not focus on what percentage of the content of \"misleading news sites\" is content that can be classified as fake news using some fact-checking mechanism but on the content structure of online portals that are deemed unreliable by the fact-checking site(s), regardless of whether the texts they contain provide disinformation or misinformation.\nOur work aims to explore and quantify the thematic patterns and focus shifts of fake news by analyzing the content of several major Hungarian fake news portals between 2019 and 2023. In our research, we investigate the changes in thematic patterns using LDA topic modeling and network analysis and apply state-of-the-art large language models to analyze the different emotions generated by these fake news.\nOur preliminary results clearly show how these portals change their focus in response to the crisis and how fear and anger dominate the emotions they express. A common feature of fake news content seems to be that it links value-neutral content with a shocking title, lead, possibly with an explicitly negative conclusion, and negative additional content. We expect that once features of fake news can be identified using artificial intelligence, our research method can be applied to other languages too.","Discipline":"Political Science","keywords":"fake news, emotion analysis, fine-tuned BERT model, topic modeling, network analysis","approach":"topic modeling and network analysis","data":"major Hungarian fake news portals","issue":"disinformation during the COVID-19 pandemic and the Ukrainian war","geofocus":"Hungary","Corresponding Author":"Orsolya Ring","chair":"Aidar Zinnatullin","discussant":"Seo Eun Yang","time":"Saturday, 11:45-13:15"},{"slot":"Day2_3","session_title":"Media and Identity","session":26,"id":21,"session_meansim":49823,"Title":"Detecting gender stereotypes using word embeddings: Evidence from media coverage of the Spanish general elections","authors":"Michele Scotto Di Vettimo; Kaitlin Senk","full_text":"Detecting gender stereotypes using word embeddings: Evidence from media coverage of the Spanish general elections\n\nNews media plays a powerful role in elections by transmitting information about candidates to voters. Yet, previous research demonstrates that the news media portray men and women in different ways, often attributing gendered stereotypes that characterize women as weak leaders, less competent, and that focus disproportionately on physical appearance. With more women entering prominent and visible political positions, we investigate whether these changing dynamics in women’s representation affect how women candidates are portrayed by the news media. We use text data collected from 84,891 news media articles about the Spanish national elections held in July 2023. These data were collected over 1,958 unique news sources over an 18 day period leading up to, and including, the election. This election featured three women in prominent party leadership positions. We use a word embeddings approach to determine whether the news media portrays women candidates in Spain in gender stereotypical ways. Word embeddings provide an unsupervised machine learning method for detecting gender biases in the language used to describe women and men candidates. Specifically, we use a list of words containing gendered traits that are stereotypically associated with men and women. We then assess the strength of the association between politicians and these gendered traits to determine whether certain gender stereotypes are applied systematically to men and women candidates. This analysis will help us determine whether having women represented in prominent and visible political positions can help mitigate the portrayal of men and women in gender stereotypical ways in the news media.","Discipline":"political science","keywords":"gender stereotypes; word embeddings; spain","approach":"word embeddings","data":"news media articles","issue":"gender stereotypes in media coverage of elections","geofocus":"Spain","Corresponding Author":"Kaitlin Senk","chair":"Sean Palicki","discussant":"Kaitlin Senk","time":"Saturday, 15:15-16:45"},{"slot":"Day2_3","session_title":"Media and Identity","session":26,"id":125,"session_meansim":49823,"Title":"Exploring Coder Bias: An Investigation of Human and LLM-based Classification of Racism in News Media","authors":"Ahrabhi Kathirgamalingam; Fabienne Lind; Jana Bernhard; Hajo G. Boomgaarden","full_text":"Exploring Coder Bias: An Investigation of Human and LLM-based Classification of Racism in News Media\n\nContent analysis is a fundamental tool in the social sciences. Although its methodology focuses on various aspects such as the reliability and validity of coding, potential sources of disagreement at the level of the coders themselves are rarely systematically investigated. This three-part study aims to explore this gap by focusing on the case of identifying racism in news media, a critical endeavor in addressing discriminatory practices and fostering social equality. While the identification of racism is increasingly addressed by employing supervised classification methods using crowdcoding, reliable and valid measurement of this latent construct is often reported as a challenge.\nIn a first step, we conduct a survey experiment involving over 100 paid crowdworkers and 300 texts from German mainstream and far-right news media as coding tasks. By including pre- and post-questionnaires, coder training, and 15 coding tasks per coder, we aim to investigate the influence of socio-demographics, political attitudes, awareness and experience of racism, and prior coding experience on coding decisions and disagreements. In a second step, we use the insights from our human annotations to design prompt experiments to systematically explore and potentially reduce biases in annotations produced by generative LLMs. Thirdly, we test and compare prompts, human annotation, and their respective biases for different generative LLMs, including GPT 3.5, GPT 4, or Bing.\nThis comprehensive approach not only seeks to enhance reliability assessment but also fosters a deeper understanding of the intricacies in coding processes, ultimately bolstering research integrity for both manual and computational content analyses.","Discipline":"Communication Science","keywords":"coder bias; crowdcoding; generative LLM; racism classification; annotator bias","approach":"survey experiment","data":"German news media texts","issue":"racism in news media","geofocus":"Germany","Corresponding Author":"Ahrabhi Kathirgamalingam","chair":"Sean Palicki","discussant":"Kaitlin Senk","time":"Saturday, 15:15-16:45"},{"slot":"Day2_3","session_title":"Media and Identity","session":26,"id":159,"session_meansim":49823,"Title":"On the topic of modeling: A framework for the comparison of topic modeling approaches used to map discourse about the digital backlash","authors":"Malene Hornstrup Jespersen","full_text":"On the topic of modeling: A framework for the comparison of topic modeling approaches used to map discourse about the digital backlash\n\nOver the past thirty years, the global permeation of the internet has brought many advantages to our lives. However, concern has been growing about the disadvantages of constant connectivity. This movement, often called the digital backlash, has brought critique of how connectivity threatens our capacity for attention, our privacy online, and our mental health – just to mention a few things.\n\nThe current paper presents a mapping of how these critiques have evolved from 1990-2022, following the advent and expansion of the internet. Based on a novel dataset of 11 million Danish news media articles referencing digital technology, we use topic models to analyze which types of critique have been most prominent in public debates and how debates have shifted over time.\n\nTo do this, we first need to choose a topic modeling algorithm to capture dynamic topic developments. Choosing the best topic model is not a simple feat, and one often overlooked in social science literature. We developed a comprehensive framework to evaluate and choose between topic models to be used in social science discourse analysis, and present evaluation of three models: Latent Dirichlet Allocation (LDA), Hierarchical Stochastic Block Modeling (hSBM), and BERTopic. The models were evaluated on their ability to produce topics that are coherent, distinct, and easily interpretable by humans, and their ability to represent how language within particular topics develops over time. It was found that BERTopic outperformed LDA and hSBM on our data.\n\nIn the paper, we present preliminary insights gained from BERTopic of how criticism of digital technologies has developed in news media over the past thirty years.","approach":"BERTopic","data":"Danish news media articles","issue":"critique of digital technologies","geofocus":"Denmark","Corresponding Author":"Malene Hornstrup Jesperse","chair":"Sean Palicki","discussant":"Kaitlin Senk","time":"Saturday, 15:15-16:45"},{"slot":"Day2_3","session_title":"Media and Identity","session":26,"id":76,"session_meansim":49823,"Title":"The Effect of #MeToo on Rape Myths in the Media: A Global Multilingual Analysis","authors":"Hubert Au; Joana Perrone; Chico Camargo","full_text":"The Effect of #MeToo on Rape Myths in the Media: A Global Multilingual Analysis\n\nThe #MeToo movement has been influential across over 85 countries and has remained an active part of modern feminist movements for since its inception. Scholars have argued that media representations and constructions are an important part of feminist activism and scholarship. This study examines if and how #MeToo has structurally altered the way sexual violence is represented in news media across 47 countries through the frequency of rape myths. Drawing from feminist scholarship that have employed content and thematic analyses to identify the varieties and categories of rape myths, this study employs multilingual natural language processing methods to extend these analyses to an international scale. Drawing from recent methodological developments, GPT-4 is utilized in augmenting qualitative annotations for subsequent model fine-tuning. Bayesian Structural Time Series are subsequently applied to understand the causal impact before and after the movement took off in each country. Scholars have also theorized that countries with greater political openness should be more receptive to change demanded by social movements. We find that, in most countries, the #MeToo movement did not significantly lower the frequency of rape myths in the media, and in the countries that it did the frequency often appeared to revert back to pre-2017 levels by 2022. Political openness did not explain which countries were found to have significant change or not.","Discipline":"social movements; communications; gender","keywords":"#metoo; feminism; digital activism; computational framing; social movements; data augmentation; time series","approach":"natural language processing","data":"news media across 47 countries","issue":"representation of sexual violence in media","geofocus":"global multilingual analysis","Corresponding Author":"Hubert Au","chair":"Sean Palicki","discussant":"Kaitlin Senk","time":"Saturday, 15:15-16:45"},{"slot":"Day2_3","session_title":"Political Emotions and Bias","session":22,"id":87,"session_meansim":30922,"Title":"Beyond Neutrality: A Longitudinal Analysis of Gender and Party Dynamics in the Tone of US Political Media Reporting","authors":"Aliya Andrich","full_text":"Beyond Neutrality: A Longitudinal Analysis of Gender and Party Dynamics in the Tone of US Political Media Reporting\n\nMedia coverage has a significant impact on electoral outcomes, making the sentiment expressed in political reporting crucial for candidate success. Previous research on gender differences in media coverage tone has produced inconsistent findings, often relying on outdated data and limited samples. This study aims to fill these gaps by examining the evolution of positive and negative media coverage of 1,095 U.S. politicians over the past decade.\nUsing state space models, we performed a longitudinal time series analysis of more than 600,000 news articles from 18 national US media outlets. Our dataset of about 8,000 human-labeled sentences, mentioning the politicians of interest, was used to fine-tune the RoBERTa model to filter out neutral content. A fine-tuned version of the SieBERT model was then used to to classify the remaining sentences into positive and negative sentiments.\nThe classification results indicate that although political reporting in the past decade was predominantly neutral, both female and male politicians received a higher proportion of negative than positive coverage. Male Republicans emerge as the most negatively portrayed group, facing heightened negativity during both election seasons and routine political periods over the past decade. Interestingly, in most election years of the 2010s, Democratic and Republican women received slightly more positive coverage.\nThis study highlights the significance of analyzing the tone of news coverage, uncovering subtle distinctions between genders and political parties. A deeper understanding of gender dynamics in media portrayals is critical to fostering a more balanced political landscape and promoting informed voter decision-making.","Discipline":"Media Communication; Political Communication","keywords":"gender bias; sentiment classification; longitudinal analysis","approach":"state space models","data":"US national media outlets","issue":"gender and party dynamics in political media reporting","geofocus":"US","Corresponding Author":"Aliya Andrich","chair":"Mary Sanford","discussant":"Indira Sen","time":"Saturday, 15:15-16:45"},{"slot":"Day2_3","session_title":"Political Emotions and Bias","session":22,"id":117,"session_meansim":30922,"Title":"Disentangling the Perception of Political Ideology among Political Elites: Evidence from Open-Ended Survey Responses of German Candidates","authors":"Lukas Warode","full_text":"Disentangling the Perception of Political Ideology among Political Elites: Evidence from Open-Ended Survey Responses of German Candidates\n\nPolitical ideology is an ubiquitous part of day-to-day politics and a widely studied field in political science. However, it is not easy to measure how political actors perceive ideology. In this paper I argue that it is important how political elites perceive ideology: By analyzing the sentiment of political elite’s perceptions towards left and right ideology in open-ended survey responses, one can show to what extent and in what direction the perception is biased. I theorise that political elites in states with former exposure to right authoritarianism perceive ideology in a biased way: They perceive left ideology more positive than right ideology. Drawing on evidence from Germany as one of the countries with the most severe history of far-right authoritarianism, I show that German politicians perceive left ideology more positive than right ideology. In analysing 3 waves of GLES candidate surveys (2013, 2017, 2021), I present an identification strategy based on a sentiment analysis of open-ended survey responses, using a) sentiment dictionaries (Rauh 2018) and b) a sentiment classification model based on BERT (Guhr et al. 2020). The results show that there is indeed a left bias in political ideology among German candidates. Left politicians consistently perceive left ideology positively and right ideology negatively, while this pattern is not reflected among right politicians, except for the AfD in 2017 and 2021. The findings have broader implications for political representation in general as voters should expect their elected representatives to have a shared and unbiased perception of ideological beliefs.","Discipline":"Political Science","keywords":"Political ideology, sentiment analysis, political elites, open-ended survey responses, BERT, dictionaries","approach":"sentiment analysis","data":"open-ended survey responses","issue":"perception of political ideology among political elites","geofocus":"Germany","Corresponding Author":"Lukas Warode","chair":"Mary Sanford","discussant":"Indira Sen","time":"Saturday, 15:15-16:45"},{"slot":"Day2_3","session_title":"Political Emotions and Bias","session":22,"id":57,"session_meansim":30922,"Title":"Unraveling the Link Between Political Discourse on Climate Change in EU Party Manifestos and Climate Policy Implementation","authors":"Mary Sanford; Silvia Pianta; Nicolas Schmid","full_text":"Unraveling the Link Between Political Discourse on Climate Change in EU Party Manifestos and Climate Policy Implementation\n\nHow do political parties discuss climate change and climate policies in their manifestos? To what extent does such discourse correlate with countries’ climate policy output? With more ambitious climate action required to achieve global climate mitigation goals, climate change has become increasingly salient in the political arena. However, the literature currently lacks comprehensive analyses of political parties’ climate policy positions and the extent to which parties’ electoral programs are translated into climate policy output. In this paper, we build a dataset of party positions on climate change and climate policy instruments for most parties active in all EU countries from 1980 to 2021. To do so, we test an annotation pipeline combining manual annotations and with a set of multilingual transformers (Roberta-XLM, Manifestoberta, and pol_emo_mDeBERTa2), and then apply it to the corpus of manifestos made available by the Manifesto Project. To investigate the correlation between political discourse in the manifestos of winning coalitions and the amount and stringency of climate policies that are actually implemented, we combine this new dataset with data on enacted climate policies from the OECD’s Climate Actions and Policy Measurement Framework. In doing so, this paper makes the following contributions: 1) The expansion of the Manifesto Project dataset to include specific climate policy variables for EU countries; 2) The implementation of an efficient and replicable pipeline for multilingual text classification for political discourse; and 3) The evaluation of correlations between party positions on climate policy and actual climate mitigation policy outcomes.","Discipline":"party politics; political economy; climate policy; NLP","keywords":"multilingual text classification; transformers; climate policy; manifesto project","approach":"multilingual transformers","data":"party manifestos from the Manifesto Project dataset","issue":"climate change political discourse and policy implementation","geofocus":"EU countries","Corresponding Author":"Mary Sanford","chair":"Mary Sanford","discussant":"Indira Sen","time":"Saturday, 15:15-16:45"},{"slot":"Day2_3","session_title":"Political Emotions and Bias","session":22,"id":124,"session_meansim":30922,"Title":"Women in Power: Holistic Measures of Gender Bias against Politicians on Reddit","authors":"Indira Sen","full_text":"Women in Power: Holistic Measures of Gender Bias against Politicians on Reddit\n\nEven though women are increasingly being elected to be heads of states, they are still underrepresented in Government in almost all countries. They face several challenges when running for positions of power: from securing campaign funds to balancing family lives. But researchers note that one of the biggest hurdles women face is how society perceives them and their quest for power. Politicians evoke images of strength and leadership, traits which are at odds with traditional gender stereotypes where women are described as the weaker sex. Therefore, female politicians are perceived as reaching outside of their gender role, and voters stereotypes with negative qualities of politicians such as dishonesty, but not with their positive traits. This often leads to unwinnable situations where women are excluded from political positions simply on the basis of their gender. Given the gatekeeping effect of stereotypes on female candidates, it is crucial to uncover the mechanisms that drive attitudes towards them.\n\nIn this work, we present a multi-country, social media-based study on the role of gender in seeking political power, using a large-scale dataset of political discourse on Reddit. Inspired by the subtype theory and the psychology of sexism, particularly ambivalent sexism, we formulate a method to assess both hostile, benevolent and stereotype-based sexism to shed light on how female presidential candidates are evaluated compared to their male counterparts. We devise methods to measure attitudes towards politicians on fine-grained political, social, and personal issues and analyze how it differs based on the gender of the candidate.","Discipline":"Computational Social Science","keywords":"stance detection, computational political science, gender bias","approach":"ambivalent sexism theory","data":"Reddit political discourse","issue":"gender bias against female politicians","geofocus":"Multiple countries","Corresponding Author":"Indira Sen","chair":"Mary Sanford","discussant":"Indira Sen","time":"Saturday, 15:15-16:45"},{"slot":"Day2_3","session_title":"Political Language Models","session":23,"id":92,"session_meansim":40703,"Title":"Context Augmentation for the Statistical Analysis of Text","authors":"Marc Ratkovic; Haoyu Zhai","full_text":"Context Augmentation for the Statistical Analysis of Text\n\nLarge language models have proven uncanny at predicting new text and providing correct answers from even complex questions. These tools, though, are tuned for prediction and not inference: they offer no uncertainty estimates, leaving the researcher unable to conduct even basic statistical inference. In order to address this shortcoming, we introduce \"context augmentation\" as a means for connecting statistical inference with large language models, using only the readily available outputs of these models. The basic idea is to use model-generated contexts around given observed strings of text in order to estimate the sampling uncertainty in the data. We derive statistics with valid p-values and confidence intervals in two problems: the two-sample problem, of establishing whether two samples of observed strings have a statistically significant difference, and the regression problem, where the researcher may want to know if observed strings may vary with observed covariates, such as time or group membership. Theoretically, we treat the context around each strings as unobserved data around the observed string. In the two-sample problem, we profile the contexts out, replacing each context with the most likely context, and generate a profile likelihood ratio statistic. In the regression problem, we integrate over the contexts in order to derive a distance between strings that can allow us to generate a set of covariates that can then be included as either an independent or dependent variable in a regression. Simulations and applied examples from political science illustrate the method's use and utility.","Discipline":"Political science; Data science; Statistics","keywords":"Large language models; statistical inference; semiparametric inference","approach":"statistical analysis","data":"text data","issue":"connecting statistical inference with large language models","geofocus":"political science","Corresponding Author":"Marc Ratkovic","chair":"Kai-Robin Lange","discussant":"Lukas Isermann","time":"Saturday, 15:15-16:45"},{"slot":"Day2_3","session_title":"Political Language Models","session":23,"id":47,"session_meansim":40703,"Title":"Disentangling the past: Automatic network reconstruction from unstructured textual sources using large language models","authors":"Felipe Perilla Reyes","full_text":"Disentangling the past: Automatic network reconstruction from unstructured textual sources using large language models\n\nThis study explores the use of Large Language Models (LLMs), particularly ChatGPT, in overcoming the challenges of extracting network data from unstructured textual sources for political science research. Traditional methods, including question-answering systems (QAS), face accuracy issues and transferability constraints across diverse contexts, crucial for both contemporary and historical analyses. ChatGPT, with its superior accuracy and transfer ease across diverse contexts, presents a promising alternative, despite concerns regarding its tendency to produce 'hallucinations' or factually incorrect outputs. By implementing an event and relation extraction system using ChatGPT's API, this paper evaluates its effectiveness in accurately reconstructing static and dynamic kinship networks from elite genealogies (including the extent of hallucinations), a task representative of broader applications in social science. The findings offer significant insights into producing reproducible, transparent, and cumulative knowledge in social sciences, highlighting LLMs' potential in advancing methodological approaches in political science research.","Discipline":"Political Science; Historical Political Economy","keywords":"Network data collection; Large Language Models; ChatGPT; Information extraction (relations and events)","approach":"large language models (LLMs)","data":"unstructured textual sources","issue":"reconstructing network data for political science research","geofocus":"n/a","Corresponding Author":"Felipe Perilla Reyes","chair":"Kai-Robin Lange","discussant":"Lukas Isermann","time":"Saturday, 15:15-16:45"},{"slot":"Day2_3","session_title":"Political Language Models","session":23,"id":148,"session_meansim":40703,"Title":"From Valence to Positional Conflict? How Parties’ compete on Climate Change","authors":"Lukas Isermann","full_text":"From Valence to Positional Conflict? How Parties’ compete on Climate Change\n\nFor the longest time, climate change was construed as a prime example for a valence issue. The political competition rested mainly on selective emphasis of the issue based on underlying cross-party consensus on the policy goals of successful mitigation of, and adaptation to climate change. However, in recent years climate change issues got increasingly politically intertwined with a range of different policy fields and goal conflicts. Today, most proposed climate mitigation efforts are linked to other policy fields like taxation, transport, energy, housing, or even international relations and incorporate fundamental changes to our industrial economies and our way of life. Especially when framing climate change mitigation as a trade-off with economic growth, parties and the electorate nowadays clearly take very different positions. Even though this transformation in the political conflict around climate change can be observed in everyday politics, scientific inquiries into the emergence and nature of today’s conflict lines are scarce.\n\nUsing topic modelling, text-scaling and an automated classification algorithm on political manifestos, parliamentary speeches and press releases to establish parties emphasis of and position on climate change, I investigate how party positioning on climate change (1) developed over time, and (2) compares to parties’ positioning in a number of related policy fields. I expect positional competition and criticism of climate protection to emerge and intensify with growing attention to the issue, and parties to increasingly emphasize climate change when their overall positioning on related issues enables them to easily implement climate change mitigation in the respective policy profile.","Discipline":"Political Science","keywords":"Climate Change; Party Competition; Issue Competition","approach":"topic modeling","data":"political manifestos","issue":"climate change","geofocus":"n/a","Corresponding Author":"Lukas Isermann","chair":"Kai-Robin Lange","discussant":"Lukas Isermann","time":"Saturday, 15:15-16:45"},{"slot":"Day2_3","session_title":"Political Language Models","session":23,"id":13,"session_meansim":40703,"Title":"How Moral Emotional Elite Rhetoric Shapes Political Norms","authors":"Tobias Widmann","full_text":"How Moral Emotional Elite Rhetoric Shapes Political Norms\n\nResearch in the field of political science increasingly recognizes the significance of social norms in shaping political behavior. However, the role of emotions as a factor influencing these norms remains largely understudied. Emotional reactions from elites can serve as cues about what behaviors are deemed appropriate within a specific context. In this study, I posit that the emotional expressions of politicians, or their absence, can shape public acceptance of actions that violate norms. I test this hypothesis in the context of right-wing political violence in Germany. By analyzing a large dataset of elite communication on social media, I employ large language models and a staggered difference-in-differences approach to identify how elites utilize different moral-emotional appeals following norm violations. Triangulating this observational evidence with survey experiments, I further demonstrate that the emotional responses of politicians can either safeguard or undermine norms concerning political violence among their partisan supporters. These findings have substantial implications for how politicians may uphold or erode crucial democratic norms by delineating the boundaries of acceptable societal behavior.","Discipline":"Political Science","keywords":"computational text analysis; moral emotions; political norms","approach":"large language models","data":"social media communication from elites","issue":"shaping political norms through moral-emotional appeals","geofocus":"Germany","Corresponding Author":"Tobias Widmann","chair":"Kai-Robin Lange","discussant":"Lukas Isermann","time":"Saturday, 15:15-16:45"},{"slot":"Day2_3","session_title":"Political Language Models","session":23,"id":96,"session_meansim":40703,"Title":"Identifying economic narratives in large text corpora - an integrated approach using Large Language Models","authors":"Kai-Robin Lange, Matthias Reccius, Tobias Schmidt","full_text":"Identifying economic narratives in large text corpora - an integrated approach using Large Language Models\n\nIn economics, narratives are increasingly seen as crucial drivers of economic decision-making. Despite recent progress, detecting economic narratives in large text data remains challenging. While simple narrative-like structures can be extracted through standard NLP tasks like topic modeling and aspect based sentiment analysis, capturing more nuanced and complex narratives that provide deeper insight into the economic landscape is far from trivial. Recent advancements involve using a sequence of interconnected tasks, each executed by tailored smaller language models. Yet, these multi-step pipeline approaches are prone to error-cascades and error propagation and struggle when applied to texts that may deviate only slightly in structure or style from their training datasets. Hence, these methods are not capable of effectively detecting true economic narratives defined as stories of economic relevance that suggest a causal relationship between two events. To overcome these limitations, we propose employing a large language model (LLM) for the identification of economic narratives. The comprehensive capabilities of LLMs allow for a more streamlined, single-step analysis. Our approach leverages hand-labeled data to fine-tune advanced open-source LLMs, which we then compare with the few-shot performance of GPT-4. This methodology combines the broad language understanding of foundational LLMs with the specialized economic knowledge of expert annotators. The outcome is a robust and reproducible open-source model. While our method is capable of tracking a variety of economic discourses, in our application, we specifically focus on narratives related to inflation. We validate our model by comparing its performance against manually annotated newspaper articles.","Discipline":"economics","keywords":"narrative economics, large language models, lora","approach":"Large Language Models","data":"large text corpora","issue":"identifying economic narratives","geofocus":"n/a","Corresponding Author":"Kai-Robin Lange","chair":"Kai-Robin Lange","discussant":"Lukas Isermann","time":"Saturday, 15:15-16:45"},{"slot":"Day2_3","session_title":"Politics of Europe Under Scrutiny","session":19,"id":157,"session_meansim":40896,"Title":"Emergency Politics in the European Union: Analyzing Urgency, Unity, and Discretion in EU Policymaking","authors":"Lukas Hetzer","full_text":"Emergency Politics in the European Union: Analyzing Urgency, Unity, and Discretion in EU Policymaking\n\nThe successive and overlapping crises faced by the EU over the last years have led researchers to identify a new modus operandi in EU policymaking, that of emergency politics (Kreuder-Sonnen & White, 2022) or crisisification (Rhinard, 2019). However, there is no scientific consensus on whether EU emergency politics impede or foster democratic deliberation. While some scholars argue that crises are ‘exploited’ to increase political and public support and to amplify executive authority (e.g., Boin et al., 2009; Kreuder-Sonnen & White, 2022), Truchlewski, Schelkle and Ganderson (2021) demonstrate that crisisification may also stimulate deliberation and compromise. This paper contributes to this debate by analyzing whether and under which circumstances policymaking in the EU becomes more efficient, unified, and discretionary when facing crises. \nI test these expectations with data from the newly constructed ParlLawSpeech dataset (forthcoming), which links 6,900 bills, 6,600 laws, and 590,000 transcribed and Google-translated speeches from the European Parliament between 1999 and 2019. First, I estimate the extent to which speeches by the commission emphasize a state of emergency using latent semantic scaling techniques (e.g., Rauh, 2022). As a next step, I analyse whether and under which conditions a perceived crisis threat increases the efficiency of lawmaking (i.e., success and duration), parliamentary unity (i.e., polarization of roll call votes and debates), and bureaucratic discretion (e.g., Franchino et al., 2023; Vannoni et al., 2021). The results will provide important new insights into the crisis modes of governance and how parliamentary emergency politics contributes to more structural changes in governance.","Discipline":"Political Science","keywords":"crises; parliamentary speech; legislative behaviour; semantic scaling","approach":"latent semantic analysis","data":"ParlLawSpeech dataset","issue":"emergency politics in the European Union","geofocus":"Europe","Corresponding Author":"Lukas Hetzer","chair":"Larissa Böckmann","discussant":"Lukas Hetzer & Hauke Licht","time":"Saturday, 15:15-16:45"},{"slot":"Day2_3","session_title":"Politics of Europe Under Scrutiny","session":19,"id":20,"session_meansim":40896,"Title":"Evoking and Contesting Expertise in Parliaments: An AI-supported Analysis of Climate Change Debates in Seven Countries","authors":"Áron Buzogány; Miklós Sebők; Melinda Manczinger","full_text":"Evoking and Contesting Expertise in Parliaments: An AI-supported Analysis of Climate Change Debates in Seven Countries\n\nThe Paris Agreement of the United Nations Framework Convention on Climate Change (UNFCCC) put nation-states front-and-centre in the politics of climate change mitigation. Several governments enshrined the pledges made in Paris into domestic legislation and exposed themselves to more systematic domestic scrutiny through parliaments and courts than ever before (Falkner 2016). The proliferation of climate change legislation and climate litigation in recent years suggests that legislatures and courts have taken to their new role, and climate policy is becoming a key concern for parliaments. More and more parliaments seek advice on climate policy from outside traditional political and expert forums and have strengthened their reach on channels of external and in-house climate expertise that are independent of government influence (Averchenkova et al. 2021). Set before this background, the paper brings together three fields of research related to climate change which are rarely interlinked: legislative studies, the study of climate policy and quantitative text analysis (Sebők et al. 2023). We examine seven European country cases of the ParlLawSpeech dataset to 1, identify debates on climate policy and 2, to explore how expertise is evoked and contested in these debates. We do this by using AI-assigned policy topic codes related to climate policy and deep learning-based large language models to tease out the sentiments associated with references to expertise. We identify temporal trends and differentiate between different party families regarding frequency, argumentation and reliance on external expertise. The paper contributes to the evolving interdisciplinary agenda analyzing the politics of climate change.","Discipline":"computational social science; environmental policy; political science","keywords":"climate change; parliamentary debates; large language models","approach":"text analysis","data":"ParlLawSpeech dataset","issue":"expertise in climate change debates","geofocus":"seven European countries","Corresponding Author":"Melinda Manczinger","chair":"Larissa Böckmann","discussant":"Lukas Hetzer & Hauke Licht","time":"Saturday, 15:15-16:45"},{"slot":"Day2_3","session_title":"Politics of Europe Under Scrutiny","session":19,"id":153,"session_meansim":40896,"Title":"Explaining Varieties of Illiberalism within Far-Right Discourse in Europe","authors":"Larissa Böckmann","full_text":"Explaining Varieties of Illiberalism within Far-Right Discourse in Europe\n\nWhat factors drive parties to embrace illiberal ideology? While an extensive literature deals with the challenges that both liberalism and democracy are facing across the globe, particularly from parties on the far-right and radicalized conservative actors, limited attention has been paid to the factors that explain the adoption of illiberal ideology within the party families and the potential heterogeneity that might exist in this regard. \n\nTo address this issue, this article analyzes the discourse of far-right parties in the European Parliament, building on a comprehensive dataset comprising of all speeches given between 1999 and 2019. In a first step, a dictionary-based approach is used to discern degrees of illiberalism within that discourse. Subsequently, the resulting scores are subjected to regression analysis, considering diverse explanatory factors that are theoretically identified to influence a party’s inclination towards illiberalism, such as regional legacies, individual party traits or contagion effects within European parliamentary groups or party families. Consequently, this article not only contributes to the understanding of a growing ideational challenge to the liberal consensus, but also systematically explores heterogeneity within far-right discourse, aiming to enhance our comprehension of the underlying dynamics.","Discipline":"Political Science","keywords":"Liberalism; Populism; European Parliament","approach":"dictionary-based approach","data":"speeches in the European Parliament","issue":"illiberalism within far-right discourse","geofocus":"Europe","Corresponding Author":"Larissa Böckmann","chair":"Larissa Böckmann","discussant":"Lukas Hetzer & Hauke Licht","time":"Saturday, 15:15-16:45"},{"slot":"Day2_3","session_title":"Politics of Europe Under Scrutiny","session":19,"id":100,"session_meansim":40896,"Title":"Ill-Informed or Up-To-Date? How National Parliamentary Discourse Affects Public Opinion on the European Union","authors":"Mariana Carmo Duarte; Rebecca Kittel","full_text":"Ill-Informed or Up-To-Date? How National Parliamentary Discourse Affects Public Opinion on the European Union\n\nThe European Union (EU) is nowadays a hot issue in national politics. As a result of years of intense crises, such as the Eurocrisis, the refugee crisis or, more recently, the war in Ukraine, the EU and the process of European decision-making have become objects of contestation in national parliaments. Existing studies have unveiled that mainstream political parties adopt pro-EU views, whereas extremist political parties defend anti-EU stances. How national parliamentary discourse on the EU affects public opinion, however, remains unknown. Often, individuals have very little knowledge about the EU. Evidence demonstrates that EU politics are perceived as more complex and technical than national politics. Parliaments, the biggest arenas for deliberation and communication, can contribute to the dissemination of information and arguments that foster individuals to formulate their political preferences. Thus, the national parliamentary discourse can, arguably, influence public opinion on the EU. We hypothesise that when radical parties talk significantly more and in a negative tone about the EU, public opinion towards the EU becomes more negative. On the other hand, we assume that mainstream positive discourse on the EU has no relevant effect on public opinion of the EU. By looking at parliamentary speech data and individual-level data from 11 EU countries between 1990 and 2022, we analyse how public opinion on the EU is shaped by the national parliamentary discourse. Detecting EU-related issues in parliamentary debates through topic models, we analyse the sentiment applied by parties when they talk about the EU.","Discipline":"Political Science","keywords":"European Uniion; Public Opinion; Radical Parties; Parliamentary Discourse; Text-as-Data","approach":"topical analysis","data":"national parliamentary debates","issue":"public opinion on the European Union","geofocus":"11 EU countries","Corresponding Author":"Rebecca Kittel","chair":"Larissa Böckmann","discussant":"Lukas Hetzer & Hauke Licht","time":"Saturday, 15:15-16:45"},{"slot":"Day2_3","session_title":"Politics of Europe Under Scrutiny","session":19,"id":143,"session_meansim":40896,"Title":"Strategic Tuning for Topics: Enhancing BERTopic Precision","authors":"Olga Litvyak; Jessica Voigt Quintino Pereira; Thomas Lampoltshammer","full_text":"Strategic Tuning for Topics: Enhancing BERTopic Precision\n\nBERTopic is a topic modelling technique that employs Transformers and c-TF-IDF to discover topics within a text, gaining popularity for its superior performance over other methods. Its modular structure enables precise customization through a set of parameters of its dependencies (e.g., UMAP and HDBScan). While it is known that individual parameter tuning impacts generic data, there are no guidelines on achieving the optimal parameter combination to attain the topics with the highest quality. This paper addresses this gap by proposing a parameter tuning technique for BERTopic. The guidelines include a combination of descriptive and quantitative analyses of different parameter combinations for four parameters (umap::n_neighbors, umap::min_dist, hdbscan::min_cluster_size, and hdbscan::min_samples). The evaluation criteria encompass calculations of topic similarity and coherence, accompanied by a qualitative analysis of the resulting topics that considers the broader context. We argue that such a step-by-step approach is applicable to various datasets. In this paper, we evaluate this technique using a dataset of current policy documents related to the timber industry in Germany, Austria, and the European Union. To evaluate our approach, we conducted a comparative analysis between the results obtained using the proposed parameter tuning technique and those obtained using default BERTopic parameters. Our findings indicate that the suggested parameter tuning technique significantly improves the quality of the BERTopic models.","Discipline":"Political science; Computational social science","keywords":"Text analysis; Topic modelling; BERT","approach":"parameter tuning","data":"text data","issue":"enhancing topic precision in BERTopic","geofocus":"Germany, Austria, and the European Union","Corresponding Author":"Olga Litvyak","chair":"Larissa Böckmann","discussant":"Lukas Hetzer & Hauke Licht","time":"Saturday, 15:15-16:45"},{"slot":"Day2_4","session_title":"Innovation Drivers Panel","session":9,"id":91,"session_meansim":4413,"Title":"\"Algorithms in the newsroom\" again: Automating news quality evaluation","authors":"Jun Luo","full_text":"\"Algorithms in the newsroom\" again: Automating news quality evaluation\n\nHigh-quality news is important for democracy. Current evaluation methods rely on manual coding, which can be subjective and labor-intensive given the sheer volume of information people receive today. This study proposes an automated news quality evaluation approach by relying on a series of natural language processing techniques, including dependency parsing and named entity recognition. The assumption is that news quality can be represented by the balance of information sources in a news article. This study tests the applicability of this approach using scientific news, political news, and social media posts.","Discipline":"Communication","keywords":"News quality; Information source; Dependency parsing; Named entity recognition; Manual coding","approach":"natural language processing","data":"news articles","issue":"automating news quality evaluation","geofocus":"scientific news, political news, and social media posts","Corresponding Author":"Jun Luo","chair":"Michal Parizek","discussant":"Jun Luo","time":"Saturday, 17:00-18:30"},{"slot":"Day2_4","session_title":"Innovation Drivers Panel","session":9,"id":118,"session_meansim":4413,"Title":"“Too Much and Always the Same”: Textual Characteristics of News Articles that People Intentionally Avoid","authors":"Dominika Betakova; Hajo Boomgaarden; Sophie Lecheler","full_text":"“Too Much and Always the Same”: Textual Characteristics of News Articles that People Intentionally Avoid\n\nIntentional news avoidance, a deliberate decision to refrain from news consumption, is associated with holding misbeliefs and lower political knowledge. This behavior also involves avoiding specific news contents or topics labeled as selective news avoidance, while reasons for such behaviors include perceived news negativity, overload, or repetitiveness. These reasons fall under content-level factors, suggesting that news content characteristics influence news avoidance and its occurrence can partially be explained by looking at the content of news coverage. Thefore, this study explores the nature of intentionally avoided news content guided by a cross-sectional survey of a quota-based sample of Austrian citizens (n = 473) who indicated their news consumption along with news topics they intentionally avoided and why. Preliminary findings identify COVID-19, European integration, corruption, economic policy and migration as the most avoided news topics. In the second step, the study analyzes Austrian news articles from eight mayor news outlets (n = 109.548) during the survey’s period. It inspects differences in articles’ textual properties, negativity, usage of alarm words and language intensifiers, complexity and salience via dictionary methods, sentiment analysis and methods measuring syntactic and semantic complexity. The aim is to build an analysis pipeline integrating news avoidance content indicators and considers their individual and interactive presence in the news. Upon completion, the study will enhance the understanding of selective news avoidance as a reaction to news content, contributing to the solutions-oriented discourse surrounding news avoidance. In addition, validated dictionaries in German language will be published on the OSF platform.","Discipline":"Political Communication; Journalism Studies","keywords":"news avoidance; news negativity; political communication; automated text analysis; dictionary methods","approach":"textual analysis","data":"news articles","issue":"intentional news avoidance","geofocus":"Austria","Corresponding Author":"Dominika Betakova","chair":"Michal Parizek","discussant":"Jun Luo","time":"Saturday, 17:00-18:30"},{"slot":"Day2_4","session_title":"Innovation Drivers Panel","session":9,"id":49,"session_meansim":4413,"Title":"Identification of innovation drivers based on technology-related news articles","authors":"Albina Latifi; David Lenz; Peter Winker","full_text":"Identification of innovation drivers based on technology-related news articles\n\nInnovations contribute to economic growth. Hence, knowledge\nabout drivers of innovation activities is a necessary input for eco-\nnomic policy making when it comes to implement targeted support\nmeasures. We focus on firms as potential drivers of innovation and\nuse a novel data-driven approach to identify them. The approach is\nbased on news articles from a technology-related newspaper for the\nperiod 1996–2021. In a first step, natural language processing (NLP)\ntools are used to identify latent topics in the text corpus. Expert\nknowledge is used to tag innovation-related topics. In a second step, a\nnamed entity recognition (NER) method is used to detect firm names\nin the news articles. Combining the information about innovation-\nrelated topics and firms mentioned in news articles linked to these\ntopics provides a set of firms linked to each innovation-related topic.\nThe results suggest that the approach helps identifying drivers of in-\nnovation activities going beyond the usual suspects. However, given\nthat the rate of false alarms is not negligible, at the end also human\njudgement is needed when using this approach.","keywords":"innovation drivers; topic modeling; entity recognition","approach":"NLP and NER","data":"technology-related news articles","issue":"identification of innovation drivers","geofocus":"global","Corresponding Author":"Albina Latifi","chair":"Michal Parizek","discussant":"Jun Luo","time":"Saturday, 17:00-18:30"},{"slot":"Day2_4","session_title":"Innovation Drivers Panel","session":9,"id":99,"session_meansim":4413,"Title":"Semantic Scores: Using BERT-embeddings for multidimensional scoring of economic and financial texts","authors":"Matthias Reccius","full_text":"Semantic Scores: Using BERT-embeddings for multidimensional scoring of economic and financial texts\n\nIn economics and finance, the tonal polarity of texts is often quantified through binary sentiment classification, which typically involves fine-tuning a pre-trained transformer language model. Since it requires a labeled set of domain- and task-specific training data, fine-tuning creates considerable costs while typically creating one-trick-pony models that can accomplish one task but nothing else. Additionally, news item may disclose information in dimensions beyond sentiment that can be relevant to a particular economic outcome. To eliminate the need to fine-tune a specialized model for every textual dimension of interest, I propose the semantic scoring method. Without further model training, semantic scoring uses the context-dependent word embeddings that encode language understanding in pre-trained models directly. In a transfer-learning approach, those embeddings are transformed to an interpretable, economically relevant feature space. Leveraging the psychometric concept of semantic differentials, semantic scoring allows a text to be scored on a real-valued scale between -1 and 1 for any dimension that can be conceptualized as being spanned by two opposites such as profit – loss or expect – know. I apply the method to company news articles by computing scores in three dimensions: latent profit expectations, the degree of forward-lookingness of a news item and cues for the news having already been priced in. I then quantify the utility of the scores for stock price prediction. By comparing BERT base to FinBERT and FinBERT Tone, I also assess the degree to which domain-specific training enhances a model’s understanding of financial and economic texts.","Discipline":"economics","keywords":"transformer models, sentiment analysis, transfer learning, asset pricing","approach":"bert-embeddings","data":"economic and financial texts","issue":"multidimensional scoring of economic and financial texts","geofocus":"company news articles","Corresponding Author":"Matthias Reccius","chair":"Michal Parizek","discussant":"Jun Luo","time":"Saturday, 17:00-18:30"},{"slot":"Day2_4","session_title":"Innovation Drivers Panel","session":9,"id":64,"session_meansim":4413,"Title":"The Narratives of the War in Ukraine in News Media Worldwide","authors":"Michal Parizek; Jakub Stauber","full_text":"The Narratives of the War in Ukraine in News Media Worldwide\n\nTwo main competing narratives of the War in Ukraine can be discerned among major powers and globally. The narrative promulgated by Western powers, supportive of the Ukrainian cause, sees the war as an unprovoked, illegal aggression towards a sovereign state. Russia presents a competing narrative in which the war is a defensive response to NATO’s Eastward expansion and a part of the global re-ordering. The narratives resonate, to varying degrees, in different parts of the World, and which of the two prevails will have important implications for the war and post-war Ukraine itself, for the CEE region and the EU at large, but also for the broader dynamics of the international order. News media is the essential vehicle that carries the competing narratives of the war. In this text, we estimate the diffusion of the narratives in news media over time and across states. We do so by deploying NLP tools to analyze over 5 million news articles from 136 states and around 1,900 media outlets between January 2022 and December 2023. We first perform dictionary analysis to map the prominence of the war in news media worldwide to show variation in its coverage over time and across regions. Next, we detect the prominence of the Russian narrative using a supervised ML model (deBERTa-v3). Finally, we demonstrate the possibility of using open-source (Llama-2) and proprietary (GPT-4) generative AI tools to detect the narratives and compare the performance of LLMs in replicating human identification of the narratives in textual data.","Discipline":"International Relations; Comparative Politics","keywords":"news; machine learning; LLM; generative AI; war; Ukraine","approach":"narrative analysis","data":"news articles from 136 states and around 1","issue":"competing narratives of the War in Ukraine","geofocus":"worldwide","Corresponding Author":"Michal Parizek","chair":"Michal Parizek","discussant":"Jun Luo","time":"Saturday, 17:00-18:30"},{"slot":"Day2_4","session_title":"Media and Politics Panel","session":31,"id":60,"session_meansim":28721,"Title":"Apathy’s a tragedy and boredom is a crime? Consequences of how media talks about politicians for voters’ behavior","authors":"Tatiana Lupacheva","full_text":"Apathy’s a tragedy and boredom is a crime? Consequences of how media talks about politicians for voters’ behavior\n\nMedia is the key source of political information for voters. The paper examines how the content of media coverage of MP affects the behavior of voters based on Estonian data. In the Estonian parliamentary electoral system, the personal image of candidates is essential for election. I apply text-as-data techniques to all online content from four major newspapers across two parliamentary terms (2015-2023) to classify the tone (positive or negative) and focus (private or political) of articles mentioning MPs. I rely on Wikipedia traffic data as an indicator of information search about MPs. What kind of media coverage prompts voters to search for more information about legislators? Does the media-prompted public attention affect MPs’ chances of re-election? The results have implications for understanding the consequences of political communication and democratic representation in the digital age.","Discipline":"Political communication; political behavior","keywords":"Media visibility; political information-seeking; members of parliament","approach":"text-as-data","data":"online content from four major newspapers","issue":"voter behavior based on media coverage of politicians","geofocus":"Estonia","Corresponding Author":"Tatiana Lupacheva","chair":"Brian Boyle","discussant":"Lukas Birkenmaier","time":"Saturday, 17:00-18:30"},{"slot":"Day2_4","session_title":"Media and Politics Panel","session":31,"id":63,"session_meansim":28721,"Title":"Catalysts for Change? Mapping Policy Recommendations in Academic Publications on Climate Change and Net Zero Energy Systems","authors":"Brian Boyle; Yen-Chieh Liao; Stefan Müller","full_text":"Catalysts for Change? Mapping Policy Recommendations in Academic Publications on Climate Change and Net Zero Energy Systems\n\nThe growing focus on climate change and net zero energy research underscores the importance of effective policy communication to foster societal engagement and encourage policy adoption. In this study, we map the prevalence and types of policy recommendations in academic climate science research and explore how researchers communicate their findings to policymakers. More specifically, we examine: How prevalent are policy recommendations in academic journal articles? To what extent do these patterns vary over time and by academic field? What are the implications for the role of scientific research in the policymaking process? After assembling a text corpus of abstracts from over 255,000 publications on climate change, net zero, and carbon neutrality, we use transformer based text classification (fine-tuned DistilBERT) alongside natural language processing techniques to identify policy mentions and recommendations. Through regression analysis, we contrast policy communication preferences across disciplines, geographical regions, publication outlets, and over time. Our dataset provides valuable insights into how climate science research engages with policymakers, while the next steps of our project involve: summarising the substantive content of these policy recommendations; exploring the extent to which policy reports cite scientific sources; and the congruence between policy recommendations and policy outputs.","Discipline":"Political science","keywords":"Environmental politics; policy recommendations; text classification","approach":"transformer-based text classification","data":"academic journal articles","issue":"policy recommendations on climate change and net zero energy systems","geofocus":"Global","Corresponding Author":"Brian Boyle","chair":"Brian Boyle","discussant":"Lukas Birkenmaier","time":"Saturday, 17:00-18:30"},{"slot":"Day2_4","session_title":"Media and Politics Panel","session":31,"id":119,"session_meansim":28721,"Title":"Resource-Efficient Text Classification Using Pretrained Language Models and Parameter-Efficient Fine-Tuning","authors":"Christopher Klamm; Sascha Meyer, Moritz Osnabrügge, Simone Ponzetto","full_text":"Resource-Efficient Text Classification Using Pretrained Language Models and Parameter-Efficient Fine-Tuning\n\nPolitical scientists usually fine-tune all parameters of pretrained language models on a specific task before using the models for text classification. This process requires significant computing resources, posing monetary and environmental challenges. To reduce the costs of fine-tuning pretrained language models, we propose using a parameter-efficient fine-tuning strategy. Our focus lies on adapters, which are small layers added between layers of a pretrained model. Adapter-based fine-tuning involves fine-tuning only the adapter parameters while freezing all other parameters of the pretrained model. In our application, we focus on topic classification of political text and compare the performance and efficiency of a fully fine-tuned and an adapter-based fine-tuned model. While both approaches achieve similar classification performance, the adapter-based fine-tuning strategy requires significantly fewer resources. We find that adapters reduce on average the training time by 28%, the disk storage for saving the model by 99%, the electricity consumption and the CO2 emissions by 34%. These results demonstrate that parameter-efficient fine-tuning can increase the resource efficiency of text classification in political science. We provide code for implementing the parameter-efficient fine-tuning strategy.","Discipline":"computational methods; NLP; ML","keywords":"text classification, language models, resource efficiency, adapters","approach":"parameter-efficient fine-tuning","data":"political texts","issue":"resource efficiency of text classification","geofocus":"computing resources","Corresponding Author":"Christopher Klamm","chair":"Brian Boyle","discussant":"Lukas Birkenmaier","time":"Saturday, 17:00-18:30"},{"slot":"Day2_4","session_title":"Media and Politics Panel","session":31,"id":113,"session_meansim":28721,"Title":"The Art of Political Persona: Examining the Role of Personality Traits in Politicians' Self-Presentation","authors":"Lukas Birkenmaier, Clemens Lechner","full_text":"The Art of Political Persona: Examining the Role of Personality Traits in Politicians' Self-Presentation\n\nThe opinions that citizens form about politicians are shaped by their impressions of these politicians. More specifically, the way candidates are perceived often depends on the assessment of their personality, character, and traits. While extensive research has explored what personality traits citizens favor in politicians, less attention has been given to how politicians strategically present specific personality traits. To bridge this research gap, we intend to employ computational text analysis to systematically investigate how politicians project their personality traits across various communication platforms. This study is based on the premise that politicians selectively highlight particular personality traits to connect with their target audience, adapting to different communication mediums. Our primary objectives are twofold: first, to identify the primary communication channels politicians use for strategically conveying their personality traits, and second, to develop computational methods for quantifying these traits. To address these research questions, we will build upon a recently developed survey instrument that encompasses 15 personality facets relevant to the perception of political figures (e.g., Truthfulness, Will to Power, Communicative Energy, Cautious Judgment). For each of these personality facets outlined in the survey, we will employ computational text analysis methods to categorize politicians' personality traits. The outcomes of our study will shed light on 1) whether fine-grained personality traits can be effectively measured using computational methods and, if so, 2) how politicians strategically emphasize these character traits in diverse situations.","Discipline":"political science; psychology","keywords":"political personality; political communication; framing","approach":"computational text analysis","data":"communication platforms","issue":"politicians","geofocus":"various communication mediums","Corresponding Author":"Lukas Birkenmaier","chair":"Brian Boyle","discussant":"Lukas Birkenmaier","time":"Saturday, 17:00-18:30"},{"slot":"Day2_4","session_title":"Media and Politics Panel","session":31,"id":74,"session_meansim":28721,"Title":"Using semantic similarity to measure the echo of strategic communications","authors":"Tristan J.B. Cann, Ben Dennes, Travis Coan, Saffron O'Neill, Hywel T.P Williams","full_text":"Using semantic similarity to measure the echo of strategic communications\n\nMedia debates and online discussions are important targets for strategic communications intended to shape attitudes and habits. Climate change in particular sees competing actors promoting agendas for and against action to mitigate climate impacts. \n\nUnderstanding the success of these communications is challenging. Relationships between advocacy groups and media platforms are rarely disclosed and standards for source acknowledgement vary between platforms. Therefore, attempts to evaluate the impact of communication campaigns rely on proxies (e.g. keyword usage). \n\nWe developed a new method using semantic similarity to quantify a message’s ‘echo’ across a reference corpus without targeting keywords. We use cosine similarity of text embeddings from the all-MiniLM-L6-v2 sentence transformer alongside a predetermined threshold to identify pairs of texts sharing the same message. The echo metric uses the number of similar reference texts on each day to calculate the change in response between the average over several days after publication and a baseline average over the days before publication. Positive (negative) echoes indicate more (less) discussion on the relevant topic, whereas zero indicates no change. \n\nWe calculated the echo of 4,334 press releases from environmentally active organisations between November 2019 and October 2021 over the Twitter and news coverage of climate change. Here we found that the typical response to a message is small, but the most successful pieces saw an average increase in coverage of more than 1,000 news articles or 20,000 tweets. Our dataset suggests that echoes greater than one percent of average activity rates are exceptionally successful.","Discipline":"Computer Science; Geography; Political communication","keywords":"impact analysis; sentence embeddings; agenda setting","approach":"semantic similarity","data":"press releases and Twitter coverage","issue":"strategic communications on climate change","geofocus":"November 2019 to October 2021","Corresponding Author":"Tristan J.B. Cann","chair":"Brian Boyle","discussant":"Lukas Birkenmaier","time":"Saturday, 17:00-18:30"},{"slot":"Day2_4","session_title":"Navigating Information Landscapes","session":33,"id":133,"session_meansim":27339,"Title":"Does Access Mean Success? Connection to Policy-Makers and Lobbying Success of Political Actors","authors":"Rosanne Logeart","full_text":"Does Access Mean Success? Connection to Policy-Makers and Lobbying Success of Political Actors\n\nThis article aims at understanding the policy-making process. It analyzes the relationship between access to policy-makers and lobbying success. I collect unique data on the textual content of lobbying activities, as well as subsequent policy changes. It enables me to identify instances of lobbying success. Policy changes are measured for 482 regulations, and success is assessed for 129,153 lobbying comments. I match this novel data with meetings held between policy-makers and lobbyists to measure access of lobbyists to policy-makers. It shows that the business sector has more access to policy-makers than the civil society has. I find that having access to policy-makers is associated with higher likelihoods of success in lobbying. Distinguishing past access and contemporaneous access to policy-makers, past access to policy-makers seems to be driving this result. It suggests that reputation and connection building play a critical role. Interacting access and lobbyist type, I find that the business sector benefits more from access through higher likelihood of lobbying success, in addition to having more access. Surprisingly, NGOs display opposite patterns. NGOs benefit from access contemporaneous to their lobbying activities while they are relatively worse off when having past access. They do not seem to build reputation and/or connection through this past access.","Discipline":"Economics","keywords":"Political economy, Lobbying, Advocacy, Interest groups, European Union","approach":"content analysis","data":"lobbying comments and policy changes","issue":"access to policy-makers and lobbying success","geofocus":"policy-making process","Corresponding Author":"Rosanne Logeart","chair":"Gerda Viira","discussant":"Rosanne Logeart","time":"Saturday, 17:00-18:30"},{"slot":"Day2_4","session_title":"Navigating Information Landscapes","session":33,"id":150,"session_meansim":27339,"Title":"DOPEH – Dynamics of online political elite hostility: The audio-visual packaging of negative and uncivil campaign ads on meta.","authors":"Philipp Mendoza; Alessandro Nai; Linda Bos","full_text":"DOPEH – Dynamics of online political elite hostility: The audio-visual packaging of negative and uncivil campaign ads on meta.\n\nThe increasing recognition of non-textual cues in emphasizing, extending, and elaborating political campaign messages is evident among campaigners and academics. Political commercials represent a deliberate mix of textual, acoustic, and visual communication. Despite the notable impact of visual and acoustic elements in online political campaign packaging, most observational and experimental studies have primarily centered on textual content. Our approach separates campaign messages into their content and packaging, investigating how text, acoustic, and visual features vary based on the message's tone, civility, and focus. This study is grounded in an analysis of all meta-ads posted by political entities surrounding Australia's 2022 general elections.\nWhile much of our research is exploratory in nature, we've developed expectations regarding various acoustic and visual characteristics. For instance, we anticipate that visual cues in positive and civil ads will likely be warmer, more saturated, and brighter compared to those in negative and uncivil ads. Conversely, we expect negative and uncivil ads to exhibit a faster tempo in music and speech, alongside more somber acoustic cues, including lower voice pitches and the use of more minor musical chords.\nTo comprehensively study variations in different ad types, we begin by classifying ads in terms of civility, tonality, and focus, utilizing a large language model for this purpose. These classifications are further validated through manual annotations. Following this, we delve into a systematic exploration of how these ad types differ across acoustic and visual communication modes, offering a nuanced understanding of the interplay between content and packaging in political campaign messaging.","Discipline":"Political Communication","keywords":"political advertising; negative campaigning; incivility; political parties;","approach":"textual","data":"meta-ads posted by political entities in Australia","issue":"negative and uncivil campaign ads","geofocus":"Australia","Corresponding Author":"Philipp Mendoza","chair":"Gerda Viira","discussant":"Rosanne Logeart","time":"Saturday, 17:00-18:30"},{"slot":"Day2_4","session_title":"Navigating Information Landscapes","session":33,"id":44,"session_meansim":27339,"Title":"Enhancing access to public information across Europe: Applying Woogle design and technique to documents published according to the Public Information Act in Estonia","authors":"Gerda Viira; Maarten Marx","full_text":"Enhancing access to public information across Europe: Applying Woogle design and technique to documents published according to the Public Information Act in Estonia\n\nFreedom of Information (FOI) is a fundamental part of democracy, facilitating the public's access to information generated by the government and public institutions when performing official functions. In the Netherlands, since 2022, the Open Government Act, known as Wet openbare overheid or Woo/Wob in Dutch, has been in effect, with the primary objective of ensuring a more transparent government. In line with the legislation, a search engine named Woogle (Woogle, n.d.) has been designed and developed with the aim of centralizing documents published under the Open Government Act. A similar legal framework is in place in Estonia. The Public Information Act requires all public institutions to publish information generated during official duties, fostering transparency and public oversight. Currently, Estonia’s document repositories are decentralized and content search is not supported which hinders people’s ability to efficiently locate information. This research project aims to, firstly, assess public information accessibility in Estonia, and secondly, apply Woogle’s design and techniques to Estonia’s document repositories, assessing its suitability for other European countries. This study seeks to identify best practices, enhance transparency, and lay a foundation for a harmonized approach to freedom of information document accessibility in Europe. We view the addition of Estonia to Woogle as a pilot of a larger project in which we add the FOI documents of all European countries, similar to the ParlaMint project in which the parliamentary proceedings of 32 countries are brought together in a uniform format (Erjavec et al., 2023).\n\nReferences\nTomaz Erjavec, Maciej Ogrodniczuk, Petya Osenova, Nikola Ljubesic, Kiril Simov, Andrej Pancur, Michal Rudolf, Maty’as Kopp, Starkaður Barkarson,\nSteinþ’or Steingr’ımsson, Çagri Ç\"oltekin, Jesse de Does, Katrien Depuydt, Tommaso Agnoloni, Giulia Venturi, Mar’ıa Calzada P’erez, Luciana D. de\nMacedo, Costanza Navarretta, Giancarlo Luxardo, Matthew Coole, Paul Rayson, Vaidas Morkevicius, Tomas Krilavicius, Roberts Dargis, Orsolya\nRing, Ruben van Heusden, Maarten Marx, and Darja Fiser. 2023. The ParlaMint corpora of parliamentary proceedings. Lang. Resour. Evaluation 57, 1\n(2023), 415–448. https://doi.org/10.1007/s10579-021-09574-0\n\nWoogle. [n. d.]. Home. Retrieved December 11, 2023 from https://woogle.wooverheid.nl/","keywords":"Freedom of Information; Information retrieval; Ontologies","approach":"information retrieval","data":"documents published according to the Public Information Act in Estonia","issue":"enhancing access to public information across Europe","geofocus":"Estonia and other European countries","Corresponding Author":"Gerda Viira","chair":"Gerda Viira","discussant":"Rosanne Logeart","time":"Saturday, 17:00-18:30"},{"slot":"Day2_4","session_title":"Navigating Information Landscapes","session":33,"id":67,"session_meansim":27339,"Title":"Language as kaleidoscope: How grammatical differences foreground different information in multilingual text classification","authors":"Avital Zalik; Anna Smoliarova; Guy Shababo; Christian Baden","full_text":"Language as kaleidoscope: How grammatical differences foreground different information in multilingual text classification\n\nTexts consist of words, but require grammar to convey specific meaning. However, if English distinguishes “dog bites man” from “man bites dog” using word order, other languages use stopwords (German: “Den Mann beisst der Hund”), inflections (Polish: “Pies gryzie mężczyznę”) or any combination of these. Moreover, English word order adjoins subject and verb (SVO), which are far apart in Korean (SOV) or in registers using passive voice (e.g., academic Russian). Yet, computational text analysis remains curiously unaware of linguistic differences in the use of grammar. Most strategies discard most grammatical information (BoW, lemmatization, stopword removal), retaining only selected parts (e.g., n-grams record word order). Depending on the language, each strategy removes different parts of grammatical information, presenting systematically different information to the computational analysis.\nTo demonstrate this point, we use parallel three corpora: the Europarl corpus (English-German-French-Spanish-Polish) and two self-created corpora of academic abstracts (Korean-English, Russian-English). As a simple, grammar-sensitive classification task, we determine whether a document foregrounds diagnostic (issue) or therapeutic (solution) framing, manually annotating 1,000 documents in each corpus. Varying both pre-processing (stopword removal, lemmatization, none) and feature construction routines (unigrams, bigrams, BERT-tokens), we compare the performance of different types of classification algorithms (RF, SVM, RNN, mBERT), using 10-fold cross-validation. Results demonstrate that identical modeling choices focus the classification on very different subsets of documents’ grammatical information in each language, resulting in marked performance differences and biases in the classification of documents. We discuss implications for computational text analysis and suggest avenues for equivalently modeling grammatical information.","Discipline":"Communication Science","keywords":"Multilingual Text Analysis; Grammar; Machine Classification; Classification Bias","approach":"text classification","data":"multilingual corpora (Europarl and two self-created abstracts)","issue":"grammatical differences in text classification","geofocus":"English, German, French, Spanish, Polish, Korean, and Russian","Corresponding Author":"Christian Baden","chair":"Gerda Viira","discussant":"Rosanne Logeart","time":"Saturday, 17:00-18:30"},{"slot":"Day2_4","session_title":"Navigating Information Landscapes","session":33,"id":123,"session_meansim":27339,"Title":"Misrepresentation of scientific uncertainty. Automated analysis of (un)certainty in science communication across disciplines and platforms.","authors":"Jana Egelhofer; Petro Tolochko","full_text":"Misrepresentation of scientific uncertainty. Automated analysis of (un)certainty in science communication across disciplines and platforms.\n\nUncertainty is inherent to the self-correcting nature of science, and scientific findings are always limited by scientists’ decisions regarding sampling and statistical analyses. However, the uncertainty of scientific information is often misrepresented in news coverage. While media logic plays a crucial role in this misrepresentation of scientific information, there are also indications that misrepresentation of uncertainty already occurs in scientific articles or related press releases. The failure to effectively communicate uncertainty in science can leave people misinformed, potentially leading them to overestimate the effectiveness of new discoveries or misunderstand the scientific process, which can ultimately diminish public trust in science. Thus far, there is only little empirical evidence on the prevalence of uncertainty in science and science communication. Specifically, there is no systematic analysis of how the communication of scientific (un)certainty differs across a) different scientific disciplines and b) platforms of science communication (i.e., academic studies, press releases, news coverage). \nTo fill this gap, we develop an automated method of measuring the concept of “uncertainty” in texts. Using a context specific text embedding model and a synthetically augmented database of uncertainty categories we operationalise scientific uncertainty based on the average distance of the scientific publication to either of the poles of the training data (high vs. low uncertainty). We will then use this method to analyse the prevalence of (un)certainty in a large sample of interdisciplinary scientific articles (published in Nature journals), their related press releases and news coverage.","Discipline":"Communication Science","keywords":"Science Communication; Sociology of Science; Scientific Uncertainty; Text Embedding","approach":"text embedding model","data":"scientific articles","issue":"misrepresentation of scientific uncertainty","geofocus":"interdisciplinary scientific articles published in Nature journals","Corresponding Author":"Petro Tolochko","chair":"Gerda Viira","discussant":"Rosanne Logeart","time":"Saturday, 17:00-18:30"},{"slot":"Day2_4","session_title":"Politics in the Digital Age","session":34,"session_meansim":0.3619,"Title":"Automatically detecting topics and argument diversity in online social platform comments","authors":"Sjoerd B. Stolwijk","full_text":"Automatically detecting topics and argument diversity in online social platform comments\n\nDeliberative perspectives on democracy require citizens to cooperate with others to solve common issues by sharing insights and having a willingness to learn from others. To evaluate whether public debate fulfills such ideals scholars have long struggled to come up with valid measurement tools (Bächtiger & Parkinson, 2019). Most work limits itself to manual coding transcripts of citizen initiatives or assemblies (Goddard & Gillespie, 2023),while the new summative approach to deliberation also emphasizes the importance of other much larger scale democratic institutions, like social media platforms. To analyze such vast amounts of data computational methods are useful, but so far only few have been proposed. This paper explores the ability of GPT4 compared to a crowd coded sample (cf. Van Atteveldt et al., 2021) to classify comments for two central concepts proposed by Stolwijk et al. (2023) to measure summative deliberation in online social comments: exposure to a specific topic of common concern (here covid) and diversity of arguments. Argument diversity will be operationalized similar to the new method proposed by Youk et al. (2023). We will collect arguments related to covid from Kialo.com, which is a public debate platform. The number of different arguments present per thread within a corpus of various threads of German X comments related to covid will be used to measure their argument diversity. By comparing the results for a more established task like topic classification to this new task of argument diversity, the generalizability of GPT4 to more complex concepts is evaluated.\n\nReferences:\n\nBächtiger, A., & Parkinson, J. (2019). Mapping and Measuring Deliberation: Towards a New Deliberative Quality (1st ed.). Oxford University Press. https://doi.org/10.1093/oso/9780199672196.001.0001\n\nGoddard, A., & Gillespie, A. (2023). Textual Indicators of Deliberative Dialogue: A Systematic Review of Methods for Studying the Quality of Online Dialogues. Social Science Computer Review, 089443932311566. https://doi.org/10.1177/08944393231156629\n\nStolwijk, S. B., Oschatz, C., Heseltine, M., & Trilling, D. (2023). Refining deliberative standards for online political communication: Introducing a summative approach to designing deliberative recommender systems. NORMalize 2023: The First Workshop on the Normative Design and Evaluation of Recommender Systems, September 19, 2023, Co-Located with the ACM Conference on Recommender Systems 2023 (RecSys 2023), Singapore.\n\nVan Atteveldt, W., Van Der Velden, M. A. C. G., & Boukes, M. (2021). The Validity of Sentiment Analysis: Comparing Manual Annotation, Crowd-Coding, Dictionary Approaches, and Machine Learning Algorithms. Communication Methods and Measures, 15(2), 121–140. https://doi.org/10.1080/19312458.2020.1869198\n\nYouk, S., Malik, M., Chen, Y., Hopp, F. R., & Weber, R. (2023). Measures of Argument Strength: A Computational, Large-Scale Analysis of Effective Persuasion in Real-World Debates. Communication Methods and Measures, 1–23. https://doi.org/10.1080/19312458.2023.2230866","Discipline":"Political Communication; computational social science","keywords":"deliberation; social media; GPT4","approach":"topic classification and argument diversity analysis","data":"online social platform comments","issue":"deliberation and democracy","geofocus":"Germany","Corresponding Author":"Sjoerd B. Stolwijk","chair":"Felix Schmidt","discussant":"Dominic Nyhuis","time":"Saturday, 17:00-18:30"},{"slot":"Day2_4","session_title":"Politics in the Digital Age","session":34,"session_meansim":0.3182,"Title":"Courts Under Pressure: How Social Media Change Political Discourse About the Rule of Law in Modern Democracies","authors":"Tilko Swalve; Merle Huber; Dominic Nyhuis; Philipp Köker; Christoph Hönnige","full_text":"Courts Under Pressure: How Social Media Change Political Discourse About the Rule of Law in Modern Democracies\n\nWith the surge of populism worldwide, many observers have become increasingly concerned about the erosion of the rule of law. While scholars have primarily focused on democratic backsliding in salient cases like Hungary or Poland, where populist parties formed a government, we know much less about the strategies of populist parties in opposition. We argue that populist politicians use social media to systematically de-legitimize the judiciary. Parallel to the rise of populism, the increasing popularity of social media as a political communication tool has enabled politicians to circumvent traditional media. The disruption of the media landscape disproportionately benefits populists who were previously most constrained by media gatekeepers. To empirically test our argument, we scrutinize the elite discourse concerning the rule of law in Poland, Germany, The Netherlands, and the United Kingdom. We collected data on 166,140 Twitter posts concerning the judicial system by MPs in the four countries between 2013 and 2022. To categorize social media posts, we train and validate BERT-based models on manually coded textual data. Afterward, we examine how MP's social media communication varies across political parties with respect to tone (neutral, positive, negative) and target (judicial system, constitution, court, judge, decision).","Discipline":"Political Science","keywords":"social media, BERT, populism, democratic backsliding, courts","approach":"BERT-based model","data":"Twitter posts by MPs","issue":"delegitimization of the judiciary through social media","geofocus":"Poland, Germany, The Netherlands, and the United Kingdom","Corresponding Author":"Dominic Nyhuis","chair":"Felix Schmidt","discussant":"Dominic Nyhuis","time":"Saturday, 17:00-18:30"},{"slot":"Day2_4","session_title":"Politics in the Digital Age","session":34,"session_meansim":0.3619,"Title":"Emotions and Politics: Mapping Emotional Dynamics and News Trustworthiness on Social Media","authors":"Jula Luehring; Jana Lasser; Apeksha Shetty; David Garcia; Annie Waldherr; Hannah Metzler","full_text":"Emotions and Politics: Mapping Emotional Dynamics and News Trustworthiness on Social Media\n\nAlthough sentiment studies of misinformation on social media exist, they often suffer from methodological shortcomings. Many classify between positive and negative sentiment only, overlooking the different effects of distinct emotions on engagement with information on social media. Importantly, existing studies frequently fail to distinguish emotions within news from reactions to it, a crucial distinction for understanding their role in engagement. Moreover, data collection methods often sample subsets of news, such as fact-checked stories, thereby misrepresenting the broader spectrum of news shared on social platforms. We present a systematic, large-scale, and long-term study conducted within the German-speaking Twittersphere from October 2020 to March 2022. We collected 11.6M random conversations (46M tweets) discussing tweets linking to one of 324 German-speaking news domains, covering the full spectrum of news trustworthiness and political orientation. Preliminary analyses show that the trustworthiness of all shared news is, on average, high, but drops by 67% for domains with far-right orientation. Trustworthy domains receive more likes, replies, and quotes, but untrustworthy domains are retweeted more frequently. Overall, we observe higher emotions, primarily anger, in reply to news, especially so in response to right-wing news. Emotions affect engagement differently; however, political orientation, interacting with anger, seems to drive engagement with untrustworthy news. Currently, we are classifying tweets based on in-group or out-group mentions, allowing us to explore how emotions evolve within and across Twitter threads amidst inter-group conflicts. Spanning an extensive timeframe, we provide comprehensive insights into the nuanced effects of emotions within a complex information ecosystem.","Discipline":"computational communication science; computational social science","keywords":"news trustworthiness; emotion analysis; social media; Germany; misinformation","approach":"emotion analysis","data":"social media conversations","issue":"emotional dynamics and news trustworthiness","geofocus":"German-speaking Twittersphere","Corresponding Author":"Luehring, Jula","chair":"Felix Schmidt","discussant":"Dominic Nyhuis","time":"Saturday, 17:00-18:30"},{"slot":"Day2_4","session_title":"Politics in the Digital Age","session":34,"session_meansim":0.3619,"Title":"Uncovering Political Bias in Emotion Inference Models: Implications for sentiment analysis in political research","authors":"Hubert Plisiecki; P. Koc; M. Flakus; A. Pokropek","full_text":"Sentiment and emotion classifiers are often used to study political phenomena, and their popularity is constantly increasing, mirrored by the developments in the accuracy of the models themselves. However, high metrics of accuracy alone do not guarantee unbiased results. The bias inherent to the annotations themselves deserves more research attention. This is especially true in the realm of political research where finding completely neutral annotators borders on impossible. Bias like this is even more evident in emotional annotation tasks, due to the partially unconscious nature of the emotional phenomena. To address this problem, we have collected and annotated 10 000 text snippets from various Polish political social media profiles with regards to the intensity of 5 basic emotions (Happiness, Sadness, Disgust, Fear, Anger) as well as Valence and Arousal, using a Likert Scale. Each text was annotated by at least 5 expert judges. After an in-depth parameter search, we have trained a transformer model to predict the annotated indices. The model achieved an average correlation on the test set of 0.75 across all affective metrics. We will create a list of emotionally neutral keywords associated with different sides of the political spectrum and inspect the emotional bias of the model. In principle a small level of bias does not disqualify the model from being used in research, but its level should be considered during results interpretation. We advise political scientists trying to use different emotion classification models in their research to conduct similar bias inspections prior to result interpretation.","Discipline":"political research; psychology; machine learning","geofocus":{},"Corresponding Author":"Hubert Plisiecki","chair":"Felix Schmidt","discussant":"Dominic Nyhuis","time":"Saturday, 17:00-18:30"},{"slot":"Day2_4","session_title":"Politics in the Digital Age","session":34,"session_meansim":0.3619,"Title":"Facing the Voters - Individual and Institutional Determinants of Personalization in Social Media Images","authors":"Felix Schmidt; Lena Masch; Dylan Paltra; Marius Sältzer","full_text":"Facing the Voters - Individual and Institutional Determinants of Personalization in Social Media Images\n\nThe political landscapes of many Western democracies, their election campaigns, in particular, have experienced a notable shift towards greater personalization and visualization. Social media and media fragmentation have magnified this trend, providing politicians with the means to directly engage with voters and cultivate their public image independently of party affiliations and policies. To address how institutional and personal factors motivate politicians to self-promote, we focus our investigation on their social media endeavors, particularly the images they share. We argue that the level of self-promotion in election campaigns constitutes a strategic choice influenced by institutional incentives and the candidates' personality traits. To test our hypotheses, we employ a novel dataset integrating candidate surveys conducted across nine German state elections in 2021 and 2022 with social media data. Utilizing state-of-the-art face recognition software and referencing images for over 1,110 individual candidates and 33,143 images posted on Twitter, we identify how often political candidates share images featuring their faces during campaign periods based on their personal characteristics. Our findings reveal a nuanced picture: First, we demonstrate that the use of one's own image is shaped by a combination of institutional incentives and personality traits, particularly narcissism. Second, our results highlight that nominated candidates with a high narcissism-trait score are likelier to share images featuring their faces. Interestingly, the certainty of election outcomes influences the likelihood of sharing such images. For candidates with a high certainty to win or lose, narcissism traits play a more pronounced role compared to those uncertain about their chances.","Discipline":"Political Communication; Political Elites; Computational Methods","keywords":"Personalization; Images as Data; Linked Survey Data; Political Psychology; Computer Vision","approach":"image analysis","data":"social media images","issue":"personalization in election campaigns","geofocus":"Germany","Corresponding Author":"Felix Schmidt","chair":"Felix Schmidt","discussant":"Dominic Nyhuis","time":"Saturday, 17:00-18:30"}]
